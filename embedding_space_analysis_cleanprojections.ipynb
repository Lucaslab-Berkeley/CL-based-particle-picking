{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "158e674a-ccf9-4ee6-8f1d-b2bf2dbdd1dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jupyter environment detected. Enabling Open3D WebVisualizer.\n",
      "[Open3D INFO] WebRTC GUI backend enabled.\n",
      "[Open3D INFO] WebRTCWindowSystem: HTTP handshake server disabled.\n"
     ]
    }
   ],
   "source": [
    "import os, shutil\n",
    "import random\n",
    "import argparse\n",
    "import torch\n",
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import wandb\n",
    "from lightly.loss.ntx_ent_loss import NTXentLoss\n",
    "import time\n",
    "from sklearn.svm import SVC\n",
    "import seaborn as sns\n",
    "import glob\n",
    "import umap.umap_ as umap\n",
    "import plotly.express as px\n",
    "import plotly.io as pio\n",
    "import csv\n",
    "import itertools\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.optim.lr_scheduler import CosineAnnealingLR\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.models import resnet50, resnet18\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "from models.dgcnn import DGCNN, ResNet, DGCNN_partseg\n",
    "from util import IOStream, AverageMeter\n",
    "from vis_utils import *\n",
    "from losses import SupConLoss\n",
    "import datasets.data_utils as d_utils\n",
    "\n",
    "import biotite.structure.io as strucio\n",
    "import biotite.structure as struc\n",
    "from scipy.spatial.transform import Rotation\n",
    "from scipy.stats import gaussian_kde\n",
    "from Bio import PDB\n",
    "from Bio.PDB import MMCIFParser\n",
    "from Bio.PDB.vectors import Vector\n",
    "import open3d as o3d\n",
    "import warnings\n",
    "from tqdm import tqdm\n",
    "from PIL import Image\n",
    "\n",
    "import mrcfile\n",
    "from scipy.interpolate import RegularGridInterpolator\n",
    "from scipy.spatial.transform import Rotation\n",
    "from typing import Tuple\n",
    "\n",
    "warnings.simplefilter('ignore', PDB.PDBExceptions.PDBConstructionWarning)\n",
    "\n",
    "parser = argparse.ArgumentParser(description='Model Analysis')\n",
    "parser.add_argument('--num_points', type=int, default=1024,\n",
    "                    help='num of points to use')\n",
    "parser.add_argument('--emb_dims', type=int, default=1024, metavar='N',\n",
    "                    help='Dimension of embeddings')\n",
    "parser.add_argument('--k', type=int, default=15, metavar='N',\n",
    "                        help='Num of nearest neighbors to use')\n",
    "parser.add_argument('--dropout', type=float, default=1.0,\n",
    "                        help='dropout rate')\n",
    "parser.add_argument('--load_perc', type=float, default=1.0, help='The percentage of data to be loaded onto the RAM')\n",
    "args = parser.parse_args(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "27d8bd8a-b260-4dbf-9d38-5887f5438541",
   "metadata": {},
   "outputs": [],
   "source": [
    "rng = random.Random(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e58eace-e167-4a08-a482-c46eb9fdee13",
   "metadata": {},
   "source": [
    "Trained model folder names:\n",
    "\n",
    "* crosspoint_newFSData_simclr_noNorm_noise2d_0\n",
    "* crosspoint_newFSData_simclr_noNorm_noise2d_0_0.01_0.03_0.05"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5700b260-bfc3-45db-abd1-a52cc6eec7b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = \"/hpc/projects/group.czii/kithmini.herath/contrastive-learning-data/new_data/ds_original\"\n",
    "exp_name = \"crosspoint_newFSData_simclr_noNorm_noise2d_0_0.01_0.03_0.05\"\n",
    "label_map = {0:'ribosome',1:'neg_class'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1c9ec68d-7299-477c-9b3f-ab3023f41d9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_dir(fp):\n",
    "    if os.path.isdir(fp):\n",
    "        shutil.rmtree(fp)\n",
    "\n",
    "    os.mkdir(fp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba78648f-f1d3-4e99-ad67-efc5ecb73305",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "679bddad-fc86-4e38-96b1-a20d099abdc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_template_data(DATA_DIR):\n",
    "    label_map = {'ribosome':0, 'neg_class':1}\n",
    "    classes_data = {0: [], 1: []}\n",
    "    \n",
    "    all_filepath = []\n",
    "    \n",
    "    for cls in sorted(glob.glob(os.path.join(DATA_DIR, '*'))):\n",
    "        pcs = sorted(glob.glob(os.path.join(cls, '*')))\n",
    "        classes_data[label_map[cls.split('/')[-1]]] += pcs\n",
    "        all_filepath += pcs\n",
    "    # print(all_filepath)    \n",
    "    return all_filepath, classes_data\n",
    "\n",
    "def load_struc_files_npy(fp):\n",
    "    return np.load(fp) # downsampled numpy array\n",
    "\n",
    "class ScatteringPotential:\n",
    "    \"\"\"This class holds a 3D scattering potential array and provides methods for\n",
    "    taking projections at different orientations via the Fourier slice operation.\n",
    "    Code credits: Matthew Giammar\n",
    "    \n",
    "    Attributes:\n",
    "        potential_array (np.ndarray): The 3D scattering potential array.\n",
    "        potential_array_fft (np.ndarray): The FFT of the scattering potential.\n",
    "        pixel_size (float): The size of the pixels in Angstroms.\n",
    "        \n",
    "        _interpolator (RegularGridInterpolator): A pre-computed interpolator for the\n",
    "            spatial frequencies of the scattering potential.\n",
    "        _slice_shape (Tuple[int, int]): The shape of the scattering potential in the\n",
    "            x and y dimensions used to define the Fourier slice grid.\n",
    "    \n",
    "    Methods:\n",
    "        from_mrc(mrc_path: str) -> ScatteringPotential: Create a ScatteringPotential\n",
    "            object from an MRC file.\n",
    "        take_fourier_slice(phi: float, theta: float, psi: float) -> np.ndarray: Takes a\n",
    "            Fourier slice of the scattering potential at an orientation from the given\n",
    "            Euler angles.\n",
    "        take_projection(phi: float, theta: float, psi: float) -> np.ndarray: Take a\n",
    "            real-space projection of the scattering potential at an orientation from the\n",
    "            given Euler angles.\n",
    "    \"\"\"\n",
    "    \n",
    "    potential_array: np.ndarray\n",
    "    potential_array_fft: np.ndarray\n",
    "    pixel_size: float  # In Angstroms, assume cubic pixels\n",
    "    \n",
    "    _interpolator: RegularGridInterpolator\n",
    "    _slice_shape: Tuple[int, int]\n",
    "    \n",
    "    @classmethod\n",
    "    def from_mrc(cls, mrc_path: str):\n",
    "        \"\"\"Create a ScatteringPotential object from an MRC file.\"\"\"\n",
    "        with mrcfile.open(mrc_path) as mrc:\n",
    "            potential_array = mrc.data.copy()\n",
    "            pixel_size = mrc.voxel_size.x\n",
    "            \n",
    "        # Conform to cisTEM convention (reversed axes)\n",
    "        potential_array = np.swapaxes(potential_array, 0, -1)\n",
    "        \n",
    "        return cls(potential_array, pixel_size)\n",
    "    \n",
    "    def __init__(self, potential_array: np.ndarray, pixel_size: float):\n",
    "        self.potential_array = potential_array\n",
    "        self.pixel_size = pixel_size\n",
    "        \n",
    "        # Precompute the FFT of the scattering potential\n",
    "        # NOTE: The real-space potential is first fft-shifted to correct for the\n",
    "        # odd-valued frequencies when taking a Fourier slice. See (TODO) for more info\n",
    "        self.potential_array_fft = np.fft.fftshift(potential_array) # if we don't do this the phase will be shifted in an undesirable way\n",
    "        self.potential_array_fft = np.fft.fftn(self.potential_array_fft)\n",
    "        self.potential_array_fft = np.fft.fftshift(self.potential_array_fft)\n",
    "        \n",
    "        dim = [np.arange(s) - s // 2 for s in potential_array.shape]\n",
    "        self._interpolator = RegularGridInterpolator(\n",
    "            points=dim,\n",
    "            values=self.potential_array_fft,\n",
    "            method=\"linear\",\n",
    "            bounds_error=False,\n",
    "            fill_value=0,\n",
    "        )\n",
    "        self._slice_shape = potential_array.shape[:-1]  # (x, y) dimensions\n",
    "        \n",
    "    def take_fourier_slice(self, phi: float, theta: float, psi: float) -> np.ndarray:\n",
    "        \"\"\"Takes a Fourier slice of the pre-computed scattering potential at an\n",
    "        orientation from the given Euler angles. The angles are in radians, and the\n",
    "        rotation convention is ZYZ.\n",
    "        \n",
    "        Returned array is in the Fourier domain and centered (zero-frequency in center)\n",
    "        \n",
    "        Args:\n",
    "            phi (float): The rotation around the Z axis in radians.\n",
    "            theta (float): The rotation around the Y' axis in radians.\n",
    "            psi (float): The rotation around the Z'' axis in radians.\n",
    "            \n",
    "        Returns:\n",
    "            np.ndarray: The Fourier slice of the scattering potential.\n",
    "        \"\"\"\n",
    "        rot = Rotation.from_euler(\"ZYZ\", [phi, theta, psi]) # A convention used in most microscopic and robotic systems...\n",
    "        \n",
    "        # Generate a grid of integer coordinates at z = 0 then rotate\n",
    "        x = np.arange(self._slice_shape[0]) - self._slice_shape[0] // 2\n",
    "        y = np.arange(self._slice_shape[1]) - self._slice_shape[1] // 2\n",
    "        xx, yy = np.meshgrid(x, y)\n",
    "        zz = np.zeros_like(xx)\n",
    "        \n",
    "        coordinates = np.stack([xx, yy, zz], axis=-1)\n",
    "        coordinates = coordinates.reshape(-1, 3)\n",
    "        coordinates = rot.apply(coordinates)\n",
    "        \n",
    "        # Interpolate the scattering potential at the rotated coordinates\n",
    "        fourier_slice = self._interpolator(coordinates)\n",
    "        fourier_slice = fourier_slice.reshape(xx.shape)\n",
    "        \n",
    "        return fourier_slice\n",
    "    \n",
    "    def take_projection(self, phi: float, theta: float, psi: float) -> np.ndarray:\n",
    "        \"\"\"Take a real-space projection of the scattering potential at an orientation\n",
    "        from the given Euler angles. The angles are in radians, and the rotation\n",
    "        convention is ZYZ.\n",
    "        \n",
    "        Returned array is in real-space.\n",
    "        \n",
    "        Args:\n",
    "            phi (float): The rotation around the Z axis in radians.\n",
    "            theta (float): The rotation around the Y' axis in radians.\n",
    "            psi (float): The rotation around the Z'' axis in radians.\n",
    "            \n",
    "        Returns:\n",
    "            np.ndarray: The projection of the scattering potential.\n",
    "        \"\"\"\n",
    "        fourier_slice = self.take_fourier_slice(phi, theta, psi)\n",
    "        \n",
    "        fourier_slice = np.fft.ifftshift(fourier_slice)\n",
    "        projection = np.fft.ifftn(fourier_slice)\n",
    "        projection = np.fft.ifftshift(projection)\n",
    "        \n",
    "        return np.real(projection)\n",
    "\n",
    "class cryoEM_onTheFly_loader(Dataset):\n",
    "    def __init__(self, fp = \"\", angle_start_idx = 0, img_transform = None, pc1_transform = None, pc2_transform = None, n_imgs = 1, load_perc=1.0, type_=\"train\"):\n",
    "        self.data, self.classes_data = load_template_data(fp)\n",
    "        self.transform = img_transform\n",
    "        self.trans_1 = pc1_transform\n",
    "        self.trans_2 = pc2_transform\n",
    "        self.n_imgs = n_imgs\n",
    "        self.type = type_\n",
    "        self.start_idx = angle_start_idx\n",
    "        self.label_map = {'ribosome':0, 'neg_class':1}\n",
    "        \n",
    "        self.phi_values = np.arange(self.start_idx, 2*np.pi, np.pi/18)\n",
    "        self.theta_values = np.arange(self.start_idx/2.0, np.pi, np.pi/36)\n",
    "        self.psi_values = np.arange(self.start_idx, 2*np.pi, np.pi/18)\n",
    "        \n",
    "        # Generate all combinations\n",
    "        self.angle_combinations = list(itertools.product(\n",
    "            self.phi_values, \n",
    "            self.theta_values, \n",
    "            self.psi_values\n",
    "        ))\n",
    "        # Shuffle them\n",
    "        random.shuffle(self.angle_combinations)\n",
    "                \n",
    "        min_examples = min(len(self.classes_data[0]), len(self.classes_data[1]))\n",
    "        \n",
    "        # random.seed(0)\n",
    "        for i in range(2):\n",
    "            self.classes_data[i] = rng.sample(self.classes_data[i], k=min_examples) # random sampling of data WITHOUT replacement\n",
    "            \n",
    "        self.new_data = []\n",
    "        print(f\"Original number of samples: {len(self.data)}\")\n",
    "        for i in range(2):\n",
    "            self.new_data += self.classes_data[i]\n",
    "        print(f\"New number of samples: {len(self.new_data)}\")\n",
    "                \n",
    "        self.num_cache = int(len(self.new_data)*load_perc)\n",
    "        \n",
    "        self.all_pcs = []\n",
    "        \n",
    "        warnings.warn(f\"Loading {self.num_cache} point cloud files of the {self.type} set to RAM. This may take a while.\")\n",
    "        \n",
    "        for dp in tqdm(range(0, self.num_cache), desc=\"Loading data\", unit=\"file\"):\n",
    "            self.all_pcs.append(load_struc_files_npy(self.new_data[dp]))\n",
    "                        \n",
    "    def render_image(self, pc_path, idx):\n",
    "        fp = f\"{'/'.join(pc_path.split('/')[:-4])}/volume/{'/'.join(pc_path.split('/')[-3:])[:-3]}mrc\"\n",
    "        density = ScatteringPotential.from_mrc(fp)\n",
    "\n",
    "        phi, theta, psi = self.angle_combinations[idx % len(self.angle_combinations)]        \n",
    "        # print(phi, theta, psi)\n",
    "\n",
    "        projection = density.take_projection(phi, theta, psi)\n",
    "\n",
    "        return projection, phi, theta, psi\n",
    "    \n",
    "    def __getitem__(self, item):\n",
    "        pcd_path = self.new_data[item]\n",
    "                \n",
    "        label_map = {'ribosome':0, 'neg_class':1}\n",
    "        \n",
    "        # if(item < self.num_cache):\n",
    "        #     # read numpy from RAM\n",
    "        #     pointcloud_1 = self.all_pcs[item]\n",
    "        #     pointcloud_2 = self.all_pcs[item]\n",
    "        # else:\n",
    "        pointcloud_loaded = load_struc_files_npy(self.new_data[item])\n",
    "        #     pointcloud_2 = load_struc_files_npy(self.new_data[item])\n",
    "        # start = time.time()\n",
    "        render_img, phi, theta, psi = self.render_image(pcd_path, item) # time = around 6s\n",
    "        # print(\"################\")\n",
    "        # print(\"max:\",render_img.max(), \"min:\", render_img.min())\n",
    "        # print(\"***\")\n",
    "        # print(f\"Processing time = {time.time() - start}s\")\n",
    "        render_img = self.transform(render_img.astype('float32')) \n",
    "        # print(\"max:\",render_img.max(), \"min:\", render_img.min())\n",
    "        # print(\"################\")\n",
    "        # print(\"\\n\")\n",
    "\n",
    "        # point_t1 = [] #self.trans_1(pointcloud_1)\n",
    "        # point_t2 = [] #self.trans_2(pointcloud_2)\n",
    "\n",
    "        # pointcloud = (point_t1, point_t2)\n",
    "        \n",
    "        pointcloud = self.trans_1(pointcloud_loaded)\n",
    "    \n",
    "        return pointcloud, render_img, label_map[pcd_path.split(\"/\")[-2]], pcd_path.split(\"/\")[-1][:-4], (phi, theta, psi)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.new_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dd5fc830-02a3-4e89-8412-0017e57ccea7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_4004075/4130683404.py:179: UserWarning: Loading 1248 point cloud files of the train set to RAM. This may take a while.\n",
      "  warnings.warn(f\"Loading {self.num_cache} point cloud files of the {self.type} set to RAM. This may take a while.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original number of samples: 1884\n",
      "New number of samples: 1248\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading data: 100%|██████████| 1248/1248 [00:00<00:00, 1844.47file/s]\n",
      "/tmp/ipykernel_4004075/4130683404.py:179: UserWarning: Loading 132 point cloud files of the test set to RAM. This may take a while.\n",
      "  warnings.warn(f\"Loading {self.num_cache} point cloud files of the {self.type} set to RAM. This may take a while.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original number of samples: 199\n",
      "New number of samples: 132\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading data: 100%|██████████| 132/132 [00:00<00:00, 1917.59file/s]\n"
     ]
    }
   ],
   "source": [
    "transform = transforms.Compose([\n",
    "                                transforms.ToTensor(), # This converts PIL Image to tensor and scales to [0, 1]. But NOT for numpy arrays. For numpy arrays it just converts to a torch tensor\n",
    "                                # transforms.Normalize((0.001,), (0.007,)), # previous was 0.5, 0.5\n",
    "                                transforms.Resize((224, 224), antialias=True),\n",
    "                                # transforms.ColorJitter(brightness=0.4, contrast=0.4, saturation=0.4),\n",
    "                                # transforms.RandomHorizontalFlip(),\n",
    "                                # transforms.Normalize((0.5,), (0.5,))\n",
    "]) # normalize within -1,1\n",
    "\n",
    "pc_trans_1 = transforms.Compose(\n",
    "            [\n",
    "                d_utils.PointcloudToTensor(),\n",
    "                d_utils.PointcloudNormalize_preserved(),\n",
    "                d_utils.PointcloudRotate(),\n",
    "                # d_utils.PointcloudJitter(p=1),\n",
    "            ]) # d_utils.PointcloudTranslate(0.5, p=1), d_utils.PointcloudRandomInputDropout(p=1), d_utils.PointcloudScale(lo=0.5, hi=2, p=1), # removed these cause these templates doesn't exist in the real world. specially randomInputDropout and scaling(becasue these biological examples have an actual size)\n",
    "\n",
    "# # point cloud jitter might be helpful cause electrons move in cryo data\n",
    "    \n",
    "pc_trans_2 = transforms.Compose(\n",
    "            [\n",
    "                d_utils.PointcloudToTensor(),\n",
    "                d_utils.PointcloudNormalize_preserved(),\n",
    "                d_utils.PointcloudRotate(),\n",
    "                # d_utils.PointcloudJitter(p=1),\n",
    "            ])\n",
    "\n",
    "\n",
    "type_ = \"train\"\n",
    "train_set = cryoEM_onTheFly_loader(f\"{data_dir}/{type_}\", angle_start_idx=0, img_transform = transform, pc1_transform = pc_trans_1, pc2_transform = pc_trans_2, n_imgs = 2, load_perc=args.load_perc, type_=type_)\n",
    "train_loader = DataLoader(train_set, num_workers=12, batch_size=1, shuffle=True, drop_last=True, pin_memory=True) # the n_imgs parameter is not being used as of now\n",
    "\n",
    "type_ = \"test\"\n",
    "val_set = cryoEM_onTheFly_loader(f\"{data_dir}/{type_}\", angle_start_idx=np.pi/36, img_transform = transform, pc1_transform = pc_trans_1, pc2_transform = pc_trans_2, n_imgs = 2, load_perc=args.load_perc, type_=type_)\n",
    "val_loader = DataLoader(val_set, num_workers=12, batch_size=1, shuffle=True, drop_last=True, pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fca59091-621b-482e-88d3-55adb5d410b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # projection_maxs = []\n",
    "# # projection_mins = []\n",
    "# img_values = []\n",
    "# for i, (_, img, label, fname, (phi, theta, psi)) in enumerate(train_loader): \n",
    "#     if i>=5: break\n",
    "#     img_values.append(img.detach().cpu().numpy().flatten())\n",
    "#     # time.sleep(5)\n",
    "#     # projection_maxs.append(img.max())\n",
    "#     # projection_mins.append(img.min())\n",
    "# img_values = np.array(img_values).flatten()\n",
    "# print(np.mean(img_values), np.std(img_values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "25c229bf-e4dd-42f0-9fbd-b3d3d3443aaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.hist(img_values, bins = 30, density = True)\n",
    "# plt.title(\"Pixel intensity distribution\")\n",
    "# plt.show()\n",
    "\n",
    "# plt.hist(projection_mins)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16895c01-2c6d-493f-9e7f-67c5518e3c48",
   "metadata": {},
   "source": [
    "# Saving subsets of train-test data for evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4aa51b98-5a78-4237-8f2b-741ad4e59c7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_img_path = \"/hpc/projects/group.czii/kithmini.herath/contrastive-learning-data/new_data/saved_projections_prenorm_uniqueAnglesSubset_noiseAnalysis/train\"\n",
    "# test_img_path = \"/hpc/projects/group.czii/kithmini.herath/contrastive-learning-data/new_data/saved_projections_prenorm_uniqueAnglesSubset_noiseAnalysis/test\"\n",
    "# train_pc_path = \"/hpc/projects/group.czii/kithmini.herath/contrastive-learning-data/new_data/saved_pointclouds_prenorm_uniqueAnglesSubset_noiseAnalysis/train\"\n",
    "# test_pc_path = \"/hpc/projects/group.czii/kithmini.herath/contrastive-learning-data/new_data/saved_pointclouds_prenorm_uniqueAnglesSubset_noiseAnalysis/test\"\n",
    "\n",
    "# make_dir(train_img_path)\n",
    "# make_dir(train_pc_path)\n",
    "# make_dir(test_img_path)\n",
    "# make_dir(test_pc_path)\n",
    "\n",
    "# torch.manual_seed(0)\n",
    "# with open(f'{train_img_path}/metadata.csv', 'w', newline='') as csvfile:\n",
    "#     csv_writer = csv.writer(csvfile)\n",
    "#     csv_writer.writerow(['filename', 'label', 'phi', 'theta', 'psi'])  # Write header\n",
    "    \n",
    "#     for i, (pc, img, label, fname, (phi, theta, psi)) in enumerate(train_loader): \n",
    "#         np.save(f\"{train_img_path}/{fname[0]}.npy\", img.detach().cpu().numpy())\n",
    "#         np.save(f\"{train_pc_path}/{fname[0]}.npy\", pc.detach().cpu().numpy())\n",
    "#         csv_writer.writerow([fname[0], label.item(), phi.item(), theta.item(), psi.item()])\n",
    "        \n",
    "# with open(f'{test_img_path}/metadata.csv', 'w', newline='') as csvfile:\n",
    "#     csv_writer = csv.writer(csvfile)\n",
    "#     csv_writer.writerow(['filename', 'label', 'phi', 'theta', 'psi'])  # Write header\n",
    "    \n",
    "#     for i, (pc, img, label, fname, (phi, theta, psi)) in enumerate(val_loader): \n",
    "#         np.save(f\"{test_img_path}/{fname[0]}.npy\", img.detach().cpu().numpy())\n",
    "#         np.save(f\"{test_pc_path}/{fname[0]}.npy\", pc.detach().cpu().numpy())\n",
    "#         csv_writer.writerow([fname[0], label.item(), phi.item(), theta.item(), psi.item()])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6d3c7ef-96dd-4c14-a3cc-f53dd8299128",
   "metadata": {},
   "source": [
    "# Load models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a2204644-ee00-4af3-8bbb-8cf96ae734e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = \"cuda:0\"\n",
    "point_model_dict = torch.load(f'/hpc/projects/group.czii/kithmini.herath/crosspoint-trained-models/results/{exp_name}/models/ckpt_epoch_last.pth', map_location=\"cuda:0\")\n",
    "img_model_dict = torch.load(f'/hpc/projects/group.czii/kithmini.herath/crosspoint-trained-models/results/{exp_name}/models/img_model_last.pth', map_location=\"cuda:0\")\n",
    "\n",
    "point_model = DGCNN(args).to(device)\n",
    "img_model = ResNet(resnet50(), feat_dim = 2048).to(device)\n",
    "\n",
    "point_model.load_state_dict(point_model_dict)\n",
    "img_model.load_state_dict(img_model_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11391161-8f30-4fce-9c34-9eca3d369b45",
   "metadata": {},
   "source": [
    "# Get train/ val features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "172b079c-2226-48ca-b89e-68c1282252df",
   "metadata": {},
   "outputs": [],
   "source": [
    "class saved_data_loader(Dataset):\n",
    "    def __init__(self, fp = \"\",pc_transform=None, img_transform = None, type_=\"train\"):\n",
    "        self.img_data = sorted(glob.glob(f\"{fp}/*.npy\"))\n",
    "        self.metadata = pd.read_csv(f\"{fp}/metadata.csv\")\n",
    "        \n",
    "        # print(self.metadata)\n",
    "        self.img_transform = img_transform\n",
    "        self.pc_transform = pc_transform\n",
    "        self.type = type_\n",
    "        self.label_map = {'ribosome':0, 'neg_class':1}\n",
    "    \n",
    "    def __getitem__(self, item):\n",
    "        img_path = self.img_data[item]\n",
    "        pc_path = \"/\".join(img_path.split(\"/\")[:-3])+f\"/saved_pointclouds_prenorm_uniqueAnglesSubset_noiseAnalysis/{self.type}/{img_path.split('/')[-1]}\"\n",
    "                \n",
    "        label_map = {'ribosome':0, 'neg_class':1}\n",
    "\n",
    "        img = np.load(img_path)[0,0]\n",
    "        img = self.img_transform(img) \n",
    "        \n",
    "        pc = np.load(pc_path)[0]\n",
    "        pc = self.pc_transform(pc) \n",
    "        \n",
    "        label = self.metadata[self.metadata['filename'] == img_path.split(\"/\")[-1][:-4]]['label'].iloc[0]\n",
    "        return pc, img, label, img_path.split(\"/\")[-1][:-4]\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.img_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e1bede37-f008-4b13-99a3-78e845e73dea",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_features(pc_model, img_model, loader, device=\"cuda\", type_=\"train\"):\n",
    "    pc_feats_arr = []\n",
    "    img_feats_arr = []\n",
    "    labels_arr = []\n",
    "    fnames_arr = []\n",
    "    print(device)\n",
    "    \n",
    "    for i, (pcs, imgs, labels, fnames) in enumerate(loader): # fname -- original file name\n",
    "        pcs = pcs.to(device)\n",
    "        pcsT = pcs.transpose(2, 1).contiguous()\n",
    "        imgs = imgs.to(device)\n",
    "        labels = labels.numpy().tolist()\n",
    "        fnames = np.array(fnames).tolist()\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            _, _, point_feats = pc_model(pcsT)\n",
    "            img_feats = img_model.resnet(imgs)\n",
    "        \n",
    "        point_feats = F.normalize(point_feats, dim=1).detach().cpu().numpy()\n",
    "        img_feats = F.normalize(img_feats, dim=1).detach().cpu().numpy()\n",
    "        pc_feats_arr.extend(point_feats)\n",
    "        img_feats_arr.extend(img_feats)\n",
    "        labels_arr += labels\n",
    "        fnames_arr += fnames\n",
    "                                \n",
    "    return np.array(pc_feats_arr), np.array(img_feats_arr), np.array(labels_arr), np.array(fnames_arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1bfd2105-131d-454e-8772-3d29369a0a75",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.manifold import TSNE\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "def get_tsne_embeddings(arr):\n",
    "    # The default of 1,000 iterations gives fine results, but I'm training for longer just to eke\n",
    "    # out some marginal improvements. NB: This takes almost an hour!\n",
    "    tsne = TSNE(random_state=0, n_iter=15000, metric=\"cosine\")\n",
    "\n",
    "    embeddings = tsne.fit_transform(arr)\n",
    "    return embeddings\n",
    "\n",
    "def get_pca_embeddings(arr, ncomp=2):\n",
    "    # Initialize PCA with the number of components you want to keep\n",
    "    pca = PCA(n_components=ncomp)\n",
    "    \n",
    "    # Fit the PCA model and transform the data\n",
    "    embeddings = pca.fit_transform(arr)\n",
    "    \n",
    "    return embeddings\n",
    "\n",
    "def get_umap_embeddings(arr):\n",
    "    # Initialize UMAP with the desired number of components\n",
    "    reducer = umap.UMAP(n_components=2, random_state=42)\n",
    "    \n",
    "    # Fit the UMAP model and transform the data\n",
    "    embeddings = reducer.fit_transform(arr)\n",
    "    \n",
    "    return embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80b90302-cc17-4d7c-9f62-0605ad50f9ba",
   "metadata": {},
   "source": [
    "# Visualizing point cloud and image embedding space\n",
    "\n",
    "Neg class label map:\n",
    "* proteasome = 1\n",
    "* apoferritin = 2\n",
    "* betagal = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f725c8f8-a54d-41e2-a2ea-62edb52cc8ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vis codes\n",
    "\n",
    "def get_binary_umap(info, data_type, type_, noise_level):\n",
    "    df = pd.DataFrame({\n",
    "        'UMAP1': info[f'{data_type}_feat1'],\n",
    "        'UMAP2': info[f'{data_type}_feat2'],\n",
    "        'PDB_ID': info['pdb_ids'],\n",
    "        'Label': info['labels']\n",
    "    })\n",
    "\n",
    "    df = df.drop_duplicates(subset=['PDB_ID'], keep='first')\n",
    "    df = df.reset_index(drop=True)\n",
    "    print(df.shape)\n",
    "\n",
    "    df['Label'] = df['Label'].astype('category')\n",
    "\n",
    "    color_map = {0: 'orange', 1: 'green'}\n",
    "\n",
    "    # Create the scatter plot using Plotly\n",
    "    fig = px.scatter(df, x='UMAP1', y='UMAP2', color='Label',\n",
    "                     color_discrete_map=color_map,\n",
    "                     hover_data={'PDB_ID': True},\n",
    "                     title=f'UMAP plot of image features | {type_} | noise_std({noise_level})')\n",
    "\n",
    "    # Update legend labels\n",
    "    fig.for_each_trace(lambda t: t.update(name='Ribosome' if t.name == '0' else 'Neg_class'))\n",
    "\n",
    "    fig.update_layout(width=900, height=900, legend_title_text='Class')\n",
    "\n",
    "    fig.write_image(f\"/hpc/projects/group.czii/kithmini.herath/crosspoint-analysis/first_experiments_multipleclasses_pointmodel_uniqueanglesubsets/{type_}_{data_type}_noise({noise_level})_umap_main.pdf\")\n",
    "    \n",
    "def get_classwise_umap(info, data_type, type_, noise_level):\n",
    "    df = pd.DataFrame({\n",
    "        'UMAP1': info[f'{data_type}_feat1'],\n",
    "        'UMAP2': info[f'{data_type}_feat2'],\n",
    "        'PDB_ID': info['pdb_ids'],\n",
    "        'Label': info['labels']\n",
    "    })\n",
    "\n",
    "    df = df.drop_duplicates(subset=['PDB_ID'], keep='first')\n",
    "    df = df.reset_index(drop=True)\n",
    "    print(df.shape)\n",
    "\n",
    "    for l in range(df.shape[0]):\n",
    "        if \"pro\" in df.loc[l, 'PDB_ID']:\n",
    "            df.loc[l, 'Label'] = 1\n",
    "        elif \"fer\" in df.loc[l, 'PDB_ID']:\n",
    "            df.loc[l, 'Label'] = 2\n",
    "        elif \"gal\" in df.loc[l, 'PDB_ID']:\n",
    "            df.loc[l, 'Label'] = 3\n",
    "\n",
    "    df['Label'] = df['Label'].astype('category')\n",
    "\n",
    "    color_map = {0: 'orange', 1: 'green', 2: 'red', 3: 'blue'}\n",
    "\n",
    "    fig = px.scatter(df, x='UMAP1', y='UMAP2', color='Label',\n",
    "                     color_discrete_map=color_map,\n",
    "                     hover_data={'PDB_ID': True},\n",
    "                     size_max=15) # ,title=f'UMAP plot of image features | {type_} | noise_std({noise_level})'\n",
    "\n",
    "    fig.for_each_trace(lambda t: t.update(name={\n",
    "        '0': 'Ribosome',\n",
    "        '1': 'Proteasome',\n",
    "        '2': 'Apoferritin',\n",
    "        '3': 'Beta-gal'\n",
    "    }.get(t.name, 'Unknown')))\n",
    "\n",
    "    fig.update_layout(width=1200, height=1200,\n",
    "                      legend_title_text='Class',\n",
    "                      font=dict(size=35),\n",
    "                      xaxis=dict(\n",
    "                      title='UMAP1',\n",
    "                      tickfont=dict(size=35),\n",
    "                      autorange=True),\n",
    "                      yaxis=dict(\n",
    "                      title='UMAP2',\n",
    "                      tickfont=dict(size=35),\n",
    "                      autorange=True),\n",
    "                      xaxis_title_font_size=35,\n",
    "                      yaxis_title_font_size=35,\n",
    "                      # xaxis_tickfont_size=20,\n",
    "                      # yaxis_tickfont_size=20\n",
    "                      showlegend=False\n",
    "                      )\n",
    "    fig.update_xaxes(title=dict(text=\"<b>UMAP1</b>\", font=dict(size=35)))\n",
    "    fig.update_yaxes(title=dict(text=\"<b>UMAP2</b>\", font=dict(size=35)))\n",
    "\n",
    "    fig.update_traces(marker=dict(size=15))\n",
    "\n",
    "    pio.write_image(fig, f\"/hpc/projects/group.czii/kithmini.herath/crosspoint-analysis/first_experiments_multipleclasses_pointmodel_uniqueanglesubsets/{type_}_{data_type}_noise({noise_level})_clswise_umap_main.pdf\", width=1200, height=1200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "61995ce8-c812-4481-beec-b7b7df23480b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Noise level = 0.0 *************************\n",
      "cuda:0\n",
      "PC features (train) shape: (1248, 2048) | Image features (train) shape: (1248, 2048)\n",
      "(1248, 2048) (1248,) (1248,)\n",
      "[0 1 1 ... 0 0 0] 1248\n",
      "cuda:0\n",
      "PC features (test) shape: (128, 2048) | Image features (test) shape: (128, 2048)\n",
      "(128, 2048) (128, 2048) (128,) (128,)\n",
      "[1 0 1 0 0 1 1 1 1 1 0 0 1 1 1 1 1 0 1 1 0 1 0 1 1 0 0 1 0 1 1 0 1 0 0 0 1\n",
      " 0 1 0 1 0 1 1 1 1 0 1 0 1 0 1 1 1 1 0 1 1 0 0 1 1 0 0 1 1 0 0 1 0 0 0 0 0\n",
      " 1 1 1 0 1 1 0 1 0 1 0 0 0 0 0 1 1 1 0 1 0 0 1 0 0 0 0 1 0 0 1 0 0 1 1 0 1\n",
      " 0 0 0 1 0 0 0 1 1 0 1 1 1 0 1 0 0] 128\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/hpc/mydata/kithmini.herath/anaconda/latest/x86_64/envs/crosspoint_2dtm/lib/python3.8/site-packages/umap/umap_.py:1945: UserWarning: n_jobs value 1 overridden to 1 by setting random_state. Use no seed for parallelism.\n",
      "  warn(f\"n_jobs value {self.n_jobs} overridden to 1 by setting random_state. Use no seed for parallelism.\")\n",
      "/hpc/mydata/kithmini.herath/anaconda/latest/x86_64/envs/crosspoint_2dtm/lib/python3.8/site-packages/umap/umap_.py:1945: UserWarning: n_jobs value 1 overridden to 1 by setting random_state. Use no seed for parallelism.\n",
      "  warn(f\"n_jobs value {self.n_jobs} overridden to 1 by setting random_state. Use no seed for parallelism.\")\n",
      "/hpc/mydata/kithmini.herath/anaconda/latest/x86_64/envs/crosspoint_2dtm/lib/python3.8/site-packages/umap/umap_.py:1945: UserWarning: n_jobs value 1 overridden to 1 by setting random_state. Use no seed for parallelism.\n",
      "  warn(f\"n_jobs value {self.n_jobs} overridden to 1 by setting random_state. Use no seed for parallelism.\")\n",
      "/hpc/mydata/kithmini.herath/anaconda/latest/x86_64/envs/crosspoint_2dtm/lib/python3.8/site-packages/umap/umap_.py:1945: UserWarning: n_jobs value 1 overridden to 1 by setting random_state. Use no seed for parallelism.\n",
      "  warn(f\"n_jobs value {self.n_jobs} overridden to 1 by setting random_state. Use no seed for parallelism.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1248, 4)\n",
      "(1248, 4)\n",
      "(128, 4)\n",
      "(128, 4)\n",
      "(1248, 4)\n",
      "(1248, 4)\n",
      "(128, 4)\n",
      "(128, 4)\n",
      "Noise level = 0.01 *************************\n",
      "cuda:0\n",
      "PC features (train) shape: (1248, 2048) | Image features (train) shape: (1248, 2048)\n",
      "(1248, 2048) (1248,) (1248,)\n",
      "[1 0 0 ... 1 0 0] 1248\n",
      "cuda:0\n",
      "PC features (test) shape: (128, 2048) | Image features (test) shape: (128, 2048)\n",
      "(128, 2048) (128, 2048) (128,) (128,)\n",
      "[1 0 1 1 0 1 0 0 1 1 1 1 0 0 0 1 0 0 1 0 0 1 1 1 0 0 1 0 0 0 1 0 1 0 1 0 1\n",
      " 1 0 1 0 1 1 0 0 1 1 0 1 0 1 0 0 1 0 0 1 1 1 0 1 0 0 1 1 0 0 1 1 0 1 0 1 1\n",
      " 1 1 0 1 1 1 1 0 1 1 0 0 1 0 0 1 0 0 1 0 1 1 0 0 0 1 0 0 0 1 1 1 1 1 0 1 0\n",
      " 1 0 0 0 0 1 0 0 1 1 1 0 0 1 0 0 0] 128\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/hpc/mydata/kithmini.herath/anaconda/latest/x86_64/envs/crosspoint_2dtm/lib/python3.8/site-packages/umap/umap_.py:1945: UserWarning:\n",
      "\n",
      "n_jobs value 1 overridden to 1 by setting random_state. Use no seed for parallelism.\n",
      "\n",
      "/hpc/mydata/kithmini.herath/anaconda/latest/x86_64/envs/crosspoint_2dtm/lib/python3.8/site-packages/umap/umap_.py:1945: UserWarning:\n",
      "\n",
      "n_jobs value 1 overridden to 1 by setting random_state. Use no seed for parallelism.\n",
      "\n",
      "/hpc/mydata/kithmini.herath/anaconda/latest/x86_64/envs/crosspoint_2dtm/lib/python3.8/site-packages/umap/umap_.py:1945: UserWarning:\n",
      "\n",
      "n_jobs value 1 overridden to 1 by setting random_state. Use no seed for parallelism.\n",
      "\n",
      "/hpc/mydata/kithmini.herath/anaconda/latest/x86_64/envs/crosspoint_2dtm/lib/python3.8/site-packages/umap/umap_.py:1945: UserWarning:\n",
      "\n",
      "n_jobs value 1 overridden to 1 by setting random_state. Use no seed for parallelism.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1248, 4)\n",
      "(1248, 4)\n",
      "(128, 4)\n",
      "(128, 4)\n",
      "(1248, 4)\n",
      "(1248, 4)\n",
      "(128, 4)\n",
      "(128, 4)\n",
      "Noise level = 0.03 *************************\n",
      "cuda:0\n",
      "PC features (train) shape: (1248, 2048) | Image features (train) shape: (1248, 2048)\n",
      "(1248, 2048) (1248,) (1248,)\n",
      "[0 1 1 ... 0 0 0] 1248\n",
      "cuda:0\n",
      "PC features (test) shape: (128, 2048) | Image features (test) shape: (128, 2048)\n",
      "(128, 2048) (128, 2048) (128,) (128,)\n",
      "[1 0 1 1 0 0 1 1 0 0 1 0 0 0 1 1 1 1 0 1 1 0 1 0 1 0 0 1 0 0 1 1 0 0 1 1 1\n",
      " 1 0 0 1 0 0 1 1 0 0 0 1 1 1 0 1 1 0 1 0 1 1 0 0 0 1 1 1 0 0 0 0 1 1 1 1 0\n",
      " 0 0 0 1 0 1 0 1 0 0 0 0 1 1 0 0 0 1 0 0 1 0 1 1 1 0 0 0 1 0 1 1 0 1 1 1 1\n",
      " 0 1 1 0 0 0 0 0 1 1 1 0 1 0 0 1 1] 128\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/hpc/mydata/kithmini.herath/anaconda/latest/x86_64/envs/crosspoint_2dtm/lib/python3.8/site-packages/umap/umap_.py:1945: UserWarning:\n",
      "\n",
      "n_jobs value 1 overridden to 1 by setting random_state. Use no seed for parallelism.\n",
      "\n",
      "/hpc/mydata/kithmini.herath/anaconda/latest/x86_64/envs/crosspoint_2dtm/lib/python3.8/site-packages/umap/umap_.py:1945: UserWarning:\n",
      "\n",
      "n_jobs value 1 overridden to 1 by setting random_state. Use no seed for parallelism.\n",
      "\n",
      "/hpc/mydata/kithmini.herath/anaconda/latest/x86_64/envs/crosspoint_2dtm/lib/python3.8/site-packages/umap/umap_.py:1945: UserWarning:\n",
      "\n",
      "n_jobs value 1 overridden to 1 by setting random_state. Use no seed for parallelism.\n",
      "\n",
      "/hpc/mydata/kithmini.herath/anaconda/latest/x86_64/envs/crosspoint_2dtm/lib/python3.8/site-packages/umap/umap_.py:1945: UserWarning:\n",
      "\n",
      "n_jobs value 1 overridden to 1 by setting random_state. Use no seed for parallelism.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1248, 4)\n",
      "(1248, 4)\n",
      "(128, 4)\n",
      "(128, 4)\n",
      "(1248, 4)\n",
      "(1248, 4)\n",
      "(128, 4)\n",
      "(128, 4)\n",
      "Noise level = 0.05 *************************\n",
      "cuda:0\n",
      "PC features (train) shape: (1248, 2048) | Image features (train) shape: (1248, 2048)\n",
      "(1248, 2048) (1248,) (1248,)\n",
      "[0 0 1 ... 0 1 1] 1248\n",
      "cuda:0\n",
      "PC features (test) shape: (128, 2048) | Image features (test) shape: (128, 2048)\n",
      "(128, 2048) (128, 2048) (128,) (128,)\n",
      "[0 1 1 0 1 0 0 0 0 0 0 0 0 1 0 0 0 1 0 1 0 1 1 0 1 0 1 0 1 1 1 1 0 0 1 0 0\n",
      " 1 1 0 0 1 1 1 1 0 1 1 1 0 0 0 1 1 1 1 0 0 0 1 0 1 1 1 0 0 1 1 1 1 0 1 1 1\n",
      " 1 1 1 0 0 0 0 1 0 1 0 1 0 1 0 0 0 1 0 1 0 0 0 1 1 1 1 1 0 0 0 1 1 0 0 1 1\n",
      " 0 0 1 0 0 0 0 0 1 0 0 0 1 0 1 1 0] 128\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/hpc/mydata/kithmini.herath/anaconda/latest/x86_64/envs/crosspoint_2dtm/lib/python3.8/site-packages/umap/umap_.py:1945: UserWarning:\n",
      "\n",
      "n_jobs value 1 overridden to 1 by setting random_state. Use no seed for parallelism.\n",
      "\n",
      "/hpc/mydata/kithmini.herath/anaconda/latest/x86_64/envs/crosspoint_2dtm/lib/python3.8/site-packages/umap/umap_.py:1945: UserWarning:\n",
      "\n",
      "n_jobs value 1 overridden to 1 by setting random_state. Use no seed for parallelism.\n",
      "\n",
      "/hpc/mydata/kithmini.herath/anaconda/latest/x86_64/envs/crosspoint_2dtm/lib/python3.8/site-packages/umap/umap_.py:1945: UserWarning:\n",
      "\n",
      "n_jobs value 1 overridden to 1 by setting random_state. Use no seed for parallelism.\n",
      "\n",
      "/hpc/mydata/kithmini.herath/anaconda/latest/x86_64/envs/crosspoint_2dtm/lib/python3.8/site-packages/umap/umap_.py:1945: UserWarning:\n",
      "\n",
      "n_jobs value 1 overridden to 1 by setting random_state. Use no seed for parallelism.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1248, 4)\n",
      "(1248, 4)\n",
      "(128, 4)\n",
      "(128, 4)\n",
      "(1248, 4)\n",
      "(1248, 4)\n",
      "(128, 4)\n",
      "(128, 4)\n"
     ]
    }
   ],
   "source": [
    "noise_2d = [0.0, 0.01, 0.03, 0.05]\n",
    "\n",
    "data_dir = \"/hpc/projects/group.czii/kithmini.herath/contrastive-learning-data/new_data/saved_projections_prenorm_uniqueAnglesSubset_noiseAnalysis\"\n",
    "exp_name = \"crosspoint_newFSData_simclr_noNorm_noise2d_0_0.01_0.03_0.05\"\n",
    "label_map = {0:'ribosome',1:'neg_class'}\n",
    "\n",
    "img_model = img_model.to(device)\n",
    "img_model = img_model.eval()\n",
    "\n",
    "point_model = point_model.to(device)\n",
    "point_model = point_model.eval()\n",
    "\n",
    "for noise in noise_2d:\n",
    "    print(f\"Noise level = {noise} *************************\")\n",
    "    transform = transforms.Compose([transforms.ToTensor(),\n",
    "                                    d_utils.AddGaussianNoise(std=noise, p=1),\n",
    "                                    # transforms.Resize((224, 224), antialias=True),\n",
    "                                    # transforms.Normalize((0.5,), (0.5,))\n",
    "                                   ])\n",
    "    \n",
    "    pc_trans = transforms.Compose([d_utils.PointcloudToTensor()]) \n",
    "\n",
    "    type_ = \"train\"\n",
    "    train_set = saved_data_loader(f\"{data_dir}/{type_}\", pc_transform=pc_trans, img_transform = transform, type_=type_)\n",
    "    train_loader = DataLoader(train_set, num_workers=12, batch_size=32, shuffle=True, drop_last=True, pin_memory=True) # the n_imgs parameter is not being used as of now\n",
    "\n",
    "    type_ = \"test\"\n",
    "    val_set = saved_data_loader(f\"{data_dir}/{type_}\", pc_transform=pc_trans, img_transform = transform, type_=type_)\n",
    "    val_loader = DataLoader(val_set, num_workers=12, batch_size=32, shuffle=True, drop_last=True, pin_memory=True)\n",
    "\n",
    "    ########## Feature Extraction\n",
    "    # normalized features\n",
    "    point_feats_train, img_feats_train, labels_train, fnames_train = get_features(point_model, img_model, train_loader, device=device, type_=\"train\")\n",
    "    print(f\"PC features (train) shape: {point_feats_train.shape} | Image features (train) shape: {img_feats_train.shape}\")\n",
    "    print(img_feats_train.shape, labels_train.shape, fnames_train.shape)\n",
    "    print(labels_train, len(labels_train))\n",
    "\n",
    "    # normalized features\n",
    "    point_feats_val, img_feats_val, labels_val, fnames_val = get_features(point_model, img_model, val_loader, device=device, type_=\"val\")\n",
    "    print(f\"PC features (test) shape: {point_feats_val.shape} | Image features (test) shape: {img_feats_val.shape}\")\n",
    "    print(point_feats_val.shape, img_feats_val.shape, labels_val.shape, fnames_val.shape)\n",
    "    print(labels_val, len(labels_val))\n",
    "    \n",
    "    ########## Get 2D embeddings for umap/ pca\n",
    "    # img_feats_train_embs = get_pca_embeddings(img_feats_train,2)\n",
    "    # img_feats_val_embs = get_pca_embeddings(img_feats_val,2)\n",
    "\n",
    "    point_feats_train_embs = get_umap_embeddings(point_feats_train)\n",
    "    point_feats_val_embs = get_umap_embeddings(point_feats_val)\n",
    "    img_feats_train_embs = get_umap_embeddings(img_feats_train)\n",
    "    img_feats_val_embs = get_umap_embeddings(img_feats_val)\n",
    "\n",
    "    train_point_dict = {\n",
    "        \"point_feat1\": point_feats_train_embs[:,0],\n",
    "        \"point_feat2\": point_feats_train_embs[:,1],\n",
    "        \"labels\": [label_map[label] for label in labels_train]\n",
    "    }\n",
    "\n",
    "    val_point_dict = {\n",
    "        \"point_feat1\": point_feats_val_embs[:,0],\n",
    "        \"point_feat2\": point_feats_val_embs[:,1],\n",
    "        \"labels\": [label_map[label] for label in labels_val]\n",
    "    }\n",
    "    \n",
    "    train_img_dict = {\n",
    "        \"img_feat1\": img_feats_train_embs[:,0],\n",
    "        \"img_feat2\": img_feats_train_embs[:,1],\n",
    "        \"labels\": [label_map[label] for label in labels_train]\n",
    "    }\n",
    "\n",
    "    val_img_dict = {\n",
    "        \"img_feat1\": img_feats_val_embs[:,0],\n",
    "        \"img_feat2\": img_feats_val_embs[:,1],\n",
    "        \"labels\": [label_map[label] for label in labels_val]\n",
    "    }\n",
    "\n",
    "    \n",
    "    info_point_train = {\n",
    "        \"point_feat1\": point_feats_train_embs[:,0],\n",
    "        \"point_feat2\": point_feats_train_embs[:,1],\n",
    "        \"labels\": labels_train,\n",
    "        \"pdb_ids\": fnames_train\n",
    "    }\n",
    "\n",
    "    info_point_val = {\n",
    "        \"point_feat1\": point_feats_val_embs[:,0],\n",
    "        \"point_feat2\": point_feats_val_embs[:,1],\n",
    "        \"labels\": labels_val,\n",
    "        \"pdb_ids\": fnames_val\n",
    "    }\n",
    "    \n",
    "    info_img_train = {\n",
    "        \"img_feat1\": img_feats_train_embs[:,0],\n",
    "        \"img_feat2\": img_feats_train_embs[:,1],\n",
    "        \"labels\": labels_train,\n",
    "        \"pdb_ids\": fnames_train\n",
    "    }\n",
    "\n",
    "    info_img_val = {\n",
    "        \"img_feat1\": img_feats_val_embs[:,0],\n",
    "        \"img_feat2\": img_feats_val_embs[:,1],\n",
    "        \"labels\": labels_val,\n",
    "        \"pdb_ids\": fnames_val\n",
    "    }\n",
    "\n",
    "    ########## Visualize embedding space\n",
    "    get_binary_umap(info_point_train, \"point\", \"train\", noise)\n",
    "    get_classwise_umap(info_point_train, \"point\", \"train\", noise)\n",
    "    \n",
    "    get_binary_umap(info_point_val, \"point\", \"test\", noise)\n",
    "    get_classwise_umap(info_point_val, \"point\", \"test\", noise)\n",
    "    \n",
    "    get_binary_umap(info_img_train, \"img\", \"train\", noise)\n",
    "    get_classwise_umap(info_img_train, \"img\", \"train\", noise)\n",
    "    \n",
    "    get_binary_umap(info_img_val, \"img\", \"test\", noise)\n",
    "    get_classwise_umap(info_img_val, \"img\", \"test\", noise)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a71b4d11-798f-4811-bc59-c2ecfff33aaf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "882423b6-35f7-4efe-8623-2fbe23ab70ea",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "crosspoint_2dtm",
   "language": "python",
   "name": "crosspoint_2dtm"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
