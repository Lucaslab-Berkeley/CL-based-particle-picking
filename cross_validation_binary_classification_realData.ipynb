{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "158e674a-ccf9-4ee6-8f1d-b2bf2dbdd1dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jupyter environment detected. Enabling Open3D WebVisualizer.\n",
      "[Open3D INFO] WebRTC GUI backend enabled.\n",
      "[Open3D INFO] WebRTCWindowSystem: HTTP handshake server disabled.\n"
     ]
    }
   ],
   "source": [
    "import os, shutil\n",
    "import random\n",
    "import argparse\n",
    "import torch\n",
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import wandb\n",
    "from lightly.loss.ntx_ent_loss import NTXentLoss\n",
    "import time\n",
    "from sklearn.svm import SVC\n",
    "import seaborn as sns\n",
    "import glob\n",
    "import umap.umap_ as umap\n",
    "import plotly.express as px\n",
    "import plotly.io as pio\n",
    "import csv\n",
    "import itertools\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.optim.lr_scheduler import CosineAnnealingLR\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.models import resnet50, resnet18\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "from models.dgcnn import DGCNN, ResNet, DGCNN_partseg\n",
    "from util import IOStream, AverageMeter\n",
    "from vis_utils import *\n",
    "from losses import SupConLoss\n",
    "import datasets.data_utils as d_utils\n",
    "\n",
    "import biotite.structure.io as strucio\n",
    "import biotite.structure as struc\n",
    "from scipy.spatial.transform import Rotation\n",
    "from scipy.stats import gaussian_kde\n",
    "from Bio import PDB\n",
    "from Bio.PDB import MMCIFParser\n",
    "from Bio.PDB.vectors import Vector\n",
    "import open3d as o3d\n",
    "import warnings\n",
    "from tqdm import tqdm\n",
    "from PIL import Image\n",
    "import datasets.filters as filters\n",
    "\n",
    "import mrcfile\n",
    "from scipy.interpolate import RegularGridInterpolator\n",
    "from scipy.spatial.transform import Rotation\n",
    "from typing import Tuple\n",
    "\n",
    "from torch.utils.data import ConcatDataset, DataLoader, SubsetRandomSampler\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "warnings.simplefilter('ignore', PDB.PDBExceptions.PDBConstructionWarning)\n",
    "\n",
    "parser = argparse.ArgumentParser(description='Model Analysis')\n",
    "parser.add_argument('--num_points', type=int, default=1024,\n",
    "                    help='num of points to use')\n",
    "parser.add_argument('--emb_dims', type=int, default=1024, metavar='N',\n",
    "                    help='Dimension of embeddings')\n",
    "parser.add_argument('--k', type=int, default=15, metavar='N',\n",
    "                        help='Num of nearest neighbors to use')\n",
    "parser.add_argument('--dropout', type=float, default=1.0,\n",
    "                        help='dropout rate')\n",
    "parser.add_argument('--load_perc', type=float, default=1.0, help='The percentage of data to be loaded onto the RAM')\n",
    "args = parser.parse_args(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "27d8bd8a-b260-4dbf-9d38-5887f5438541",
   "metadata": {},
   "outputs": [],
   "source": [
    "rng = random.Random(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e58eace-e167-4a08-a482-c46eb9fdee13",
   "metadata": {},
   "source": [
    "Trained model folder names:\n",
    "\n",
    "* crosspoint_newFSData_simclr_noNorm_noise2d_0\n",
    "* crosspoint_newFSData_simclr_noNorm_noise2d_0_0.01_0.03_0.05"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5700b260-bfc3-45db-abd1-a52cc6eec7b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = \"/global/scratch/users/kithminiherath/in_situ_2d2d_realdata_binned_2t\"\n",
    "exp_name = \"cl_2d2d_realbinneddata_resnet50_HoriflipVerflip\"\n",
    "filter_type = \"lowpass\"\n",
    "filter_cutoff = 0.2\n",
    "label_map = {0:'ribosome',1:'background'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1c9ec68d-7299-477c-9b3f-ab3023f41d9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_dir(fp):\n",
    "    if os.path.isdir(fp):\n",
    "        shutil.rmtree(fp)\n",
    "\n",
    "    os.mkdir(fp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6d3c7ef-96dd-4c14-a3cc-f53dd8299128",
   "metadata": {},
   "source": [
    "# Load models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a2204644-ee00-4af3-8bbb-8cf96ae734e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = \"cuda:0\"\n",
    "img_model_dict = torch.load(f'/global/scratch/users/kithminiherath/results/{exp_name}/models/img_model_best.pth', map_location=\"cuda:0\")\n",
    "\n",
    "img_model = ResNet(resnet50(), feat_dim = 2048).to(device)\n",
    "\n",
    "img_model.load_state_dict(img_model_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11391161-8f30-4fce-9c34-9eca3d369b45",
   "metadata": {},
   "source": [
    "# Get train/ val features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "172b079c-2226-48ca-b89e-68c1282252df",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_img_data(DATA_DIR):\n",
    "    all_filepath = []\n",
    "    \n",
    "    for cls in sorted(glob.glob(os.path.join(DATA_DIR, '*'))):\n",
    "        imgs = sorted(glob.glob(os.path.join(cls, '*')))\n",
    "        if len(imgs)%2 == 0:\n",
    "            all_filepath += imgs\n",
    "        else:\n",
    "            all_filepath += imgs[:-1]\n",
    "    # print(all_filepath)    \n",
    "    return all_filepath\n",
    "\n",
    "def load_img_file(fp):\n",
    "    with mrcfile.open(fp) as mrc:\n",
    "        data = mrc.data.copy()\n",
    "        \n",
    "    return data\n",
    "\n",
    "def prenorm(fp):\n",
    "    if \"_projection_\" not in fp:\n",
    "        img = load_img_file(fp)\n",
    "        return (img - np.mean(img)) / np.std(img)\n",
    "    else:\n",
    "        return load_img_file(fp)\n",
    "\n",
    "class cl_data_loader(Dataset):\n",
    "    def __init__(self, fp = \"\", img_transform = None, type_=\"train\", filter_type=\"lowpass\", filter_cutoff=0.1, fourier_transformed=False):\n",
    "        self.data = load_img_data(fp) # ribosome, background\n",
    "        self.transform = img_transform\n",
    "        self.type = type_\n",
    "        self.filter_type = filter_type\n",
    "        self.filter_cutoff = filter_cutoff\n",
    "        self.fourier_transformed = fourier_transformed\n",
    "    \n",
    "    def __getitem__(self, item):                \n",
    "        label_map = {'ribosome':0, 'background':1}\n",
    "        \n",
    "        img1_fp = self.data[2*item]\n",
    "        img2_fp = self.data[2*item + 1]\n",
    "        \n",
    "        img1_class = img1_fp.split(\"/\")[-2]\n",
    "        img2_class = img2_fp.split(\"/\")[-2]\n",
    "                \n",
    "        assert img1_class == img2_class, \"Classes different in positive pair !!!\"\n",
    "        \n",
    "        img1 = prenorm(img1_fp)\n",
    "        img2 = prenorm(img2_fp)\n",
    "        \n",
    "        img1_filtered = filters.filter_image(img1, self.filter_cutoff, filter_type = self.filter_type)\n",
    "        img2_filtered = filters.filter_image(img2, self.filter_cutoff, filter_type = self.filter_type)\n",
    "        \n",
    "        if self.fourier_transformed:\n",
    "            img1_filtered = np.fft.fftshift(np.fft.fft2(img1_filtered))\n",
    "            img2_filtered = np.fft.fftshift(np.fft.fft2(img2_filtered))\n",
    "\n",
    "        img_t1 = self.transform(img1_filtered.astype('float32'))\n",
    "        img_t2 = self.transform(img2_filtered.astype('float32'))\n",
    "        \n",
    "        if \"projection\" in img1_fp.split(\"/\")[-1][:-4]:\n",
    "            ftype = \"simulated\"\n",
    "        else:\n",
    "            ftype = \"real\"\n",
    "    \n",
    "        return img_t1, img_t2, label_map[img1_class], ftype\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.data)//2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e1bede37-f008-4b13-99a3-78e845e73dea",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_features(img_model, loader, device=\"cuda\", type_=\"train\"):\n",
    "    img_feats_arr = []\n",
    "    labels_arr = []\n",
    "    fnames_arr = []\n",
    "    print(device)\n",
    "    \n",
    "    for i, (imgs1, imgs2, labels, fnames) in enumerate(loader):\n",
    "        if i>60: break\n",
    "        imgs = imgs1.to(device)\n",
    "        labels = labels.numpy().tolist()\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            img_feats = img_model.resnet(imgs)\n",
    "        \n",
    "        img_feats = F.normalize(img_feats, dim=1).detach().cpu().numpy()\n",
    "        img_feats_arr.extend(img_feats)\n",
    "        labels_arr += labels\n",
    "        fnames_arr += fnames\n",
    "                                \n",
    "    return np.array(img_feats_arr), np.array(labels_arr), np.array(fnames_arr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80b90302-cc17-4d7c-9f62-0605ad50f9ba",
   "metadata": {},
   "source": [
    "# Classification\n",
    "\n",
    "Neg class label map:\n",
    "* proteasome = 1\n",
    "* apoferritin = 2\n",
    "* betagal = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f725c8f8-a54d-41e2-a2ea-62edb52cc8ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.stats as stats\n",
    "\n",
    "def get_bar_plots_binaryclass(ribosome_scores, neg_scores):\n",
    "    barWidth = 0.38\n",
    "    ribo_means = {key: np.mean(values) for key, values in ribosome_scores.items()}\n",
    "    ribo_std_errors = {key: np.std(values, ddof=1) / np.sqrt(len(values)) \n",
    "                 for key, values in ribosome_scores.items()}\n",
    "    neg_means = {key: np.mean(values) for key, values in neg_scores.items()}\n",
    "    neg_std_errors = {key: np.std(values, ddof=1) / np.sqrt(len(values)) \n",
    "                 for key, values in neg_scores.items()}\n",
    "    \n",
    "    labels = [key.split('_')[-1] for key in list(ribosome_scores.keys())]\n",
    "    ribo_mean_values = list(ribo_means.values())\n",
    "    ribo_std_error_values = list(ribo_std_errors.values())\n",
    "    neg_mean_values = list(neg_means.values())\n",
    "    neg_std_error_values = list(neg_std_errors.values())\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize = (12, 8))  \n",
    "\n",
    "    # Set position of bar on X axis \n",
    "    br1 = np.arange(len(labels)) \n",
    "    br2 = [x + barWidth for x in br1] \n",
    "    \n",
    "    # Set the silver/gray background color\n",
    "    ax.set_facecolor('#EAEAF0')  # Light gray color\n",
    "    fig.patch.set_facecolor('white')\n",
    "    \n",
    "    ax.spines['top'].set_visible(False)\n",
    "    ax.spines['right'].set_visible(False)\n",
    "    ax.spines['bottom'].set_visible(False)\n",
    "    ax.spines['left'].set_visible(False)\n",
    "    \n",
    "    # Define error bar style\n",
    "    error_params = dict(elinewidth=3, capsize=10, capthick=1.5, ecolor='black')\n",
    "\n",
    "    # Make the plot\n",
    "    plt.bar(br1, ribo_mean_values, yerr=ribo_std_error_values, color ='#384860', width = barWidth, \n",
    "            edgecolor ='none', label ='Ribosome', zorder=2, error_kw=error_params) # , yerr=[train_errs0, train_errs1], capsize=5\n",
    "    plt.bar(br2, neg_mean_values, yerr=neg_std_error_values, color ='#97a6c4', width = barWidth, \n",
    "            edgecolor ='none', label ='Negative class', zorder=2, error_kw=error_params) # , yerr=[val_errs0, val_errs1], capsize=5\n",
    "\n",
    "    plt.grid(True, axis='y', color='black', linestyle='--', linewidth=0.5, zorder=0)\n",
    "    \n",
    "    # Adding Xticks \n",
    "    plt.xlabel('Noise (std)', fontweight ='bold', fontsize = 25) \n",
    "    plt.ylabel('Accuracy', fontweight ='bold', fontsize = 25) \n",
    "    plt.xticks([r + barWidth/2 for r in range(len(labels))], labels, fontsize=20)\n",
    "    plt.yticks(fontsize=20)\n",
    "    \n",
    "    # plt.title(title)\n",
    "    # plt.legend()\n",
    "    # plt.savefig(f'/hpc/projects/group.czii/kithmini.herath/crosspoint-analysis/first_experiments_multipleclasses_pointmodel_uniqueanglesubsets/{caption}_bar.pdf', dpi=300, bbox_inches='tight')\n",
    "    plt.show() \n",
    "    \n",
    "def plot_bar_graph_crossval(scores_dict):\n",
    "    # Calculate means and standard errors\n",
    "    barWidth = 0.3\n",
    "    means = {key: np.mean(values) for key, values in scores_dict.items()}\n",
    "    std_errors = {key: np.std(values, ddof=1) / np.sqrt(len(values)) \n",
    "                 for key, values in fold_scores.items()}\n",
    "\n",
    "    # Prepare data for plotting\n",
    "    labels = [key.split('_')[-1] for key in list(fold_scores.keys())]\n",
    "    mean_values = list(means.values())\n",
    "    std_error_values = list(std_errors.values())\n",
    "    \n",
    "    # Define error bar style\n",
    "    error_params = dict(elinewidth=3, capsize=10, capthick=1.5, ecolor='black')\n",
    "\n",
    "    # Create the bar plot\n",
    "    x = np.arange(len(labels))\n",
    "    fig, ax = plt.subplots(figsize = (12, 8))\n",
    "    # Set the silver/gray background color\n",
    "    ax.set_facecolor('#EAEAF0')  # Light gray color\n",
    "    fig.patch.set_facecolor('white')\n",
    "    \n",
    "    ax.spines['top'].set_visible(False)\n",
    "    ax.spines['right'].set_visible(False)\n",
    "    ax.spines['bottom'].set_visible(False)\n",
    "    ax.spines['left'].set_visible(False)\n",
    "    \n",
    "    ax.bar(x, mean_values, yerr=std_error_values, capsize=5, color='#f1a226', zorder=2, error_kw=error_params)\n",
    "    \n",
    "    plt.grid(True, axis='y', color='black', linestyle='--', linewidth=0.5, zorder=0)\n",
    "\n",
    "    # Customize the plot\n",
    "    plt.xlabel('Noise (std)', fontweight ='bold', fontsize = 25) \n",
    "    plt.ylabel('Accuracy', fontweight ='bold', fontsize = 25) \n",
    "    plt.xticks(x, labels, fontsize=20)\n",
    "    plt.yticks(fontsize=20)\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5fed327d-035b-4d4c-aa0a-25e71b5df21e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classifier train codes\n",
    "\n",
    "def get_class_accs(cls_dict, preds, labels):\n",
    "    # label_map = {0:'ribosome', 1:'atpase', 2:'proteasome'}\n",
    "\n",
    "    for idx, key in enumerate(cls_dict.keys()):\n",
    "        # print(idx, key)\n",
    "        cls_idxs = np.where(np.array(labels) == idx)[0]\n",
    "        cls_preds = np.array(preds)[cls_idxs]\n",
    "        cls_y = np.array(labels)[cls_idxs]\n",
    "        cls_dict[key] = (cls_preds == cls_y).sum()/len(cls_idxs)\n",
    "    return cls_dict\n",
    "\n",
    "class classifier(nn.Module):\n",
    "    \"\"\"\n",
    "    A simple classifier.\n",
    "\n",
    "    Attributes:\n",
    "    num_classes: The number of classes to classify into.\n",
    "    kernel_initializer: An initializer to use for the weights.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, num_classes, kernel_initializer=None):\n",
    "        super(classifier, self).__init__()\n",
    "        self.num_classes = num_classes\n",
    "        \n",
    "        # Define the dense layer\n",
    "        self.dense_layer = nn.Linear(in_features=2048, out_features=num_classes)\n",
    "        \n",
    "        # Initialize weights if initializer is provided\n",
    "        if kernel_initializer:\n",
    "            kernel_initializer(self.dense_layer.weight)\n",
    "    \n",
    "    def forward(self, inputs):\n",
    "        # Ensure the input has rank 2\n",
    "        if len(inputs.shape) != 2:\n",
    "            raise ValueError(f'Input shape {inputs.shape} is expected to have rank 2, but does not.')\n",
    "        \n",
    "        return self.dense_layer(inputs)\n",
    "\n",
    "def loop(model, feats, labels, opt, criterion, epoch, type_ = \"train\", device=\"cuda:0\"):\n",
    "    losses = AverageMeter()\n",
    "    total, correct = 0, 0\n",
    "\n",
    "    if type_ == \"train\":\n",
    "        model.train()\n",
    "        # print(f'Start training epoch')\n",
    "    elif type_ == \"val\":\n",
    "        model.eval()\n",
    "        # print(f'Start validation')\n",
    "    \n",
    "    bs = 32\n",
    "    nb = feats.shape[0]//bs\n",
    "    # print(feats.shape, labels.shape)\n",
    "    for i in range(nb):\n",
    "        x = torch.from_numpy(feats[i*bs: (i+1)*bs]).to(device)\n",
    "        y = torch.from_numpy(labels[i*bs: (i+1)*bs]).to(device)\n",
    "\n",
    "        if type_ == \"train\":\n",
    "            opt.zero_grad()\n",
    "            preds = model(x)\n",
    "        elif type_ == \"val\":\n",
    "            with torch.no_grad():\n",
    "                preds = model(x)\n",
    "\n",
    "        loss = criterion(preds, y)   # logits, targets\n",
    "        \n",
    "        _, y_pred = torch.max(preds, 1)\n",
    "        total += y.size(0)\n",
    "        correct += (y_pred == y).sum().item()\n",
    "        \n",
    "        if type_ == \"train\":\n",
    "            loss.backward()\n",
    "            opt.step()\n",
    "\n",
    "        losses.update(loss.item(), bs)\n",
    "            \n",
    "    return losses, correct/total\n",
    "\n",
    "def train(train_data, val_data, lr, epochs, device=\"cuda:0\"):\n",
    "    # print(\"train device:\",device)\n",
    "    train_feats, train_labels = train_data\n",
    "    val_feats, val_labels = val_data\n",
    "    torch.manual_seed(0)\n",
    "    \n",
    "    if not os.path.exists('/global/scratch/users/kithminiherath/results/cross-validation-realdata'):\n",
    "        os.makedirs('/global/scratch/users/kithminiherath/results/cross-validation-realdata')\n",
    "    if not os.path.exists('/global/scratch/users/kithminiherath/results/cross-validation-realdata/models'):\n",
    "        os.makedirs('/global/scratch/users/kithminiherath/results/cross-validation-realdata/models')\n",
    "    \n",
    "    model = classifier(num_classes=2, kernel_initializer=nn.init.xavier_uniform_).to(device)\n",
    "    \n",
    "    opt = optim.Adam(model.parameters(), lr=lr, weight_decay=1e-6)\n",
    "    \n",
    "    criterion = nn.CrossEntropyLoss().to(device)\n",
    "    \n",
    "    train_loss, val_loss = [], []\n",
    "    train_acc, val_acc = [], []\n",
    "    for epoch in range(epochs):\n",
    "        train_losses, train_accs = loop(model, train_feats, train_labels, opt, criterion, epoch, type_ = \"train\", device=device)\n",
    "        val_losses, val_accs = loop(model, val_feats, val_labels, opt, criterion, epoch, type_ = \"val\", device=device)\n",
    "        \n",
    "        train_loss.append(train_losses.avg)\n",
    "        val_loss.append(val_losses.avg)\n",
    "        \n",
    "        train_acc.append(train_accs)\n",
    "        val_acc.append(val_accs)\n",
    "        \n",
    "        if epoch % 10 == 0:\n",
    "            # print('==> Saving...')\n",
    "            save_file = os.path.join(f'/global/scratch/users/kithminiherath/results/cross-validation-realdata/models/','ckpt_epoch_{epoch}.pth'.format(epoch=epoch))\n",
    "            torch.save(model.state_dict(), save_file)\n",
    "\n",
    "\n",
    "    # print('==> Saving Last Model...')\n",
    "    save_file = os.path.join(f'/global/scratch/users/kithminiherath/results/cross-validation-realdata/models/',\n",
    "                             'ckpt_epoch_last.pth'.format(epoch=epoch))\n",
    "    torch.save(model.state_dict(), save_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61995ce8-c812-4481-beec-b7b7df23480b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Noise level = 0.0 *************************\n",
      "cuda:0\n",
      "cuda:0\n",
      "cuda:0\n",
      "cuda:0\n",
      "cuda:0\n",
      "cuda:0\n",
      "cuda:0\n",
      "cuda:0\n",
      "cuda:0\n",
      "cuda:0\n",
      "cuda:0\n",
      "cuda:0\n",
      "cuda:0\n",
      "cuda:0\n",
      "cuda:0\n",
      "cuda:0\n",
      "cuda:0\n",
      "cuda:0\n",
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "noise_2d = [0.0]\n",
    "\n",
    "data_dir = \"/global/scratch/users/kithminiherath/in_situ_2d2d_realdata_binned_2t\"\n",
    "label_map = {0:'ribosome',1:'background'}\n",
    "\n",
    "img_model = img_model.to(device)\n",
    "img_model = img_model.eval()\n",
    "\n",
    "# Store scores\n",
    "fold_scores = {\n",
    "    \"noise_0.0\" : []\n",
    "}\n",
    "\n",
    "fold_scores_ribosome = {\n",
    "    \"noise_0.0\" : []\n",
    "}\n",
    "\n",
    "fold_scores_neg_class = {\n",
    "    \"noise_0.0\" : []\n",
    "}\n",
    "\n",
    "for noise in noise_2d:\n",
    "    print(f\"Noise level = {noise} *************************\")\n",
    "    transform = transforms.Compose([transforms.ToTensor()]) #, transforms.CenterCrop((300, 300))\n",
    "\n",
    "    type_ = \"train\"\n",
    "    train_set = cl_data_loader(f\"{data_dir}/{type_}\", img_transform = transform, type_=type_, filter_type=filter_type, filter_cutoff=filter_cutoff)\n",
    "\n",
    "    type_ = \"test\"\n",
    "    val_set = cl_data_loader(f\"{data_dir}/{type_}\", img_transform = transform, type_=type_, filter_type=filter_type, filter_cutoff=filter_cutoff)\n",
    "    \n",
    "    combined_dataset = ConcatDataset([train_set, val_set])\n",
    "    \n",
    "    # Initialize K-Fold\n",
    "    kfold = KFold(n_splits=10, shuffle=True, random_state=10)\n",
    "\n",
    "    ########## Feature Extraction\n",
    "    for fold, (train_ids, val_ids) in enumerate(kfold.split(combined_dataset)):\n",
    "        # print(f'FOLD {fold + 1}')\n",
    "        \n",
    "        # Create samplers for train and validation splits\n",
    "        train_sampler = SubsetRandomSampler(train_ids)\n",
    "        val_sampler = SubsetRandomSampler(val_ids)\n",
    "        \n",
    "        # Create data loaders with your specific parameters\n",
    "        train_loader = DataLoader(\n",
    "            combined_dataset,\n",
    "            batch_size=32,\n",
    "            sampler=train_sampler,\n",
    "            num_workers=12,\n",
    "            pin_memory=True,\n",
    "            drop_last=True\n",
    "        )\n",
    "        \n",
    "        val_loader = DataLoader(\n",
    "            combined_dataset,\n",
    "            batch_size=32,\n",
    "            sampler=val_sampler,\n",
    "            num_workers=12,\n",
    "            pin_memory=True,\n",
    "            drop_last=True\n",
    "        )\n",
    "        \n",
    "        # normalized features\n",
    "        img_feats_train, labels_train, type_train = get_features(img_model, train_loader, device=device, type_=\"train\")\n",
    "        # print(f\"PC features (train) shape: {point_feats_train.shape} | Image features (train) shape: {img_feats_train.shape}\")\n",
    "        # print(img_feats_train.shape, labels_train.shape, fnames_train.shape)\n",
    "        # print(labels_train, len(labels_train))\n",
    "\n",
    "        # normalized features\n",
    "        img_feats_val, labels_val, type_val = get_features(img_model, val_loader, device=device, type_=\"val\")\n",
    "        # print(f\"PC features (test) shape: {point_feats_val.shape} | Image features (test) shape: {img_feats_val.shape}\")\n",
    "        # print(point_feats_val.shape, img_feats_val.shape, labels_val.shape, fnames_val.shape)\n",
    "        # print(labels_val, len(labels_val))\n",
    "    \n",
    "        ######## Train classifier\n",
    "        lr = 0.001\n",
    "        epochs = 40\n",
    "        # device = torch.device(\"cuda:0\")\n",
    "\n",
    "        train((img_feats_train, labels_train), (img_feats_val, labels_val), lr, epochs, device=device)\n",
    "\n",
    "        classifier_dict = torch.load(f'/global/scratch/users/kithminiherath/results/cross-validation-realdata/models/ckpt_epoch_last.pth', map_location=\"cuda:0\")\n",
    "        classifier_model = classifier(num_classes=2, kernel_initializer=nn.init.xavier_uniform_).to(device)\n",
    "\n",
    "        classifier_model.load_state_dict(classifier_dict)\n",
    "\n",
    "        classifier_model.eval()\n",
    "\n",
    "        with torch.no_grad():\n",
    "            preds_img_val = classifier_model(torch.from_numpy(img_feats_val).to(device)).to(device)\n",
    "\n",
    "        _, nn_img_val_preds = torch.max(preds_img_val, 1)\n",
    "\n",
    "        total_val = len(labels_val)\n",
    "\n",
    "        nn_img_val_acc = ((nn_img_val_preds.detach().cpu().numpy() == labels_val).sum().item())/total_val\n",
    "        \n",
    "        fold_scores[f\"noise_{noise}\"].append(nn_img_val_acc)\n",
    "        \n",
    "        cls_nn_img_val_acc = get_class_accs({'ribosome':0, 'background':0}, nn_img_val_preds.detach().cpu().numpy(), labels_val)\n",
    "        \n",
    "        fold_scores_ribosome[f\"noise_{noise}\"].append(cls_nn_img_val_acc['ribosome'])\n",
    "        fold_scores_neg_class[f\"noise_{noise}\"].append(cls_nn_img_val_acc['background'])\n",
    "\n",
    "plot_bar_graph_crossval(fold_scores)\n",
    "get_bar_plots_binaryclass(fold_scores_ribosome, fold_scores_neg_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8d28848-4339-40c2-8913-41c40607d869",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(fold_scores['noise_0.0']), np.mean(fold_scores_ribosome['noise_0.0']), np.mean(fold_scores_neg_class['noise_0.0'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1d37aef-46c4-4e70-a585-0d6cec7990b9",
   "metadata": {},
   "source": [
    "# SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d12c9d5-e659-4482-88de-5a7c0d021f3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "noise_2d = [0.0]\n",
    "\n",
    "data_dir = \"/global/scratch/users/kithminiherath/in_situ_2d2d_realdata_binned_2t\"\n",
    "label_map = {0:'ribosome',1:'background'}\n",
    "\n",
    "img_model = img_model.to(device)\n",
    "img_model = img_model.eval()\n",
    "\n",
    "# Store scores\n",
    "fold_scores = {\n",
    "    \"noise_0.0\" : []\n",
    "}\n",
    "\n",
    "fold_scores_ribosome = {\n",
    "    \"noise_0.0\" : []\n",
    "}\n",
    "\n",
    "fold_scores_neg_class = {\n",
    "    \"noise_0.0\" : []\n",
    "}\n",
    "\n",
    "for noise in noise_2d:\n",
    "    print(f\"Noise level = {noise} *************************\")\n",
    "    transform = transforms.Compose([transforms.ToTensor(), transforms.CenterCrop((300, 300))])\n",
    "\n",
    "    type_ = \"train\"\n",
    "    train_set = cl_data_loader(f\"{data_dir}/{type_}\", img_transform = transform, type_=type_, filter_type=filter_type, filter_cutoff=filter_cutoff)\n",
    "\n",
    "    type_ = \"test\"\n",
    "    val_set = cl_data_loader(f\"{data_dir}/{type_}\", img_transform = transform, type_=type_, filter_type=filter_type, filter_cutoff=filter_cutoff)\n",
    "    \n",
    "    combined_dataset = ConcatDataset([train_set, val_set])\n",
    "    \n",
    "    # Initialize K-Fold\n",
    "    kfold = KFold(n_splits=10, shuffle=True, random_state=10)\n",
    "\n",
    "    ########## Feature Extraction\n",
    "    for fold, (train_ids, val_ids) in enumerate(kfold.split(combined_dataset)):\n",
    "        # print(f'FOLD {fold + 1}')\n",
    "        \n",
    "        # Create samplers for train and validation splits\n",
    "        train_sampler = SubsetRandomSampler(train_ids)\n",
    "        val_sampler = SubsetRandomSampler(val_ids)\n",
    "        \n",
    "        # Create data loaders with your specific parameters\n",
    "        train_loader = DataLoader(\n",
    "            combined_dataset,\n",
    "            batch_size=32,\n",
    "            sampler=train_sampler,\n",
    "            num_workers=12,\n",
    "            pin_memory=True,\n",
    "            drop_last=True\n",
    "        )\n",
    "        \n",
    "        val_loader = DataLoader(\n",
    "            combined_dataset,\n",
    "            batch_size=32,\n",
    "            sampler=val_sampler,\n",
    "            num_workers=12,\n",
    "            pin_memory=True,\n",
    "            drop_last=True\n",
    "        )\n",
    "        \n",
    "        # normalized features\n",
    "        img_feats_train, labels_train, type_train = get_features(img_model, train_loader, device=device, type_=\"train\")\n",
    "        # print(f\"PC features (train) shape: {point_feats_train.shape} | Image features (train) shape: {img_feats_train.shape}\")\n",
    "        # print(img_feats_train.shape, labels_train.shape, fnames_train.shape)\n",
    "        # print(labels_train, len(labels_train))\n",
    "\n",
    "        # normalized features\n",
    "        img_feats_val, labels_val, type_val = get_features(img_model, val_loader, device=device, type_=\"val\")\n",
    "        # print(f\"PC features (test) shape: {point_feats_val.shape} | Image features (test) shape: {img_feats_val.shape}\")\n",
    "        # print(point_feats_val.shape, img_feats_val.shape, labels_val.shape, fnames_val.shape)\n",
    "        # print(labels_val, len(labels_val))\n",
    "    \n",
    "        ######## Fit classifier on train set\n",
    "        model_tl = SVC(C = 0.1, kernel ='linear')\n",
    "\n",
    "        feats_train = np.array(img_feats_train)\n",
    "        labels_train = np.array(labels_train)\n",
    "\n",
    "        model_tl.fit(feats_train, labels_train) \n",
    "        \n",
    "        feats_val = np.array(img_feats_val)\n",
    "        labels_val = np.array(labels_val)\n",
    "        \n",
    "        val_accuracy = model_tl.score(feats_val, labels_val)\n",
    "        fold_scores[f\"noise_{noise}\"].append(val_accuracy)\n",
    "        \n",
    "        preds_img_val = model_tl.predict(feats_val)\n",
    "                \n",
    "        total_val = len(labels_val)\n",
    "        \n",
    "        cls_img_val_acc = get_class_accs({'ribosome':0, 'background':0}, preds_img_val, labels_val)\n",
    "        \n",
    "        fold_scores_ribosome[f\"noise_{noise}\"].append(cls_img_val_acc['ribosome'])\n",
    "        fold_scores_neg_class[f\"noise_{noise}\"].append(cls_img_val_acc['background'])\n",
    "\n",
    "np.mean(fold_scores['noise_0.0']), np.mean(fold_scores_ribosome['noise_0.0']), np.mean(fold_scores_neg_class['noise_0.0'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71b57a16-acc0-4d5c-bfeb-b135bf869e3e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "crosspoint_2dtm",
   "language": "python",
   "name": "crosspoint_2dtm"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
