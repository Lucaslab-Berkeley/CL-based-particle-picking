
The following have been reloaded with a version change:
  1) anaconda/2023.03 => anaconda/latest

/home/kithmini.herath/codes/CrossPoint/datasets/data.py:407: UserWarning: Loading 13700 point cloud files of the train set to RAM. This may take a while.
  warnings.warn(f"Loading {self.num_cache} point cloud files of the {self.type} set to RAM. This may take a while.")
Namespace(batch_size=128, cmid_reg=1.0, dataset='crosspoint_2dtm_4', dropout=0.5, emb_dims=1024, epochs=300, eval=False, exp_name='crosspoint_2dtm_4_onTheFly_simclr', imid_reg=1.0, k=15, load_perc=1.0, loss='SimCLR', lr=0.001, model='dgcnn', model_path='', momentum=0.9, no_cuda=False, noise2d=0.0, noise3d=0.1, num_points=2048, print_freq=20, resume=False, save_freq=10, seed=1, start_epoch=0, test=False, test_batch_size=16, use_sgd=False, val_included=1)
Using GPU : 0 from 1 devices
Loading data:   0%|                                                                                   | 0/13700 [00:00<?, ?file/s]Loading data:   1%|▉                                                                      | 179/13700 [00:00<00:07, 1785.36file/s]Loading data:   3%|█▉                                                                     | 364/13700 [00:00<00:07, 1819.72file/s]Loading data:   4%|██▊                                                                    | 550/13700 [00:00<00:07, 1836.88file/s]Loading data:   5%|███▊                                                                   | 734/13700 [00:00<00:07, 1832.65file/s]Loading data:   7%|████▊                                                                  | 924/13700 [00:00<00:06, 1855.61file/s]Loading data:   8%|█████▋                                                                | 1115/13700 [00:00<00:06, 1871.85file/s]Loading data:  10%|██████▋                                                               | 1306/13700 [00:00<00:06, 1881.86file/s]Loading data:  11%|███████▋                                                              | 1495/13700 [00:00<00:06, 1883.80file/s]Loading data:  12%|████████▌                                                             | 1685/13700 [00:00<00:06, 1886.39file/s]Loading data:  14%|█████████▌                                                            | 1874/13700 [00:01<00:06, 1828.48file/s]Loading data:  15%|██████████▌                                                           | 2064/13700 [00:01<00:06, 1847.59file/s]Loading data:  16%|███████████▌                                                          | 2258/13700 [00:01<00:06, 1873.92file/s]Loading data:  18%|████████████▌                                                         | 2451/13700 [00:01<00:05, 1887.70file/s]Loading data:  19%|█████████████▍                                                        | 2640/13700 [00:01<00:06, 1816.23file/s]Loading data:  21%|██████████████▍                                                       | 2833/13700 [00:01<00:05, 1848.02file/s]Loading data:  22%|███████████████▍                                                      | 3019/13700 [00:01<00:05, 1783.85file/s]Loading data:  23%|████████████████▍                                                     | 3216/13700 [00:01<00:05, 1835.62file/s]Loading data:  25%|█████████████████▍                                                    | 3408/13700 [00:01<00:05, 1858.78file/s]Loading data:  26%|██████████████████▍                                                   | 3601/13700 [00:01<00:05, 1878.67file/s]Loading data:  28%|███████████████████▎                                                  | 3790/13700 [00:02<00:05, 1877.02file/s]Loading data:  29%|████████████████████▎                                                 | 3980/13700 [00:02<00:05, 1883.08file/s]Loading data:  30%|█████████████████████▎                                                | 4172/13700 [00:02<00:05, 1893.62file/s]Loading data:  32%|██████████████████████▎                                               | 4362/13700 [00:02<00:04, 1891.04file/s]Loading data:  33%|███████████████████████▎                                              | 4552/13700 [00:02<00:04, 1885.95file/s]Loading data:  35%|████████████████████████▏                                             | 4741/13700 [00:02<00:04, 1884.43file/s]Loading data:  36%|█████████████████████████▏                                            | 4931/13700 [00:02<00:04, 1888.30file/s]Loading data:  37%|██████████████████████████▏                                           | 5121/13700 [00:02<00:04, 1889.57file/s]Loading data:  39%|███████████████████████████▏                                          | 5310/13700 [00:02<00:04, 1879.32file/s]Loading data:  40%|████████████████████████████                                          | 5504/13700 [00:02<00:04, 1896.86file/s]Loading data:  42%|█████████████████████████████                                         | 5694/13700 [00:03<00:04, 1896.89file/s]Loading data:  43%|██████████████████████████████                                        | 5884/13700 [00:03<00:04, 1895.17file/s]Loading data:  44%|███████████████████████████████                                       | 6077/13700 [00:03<00:04, 1903.42file/s]Loading data:  46%|████████████████████████████████                                      | 6268/13700 [00:03<00:04, 1845.69file/s]Loading data:  47%|█████████████████████████████████                                     | 6463/13700 [00:03<00:03, 1875.63file/s]Loading data:  49%|██████████████████████████████████                                    | 6656/13700 [00:03<00:03, 1888.94file/s]Loading data:  50%|███████████████████████████████████                                   | 6852/13700 [00:03<00:03, 1909.79file/s]Loading data:  51%|███████████████████████████████████▉                                  | 7044/13700 [00:03<00:03, 1908.39file/s]Loading data:  53%|████████████████████████████████████▉                                 | 7238/13700 [00:03<00:03, 1915.55file/s]Loading data:  54%|█████████████████████████████████████▉                                | 7433/13700 [00:03<00:03, 1924.50file/s]Loading data:  56%|██████████████████████████████████████▉                               | 7628/13700 [00:04<00:03, 1930.14file/s]Loading data:  57%|███████████████████████████████████████▉                              | 7826/13700 [00:04<00:03, 1942.71file/s]Loading data:  59%|████████████████████████████████████████▉                             | 8021/13700 [00:04<00:03, 1867.28file/s]Loading data:  60%|██████████████████████████████████████████                            | 8224/13700 [00:04<00:02, 1912.30file/s]Loading data:  61%|███████████████████████████████████████████                           | 8421/13700 [00:04<00:02, 1928.32file/s]Loading data:  63%|████████████████████████████████████████████                          | 8618/13700 [00:04<00:02, 1938.03file/s]Loading data:  64%|█████████████████████████████████████████████                         | 8817/13700 [00:04<00:02, 1953.24file/s]Loading data:  66%|██████████████████████████████████████████████                        | 9014/13700 [00:04<00:02, 1957.20file/s]Loading data:  67%|███████████████████████████████████████████████                       | 9212/13700 [00:04<00:02, 1963.46file/s]Loading data:  69%|████████████████████████████████████████████████                      | 9409/13700 [00:04<00:02, 1958.70file/s]Loading data:  70%|█████████████████████████████████████████████████                     | 9605/13700 [00:05<00:02, 1952.19file/s]Loading data:  72%|██████████████████████████████████████████████████                    | 9801/13700 [00:05<00:02, 1949.12file/s]Loading data:  73%|███████████████████████████████████████████████████                   | 9996/13700 [00:05<00:01, 1935.44file/s]Loading data:  74%|███████████████████████████████████████████████████▎                 | 10190/13700 [00:05<00:01, 1925.06file/s]Loading data:  76%|████████████████████████████████████████████████████▎                | 10384/13700 [00:05<00:01, 1928.59file/s]Loading data:  77%|█████████████████████████████████████████████████████▎               | 10579/13700 [00:05<00:01, 1934.01file/s]Loading data:  79%|██████████████████████████████████████████████████████▎              | 10775/13700 [00:05<00:01, 1940.45file/s]Loading data:  80%|███████████████████████████████████████████████████████▎             | 10970/13700 [00:05<00:01, 1934.32file/s]Loading data:  82%|████████████████████████████████████████████████████████▏            | 11167/13700 [00:05<00:01, 1942.89file/s]Loading data:  83%|█████████████████████████████████████████████████████████▏           | 11363/13700 [00:05<00:01, 1946.55file/s]Loading data:  84%|██████████████████████████████████████████████████████████▏          | 11562/13700 [00:06<00:01, 1955.71file/s]Loading data:  86%|███████████████████████████████████████████████████████████▏         | 11758/13700 [00:06<00:00, 1944.55file/s]Loading data:  87%|████████████████████████████████████████████████████████████▏        | 11953/13700 [00:06<00:00, 1934.88file/s]Loading data:  89%|█████████████████████████████████████████████████████████████▏       | 12147/13700 [00:06<00:00, 1929.12file/s]Loading data:  90%|██████████████████████████████████████████████████████████████▏      | 12342/13700 [00:06<00:00, 1934.10file/s]Loading data:  92%|███████████████████████████████████████████████████████████████▏     | 12540/13700 [00:06<00:00, 1945.84file/s]Loading data:  93%|████████████████████████████████████████████████████████████████▏    | 12736/13700 [00:06<00:00, 1947.71file/s]Loading data:  94%|█████████████████████████████████████████████████████████████████▏   | 12931/13700 [00:06<00:00, 1941.78file/s]Loading data:  96%|██████████████████████████████████████████████████████████████████   | 13126/13700 [00:06<00:00, 1938.24file/s]Loading data:  97%|███████████████████████████████████████████████████████████████████  | 13320/13700 [00:06<00:00, 1935.26file/s]Loading data:  99%|████████████████████████████████████████████████████████████████████ | 13514/13700 [00:07<00:00, 1933.54file/s]Loading data: 100%|█████████████████████████████████████████████████████████████████████| 13700/13700 [00:07<00:00, 1904.14file/s]
/home/kithmini.herath/codes/CrossPoint/datasets/data.py:407: UserWarning: Loading 1257 point cloud files of the val set to RAM. This may take a while.
  warnings.warn(f"Loading {self.num_cache} point cloud files of the {self.type} set to RAM. This may take a while.")
Loading data:   0%|                                                                                    | 0/1257 [00:00<?, ?file/s]Loading data:  15%|███████████                                                             | 193/1257 [00:00<00:00, 1923.86file/s]Loading data:  31%|██████████████████████                                                  | 386/1257 [00:00<00:00, 1906.89file/s]Loading data:  46%|█████████████████████████████████                                       | 577/1257 [00:00<00:00, 1907.49file/s]Loading data:  61%|███████████████████████████████████████████▉                            | 768/1257 [00:00<00:00, 1891.78file/s]Loading data:  76%|██████████████████████████████████████████████████████▊                 | 958/1257 [00:00<00:00, 1888.91file/s]Loading data:  91%|████████████████████████████████████████████████████████████████▊      | 1147/1257 [00:00<00:00, 1607.27file/s]Loading data: 100%|███████████████████████████████████████████████████████████████████████| 1257/1257 [00:00<00:00, 1758.17file/s]cuda
Use Adam
Start training epoch: (0/300)

Epoch (0), Batch(0/107), loss: 13.289568, imid loss: 4.072211, cmid loss: 9.217357 
Epoch (0), Batch(20/107), loss: 10.014701, imid loss: 3.820857, cmid loss: 6.193844 
Epoch (0), Batch(40/107), loss: 9.316338, imid loss: 3.325280, cmid loss: 5.991058 
Epoch (0), Batch(60/107), loss: 8.760109, imid loss: 2.868118, cmid loss: 5.891991 
Epoch (0), Batch(80/107), loss: 8.334208, imid loss: 2.517225, cmid loss: 5.816984 
Epoch (0), Batch(100/107), loss: 7.998099, imid loss: 2.252297, cmid loss: 5.745802 
Train 0, loss: 7.903546
Start validation
Val 0, loss: 15.179561
Linear Accuracy (val): 0.5625
==> Saving Best Model...
==> Saving...
Start training epoch: (1/300)
Epoch (1), Batch(0/107), loss: 6.213257, imid loss: 1.072098, cmid loss: 5.141159 
Epoch (1), Batch(20/107), loss: 6.228711, imid loss: 0.941309, cmid loss: 5.287402 
Epoch (1), Batch(40/107), loss: 6.130329, imid loss: 0.893787, cmid loss: 5.236542 
Epoch (1), Batch(60/107), loss: 6.025059, imid loss: 0.857455, cmid loss: 5.167604 
Epoch (1), Batch(80/107), loss: 5.934400, imid loss: 0.821477, cmid loss: 5.112924 
Epoch (1), Batch(100/107), loss: 5.853147, imid loss: 0.801971, cmid loss: 5.051177 
Train 1, loss: 5.833198
Start validation
Val 1, loss: 9.475247
Linear Accuracy (val): 0.5729166666666666
==> Saving Best Model...
Start training epoch: (2/300)
Epoch (2), Batch(0/107), loss: 5.525437, imid loss: 0.595358, cmid loss: 4.930079 
Epoch (2), Batch(20/107), loss: 5.182824, imid loss: 0.627695, cmid loss: 4.555128 
Epoch (2), Batch(40/107), loss: 5.157646, imid loss: 0.631807, cmid loss: 4.525839 
Epoch (2), Batch(60/107), loss: 5.068833, imid loss: 0.617108, cmid loss: 4.451725 
Epoch (2), Batch(80/107), loss: 4.971932, imid loss: 0.599428, cmid loss: 4.372504 
Epoch (2), Batch(100/107), loss: 4.906248, imid loss: 0.589527, cmid loss: 4.316721 
Train 2, loss: 4.886934
Start validation
Val 2, loss: 8.811539
Linear Accuracy (val): 0.5833333333333334
==> Saving Best Model...
Start training epoch: (3/300)
Epoch (3), Batch(0/107), loss: 4.675569, imid loss: 0.561052, cmid loss: 4.114516 
Epoch (3), Batch(20/107), loss: 4.448767, imid loss: 0.529412, cmid loss: 3.919355 
Epoch (3), Batch(40/107), loss: 4.415272, imid loss: 0.519638, cmid loss: 3.895634 
Epoch (3), Batch(60/107), loss: 4.416590, imid loss: 0.514445, cmid loss: 3.902145 
Epoch (3), Batch(80/107), loss: 4.385895, imid loss: 0.510166, cmid loss: 3.875729 
Epoch (3), Batch(100/107), loss: 4.369987, imid loss: 0.507943, cmid loss: 3.862043 
Train 3, loss: 4.367700
Start validation
Val 3, loss: 6.432437
Linear Accuracy (val): 0.5798611111111112
Start training epoch: (4/300)
Epoch (4), Batch(0/107), loss: 4.338321, imid loss: 0.465880, cmid loss: 3.872441 
Epoch (4), Batch(20/107), loss: 4.190825, imid loss: 0.481501, cmid loss: 3.709324 
Epoch (4), Batch(40/107), loss: 4.175039, imid loss: 0.480245, cmid loss: 3.694794 
Epoch (4), Batch(60/107), loss: 4.143432, imid loss: 0.473743, cmid loss: 3.669689 
Epoch (4), Batch(80/107), loss: 4.115449, imid loss: 0.470206, cmid loss: 3.645244 
Epoch (4), Batch(100/107), loss: 4.104766, imid loss: 0.465119, cmid loss: 3.639647 
Train 4, loss: 4.101293
Start validation
Val 4, loss: 6.179940
Linear Accuracy (val): 0.5972222222222222
==> Saving Best Model...
Start training epoch: (5/300)
Epoch (5), Batch(0/107), loss: 4.118323, imid loss: 0.433549, cmid loss: 3.684775 
Epoch (5), Batch(20/107), loss: 3.998338, imid loss: 0.434501, cmid loss: 3.563837 
Epoch (5), Batch(40/107), loss: 3.970403, imid loss: 0.433856, cmid loss: 3.536547 
Epoch (5), Batch(60/107), loss: 3.943398, imid loss: 0.429072, cmid loss: 3.514325 
Epoch (5), Batch(80/107), loss: 3.922498, imid loss: 0.428071, cmid loss: 3.494427 
Epoch (5), Batch(100/107), loss: 3.893661, imid loss: 0.425100, cmid loss: 3.468561 
Train 5, loss: 3.888788
Start validation
Val 5, loss: 10.469188
Linear Accuracy (val): 0.59375
Start training epoch: (6/300)
Epoch (6), Batch(0/107), loss: 3.718467, imid loss: 0.426690, cmid loss: 3.291777 
Epoch (6), Batch(20/107), loss: 3.763677, imid loss: 0.407658, cmid loss: 3.356019 
Epoch (6), Batch(40/107), loss: 3.764581, imid loss: 0.404259, cmid loss: 3.360322 
Epoch (6), Batch(60/107), loss: 3.731938, imid loss: 0.400619, cmid loss: 3.331319 
Epoch (6), Batch(80/107), loss: 3.713373, imid loss: 0.401960, cmid loss: 3.311414 
Epoch (6), Batch(100/107), loss: 3.697698, imid loss: 0.398819, cmid loss: 3.298879 
Train 6, loss: 3.689085
Start validation
Val 6, loss: 10.674732
Linear Accuracy (val): 0.5911458333333334
Start training epoch: (7/300)
Epoch (7), Batch(0/107), loss: 3.690663, imid loss: 0.393267, cmid loss: 3.297397 
Epoch (7), Batch(20/107), loss: 3.521559, imid loss: 0.382537, cmid loss: 3.139021 
Epoch (7), Batch(40/107), loss: 3.558427, imid loss: 0.381787, cmid loss: 3.176640 
Epoch (7), Batch(60/107), loss: 3.530705, imid loss: 0.380870, cmid loss: 3.149835 
Epoch (7), Batch(80/107), loss: 3.509906, imid loss: 0.378832, cmid loss: 3.131074 
Epoch (7), Batch(100/107), loss: 3.488319, imid loss: 0.378260, cmid loss: 3.110059 
Train 7, loss: 3.489697
Start validation
Val 7, loss: 7.923393
Linear Accuracy (val): 0.5998263888888888
==> Saving Best Model...
Start training epoch: (8/300)
Epoch (8), Batch(0/107), loss: 3.485994, imid loss: 0.397445, cmid loss: 3.088549 
Epoch (8), Batch(20/107), loss: 3.436046, imid loss: 0.364359, cmid loss: 3.071687 
Epoch (8), Batch(40/107), loss: 3.405806, imid loss: 0.356988, cmid loss: 3.048818 
Epoch (8), Batch(60/107), loss: 3.387173, imid loss: 0.355970, cmid loss: 3.031203 
Epoch (8), Batch(80/107), loss: 3.377366, imid loss: 0.358116, cmid loss: 3.019251 
Epoch (8), Batch(100/107), loss: 3.374827, imid loss: 0.354991, cmid loss: 3.019835 
Train 8, loss: 3.373073
Start validation
Val 8, loss: 10.359168
Linear Accuracy (val): 0.5920138888888888
Start training epoch: (9/300)
Epoch (9), Batch(0/107), loss: 3.175262, imid loss: 0.333286, cmid loss: 2.841977 
Epoch (9), Batch(20/107), loss: 3.238535, imid loss: 0.345594, cmid loss: 2.892941 
Epoch (9), Batch(40/107), loss: 3.264702, imid loss: 0.344347, cmid loss: 2.920354 
Epoch (9), Batch(60/107), loss: 3.251931, imid loss: 0.345598, cmid loss: 2.906334 
Epoch (9), Batch(80/107), loss: 3.237818, imid loss: 0.343619, cmid loss: 2.894199 
Epoch (9), Batch(100/107), loss: 3.236608, imid loss: 0.343554, cmid loss: 2.893055 
Train 9, loss: 3.232996
Start validation
Val 9, loss: 9.458975
Linear Accuracy (val): 0.5998263888888888
Start training epoch: (10/300)
Epoch (10), Batch(0/107), loss: 3.161067, imid loss: 0.315447, cmid loss: 2.845620 
Epoch (10), Batch(20/107), loss: 3.135493, imid loss: 0.334831, cmid loss: 2.800662 
Epoch (10), Batch(40/107), loss: 3.167866, imid loss: 0.337050, cmid loss: 2.830816 
Epoch (10), Batch(60/107), loss: 3.164274, imid loss: 0.333075, cmid loss: 2.831199 
Epoch (10), Batch(80/107), loss: 3.161470, imid loss: 0.331717, cmid loss: 2.829754 
Epoch (10), Batch(100/107), loss: 3.157107, imid loss: 0.331229, cmid loss: 2.825879 
Train 10, loss: 3.161295
Start validation
Val 10, loss: 4.729492
Linear Accuracy (val): 0.6111111111111112
==> Saving Best Model...
==> Saving...
Start training epoch: (11/300)
Epoch (11), Batch(0/107), loss: 3.144199, imid loss: 0.324500, cmid loss: 2.819700 
Epoch (11), Batch(20/107), loss: 3.145764, imid loss: 0.325535, cmid loss: 2.820228 
Epoch (11), Batch(40/107), loss: 3.126923, imid loss: 0.327466, cmid loss: 2.799457 
Epoch (11), Batch(60/107), loss: 3.098896, imid loss: 0.326011, cmid loss: 2.772885 
Epoch (11), Batch(80/107), loss: 3.093454, imid loss: 0.324629, cmid loss: 2.768824 
Epoch (11), Batch(100/107), loss: 3.092206, imid loss: 0.324571, cmid loss: 2.767636 
Train 11, loss: 3.088434
Start validation
Val 11, loss: 8.812528
Linear Accuracy (val): 0.6076388888888888
Start training epoch: (12/300)
Epoch (12), Batch(0/107), loss: 2.843211, imid loss: 0.342102, cmid loss: 2.501109 
Epoch (12), Batch(20/107), loss: 3.053429, imid loss: 0.317397, cmid loss: 2.736032 
Epoch (12), Batch(40/107), loss: 3.054505, imid loss: 0.316957, cmid loss: 2.737548 
Epoch (12), Batch(60/107), loss: 3.042194, imid loss: 0.316362, cmid loss: 2.725833 
Epoch (12), Batch(80/107), loss: 3.047448, imid loss: 0.313606, cmid loss: 2.733841 
Epoch (12), Batch(100/107), loss: 3.034416, imid loss: 0.313945, cmid loss: 2.720471 
Train 12, loss: 3.030537
Start validation
Val 12, loss: 10.618297
Linear Accuracy (val): 0.5998263888888888
Start training epoch: (13/300)
Epoch (13), Batch(0/107), loss: 2.647051, imid loss: 0.308518, cmid loss: 2.338533 
Epoch (13), Batch(20/107), loss: 2.960326, imid loss: 0.298231, cmid loss: 2.662095 
Epoch (13), Batch(40/107), loss: 2.957047, imid loss: 0.302532, cmid loss: 2.654515 
Epoch (13), Batch(60/107), loss: 2.954255, imid loss: 0.303529, cmid loss: 2.650726 
Epoch (13), Batch(80/107), loss: 2.951649, imid loss: 0.303731, cmid loss: 2.647918 
Epoch (13), Batch(100/107), loss: 2.954849, imid loss: 0.305017, cmid loss: 2.649832 
Train 13, loss: 2.956308
Start validation
Val 13, loss: 9.215429
Linear Accuracy (val): 0.59375
Start training epoch: (14/300)
Epoch (14), Batch(0/107), loss: 2.742318, imid loss: 0.293938, cmid loss: 2.448380 
Epoch (14), Batch(20/107), loss: 2.949406, imid loss: 0.309736, cmid loss: 2.639670 
Epoch (14), Batch(40/107), loss: 2.915237, imid loss: 0.303978, cmid loss: 2.611258 
Epoch (14), Batch(60/107), loss: 2.901728, imid loss: 0.303307, cmid loss: 2.598422 
Epoch (14), Batch(80/107), loss: 2.882344, imid loss: 0.300676, cmid loss: 2.581667 
Epoch (14), Batch(100/107), loss: 2.872216, imid loss: 0.301056, cmid loss: 2.571160 
Train 14, loss: 2.873163
Start validation
Val 14, loss: 5.019198
Linear Accuracy (val): 0.6067708333333334
Start training epoch: (15/300)
Epoch (15), Batch(0/107), loss: 2.837138, imid loss: 0.316366, cmid loss: 2.520772 
Epoch (15), Batch(20/107), loss: 2.902327, imid loss: 0.302881, cmid loss: 2.599446 
Epoch (15), Batch(40/107), loss: 2.877051, imid loss: 0.293873, cmid loss: 2.583178 
Epoch (15), Batch(60/107), loss: 2.879368, imid loss: 0.289548, cmid loss: 2.589821 
Epoch (15), Batch(80/107), loss: 2.852276, imid loss: 0.291263, cmid loss: 2.561012 
Epoch (15), Batch(100/107), loss: 2.846688, imid loss: 0.288446, cmid loss: 2.558241 
Train 15, loss: 2.852596
Start validation
Val 15, loss: 4.883031
Linear Accuracy (val): 0.6076388888888888
Start training epoch: (16/300)
Epoch (16), Batch(0/107), loss: 2.777790, imid loss: 0.230037, cmid loss: 2.547752 
Epoch (16), Batch(20/107), loss: 2.829852, imid loss: 0.289373, cmid loss: 2.540479 
Epoch (16), Batch(40/107), loss: 2.800249, imid loss: 0.289507, cmid loss: 2.510742 
Epoch (16), Batch(60/107), loss: 2.804191, imid loss: 0.288355, cmid loss: 2.515836 
Epoch (16), Batch(80/107), loss: 2.811947, imid loss: 0.289607, cmid loss: 2.522339 
Epoch (16), Batch(100/107), loss: 2.814821, imid loss: 0.289357, cmid loss: 2.525464 
Train 16, loss: 2.815273
Start validation
Val 16, loss: 4.964457
Linear Accuracy (val): 0.6032986111111112
Start training epoch: (17/300)
Epoch (17), Batch(0/107), loss: 2.708555, imid loss: 0.261613, cmid loss: 2.446942 
Epoch (17), Batch(20/107), loss: 2.769503, imid loss: 0.289677, cmid loss: 2.479826 
Epoch (17), Batch(40/107), loss: 2.728489, imid loss: 0.283135, cmid loss: 2.445355 
Epoch (17), Batch(60/107), loss: 2.712832, imid loss: 0.282371, cmid loss: 2.430460 
Epoch (17), Batch(80/107), loss: 2.707214, imid loss: 0.283146, cmid loss: 2.424069 
Epoch (17), Batch(100/107), loss: 2.712892, imid loss: 0.285796, cmid loss: 2.427096 
Train 17, loss: 2.709544
Start validation
Val 17, loss: 8.677836
Linear Accuracy (val): 0.6076388888888888
Start training epoch: (18/300)
Epoch (18), Batch(0/107), loss: 2.735760, imid loss: 0.280652, cmid loss: 2.455108 
Epoch (18), Batch(20/107), loss: 2.683424, imid loss: 0.272228, cmid loss: 2.411196 
Epoch (18), Batch(40/107), loss: 2.716488, imid loss: 0.283131, cmid loss: 2.433356 
Epoch (18), Batch(60/107), loss: 2.716924, imid loss: 0.281785, cmid loss: 2.435139 
Epoch (18), Batch(80/107), loss: 2.708086, imid loss: 0.282553, cmid loss: 2.425533 
Epoch (18), Batch(100/107), loss: 2.706437, imid loss: 0.282612, cmid loss: 2.423825 
Train 18, loss: 2.710549
Start validation
Val 18, loss: 3.719278
Linear Accuracy (val): 0.6085069444444444
Start training epoch: (19/300)
Epoch (19), Batch(0/107), loss: 2.563096, imid loss: 0.238126, cmid loss: 2.324970 
Epoch (19), Batch(20/107), loss: 2.640109, imid loss: 0.276353, cmid loss: 2.363756 
Epoch (19), Batch(40/107), loss: 2.641814, imid loss: 0.277593, cmid loss: 2.364220 
Epoch (19), Batch(60/107), loss: 2.637253, imid loss: 0.277614, cmid loss: 2.359639 
Epoch (19), Batch(80/107), loss: 2.634775, imid loss: 0.277860, cmid loss: 2.356915 
Epoch (19), Batch(100/107), loss: 2.637244, imid loss: 0.278241, cmid loss: 2.359003 
Train 19, loss: 2.634455
Start validation
Val 19, loss: 4.517068
Linear Accuracy (val): 0.6119791666666666
==> Saving Best Model...
Start training epoch: (20/300)
Epoch (20), Batch(0/107), loss: 2.696922, imid loss: 0.305746, cmid loss: 2.391176 
Epoch (20), Batch(20/107), loss: 2.638459, imid loss: 0.270232, cmid loss: 2.368227 
Epoch (20), Batch(40/107), loss: 2.603423, imid loss: 0.268540, cmid loss: 2.334883 
Epoch (20), Batch(60/107), loss: 2.602789, imid loss: 0.272027, cmid loss: 2.330762 
Epoch (20), Batch(80/107), loss: 2.640725, imid loss: 0.270253, cmid loss: 2.370472 
Epoch (20), Batch(100/107), loss: 2.655492, imid loss: 0.269780, cmid loss: 2.385712 
Train 20, loss: 2.653078
Start validation
Val 20, loss: 9.357565
Linear Accuracy (val): 0.6041666666666666
==> Saving...
Start training epoch: (21/300)
Epoch (21), Batch(0/107), loss: 2.649427, imid loss: 0.264314, cmid loss: 2.385113 
Epoch (21), Batch(20/107), loss: 2.664722, imid loss: 0.271210, cmid loss: 2.393512 
Epoch (21), Batch(40/107), loss: 2.614254, imid loss: 0.266762, cmid loss: 2.347491 
Epoch (21), Batch(60/107), loss: 2.619601, imid loss: 0.267923, cmid loss: 2.351679 
Epoch (21), Batch(80/107), loss: 2.613083, imid loss: 0.269059, cmid loss: 2.344023 
Epoch (21), Batch(100/107), loss: 2.611282, imid loss: 0.268947, cmid loss: 2.342335 
Train 21, loss: 2.612266
Start validation
Val 21, loss: 3.552794
Linear Accuracy (val): 0.6154513888888888
==> Saving Best Model...
Start training epoch: (22/300)
Epoch (22), Batch(0/107), loss: 2.690285, imid loss: 0.290965, cmid loss: 2.399320 
Epoch (22), Batch(20/107), loss: 2.601750, imid loss: 0.265818, cmid loss: 2.335932 
Epoch (22), Batch(40/107), loss: 2.595042, imid loss: 0.269338, cmid loss: 2.325704 
Epoch (22), Batch(60/107), loss: 2.571870, imid loss: 0.265890, cmid loss: 2.305980 
Epoch (22), Batch(80/107), loss: 2.590421, imid loss: 0.266653, cmid loss: 2.323768 
Epoch (22), Batch(100/107), loss: 2.593825, imid loss: 0.266017, cmid loss: 2.327808 
Train 22, loss: 2.586907
Start validation
Val 22, loss: 10.830354
Linear Accuracy (val): 0.6119791666666666
Start training epoch: (23/300)
Epoch (23), Batch(0/107), loss: 2.441386, imid loss: 0.293299, cmid loss: 2.148086 
Epoch (23), Batch(20/107), loss: 2.514693, imid loss: 0.268205, cmid loss: 2.246488 
Epoch (23), Batch(40/107), loss: 2.504981, imid loss: 0.258579, cmid loss: 2.246402 
Epoch (23), Batch(60/107), loss: 2.479509, imid loss: 0.257847, cmid loss: 2.221662 
Epoch (23), Batch(80/107), loss: 2.477134, imid loss: 0.256503, cmid loss: 2.220631 
Epoch (23), Batch(100/107), loss: 2.490942, imid loss: 0.258892, cmid loss: 2.232051 
Train 23, loss: 2.491924
Start validation
Val 23, loss: 9.639917
Linear Accuracy (val): 0.6111111111111112
Start training epoch: (24/300)
Epoch (24), Batch(0/107), loss: 2.340526, imid loss: 0.279670, cmid loss: 2.060856 
Epoch (24), Batch(20/107), loss: 2.468906, imid loss: 0.253784, cmid loss: 2.215122 
Epoch (24), Batch(40/107), loss: 2.454066, imid loss: 0.253045, cmid loss: 2.201021 
Epoch (24), Batch(60/107), loss: 2.475397, imid loss: 0.257727, cmid loss: 2.217670 
Epoch (24), Batch(80/107), loss: 2.480107, imid loss: 0.258875, cmid loss: 2.221232 
Epoch (24), Batch(100/107), loss: 2.472073, imid loss: 0.257855, cmid loss: 2.214218 
Train 24, loss: 2.471743
Start validation
Val 24, loss: 8.034373
Linear Accuracy (val): 0.6102430555555556
Start training epoch: (25/300)
Epoch (25), Batch(0/107), loss: 2.041967, imid loss: 0.251469, cmid loss: 1.790498 
Epoch (25), Batch(20/107), loss: 2.443908, imid loss: 0.256651, cmid loss: 2.187257 
Epoch (25), Batch(40/107), loss: 2.428292, imid loss: 0.257390, cmid loss: 2.170902 
Epoch (25), Batch(60/107), loss: 2.448287, imid loss: 0.257832, cmid loss: 2.190455 
Epoch (25), Batch(80/107), loss: 2.447590, imid loss: 0.256843, cmid loss: 2.190747 
Epoch (25), Batch(100/107), loss: 2.451558, imid loss: 0.257816, cmid loss: 2.193742 
Train 25, loss: 2.453559
Start validation
Val 25, loss: 10.143593
Linear Accuracy (val): 0.5989583333333334
Start training epoch: (26/300)
Epoch (26), Batch(0/107), loss: 2.334277, imid loss: 0.273619, cmid loss: 2.060658 
Epoch (26), Batch(20/107), loss: 2.446121, imid loss: 0.254701, cmid loss: 2.191419 
Epoch (26), Batch(40/107), loss: 2.438959, imid loss: 0.249967, cmid loss: 2.188993 
Epoch (26), Batch(60/107), loss: 2.438599, imid loss: 0.253817, cmid loss: 2.184782 
Epoch (26), Batch(80/107), loss: 2.434858, imid loss: 0.254424, cmid loss: 2.180434 
Epoch (26), Batch(100/107), loss: 2.429871, imid loss: 0.252901, cmid loss: 2.176969 
Train 26, loss: 2.424745
Start validation
Val 26, loss: 12.359197
Linear Accuracy (val): 0.6050347222222222
Start training epoch: (27/300)
Epoch (27), Batch(0/107), loss: 2.253415, imid loss: 0.266904, cmid loss: 1.986511 
Epoch (27), Batch(20/107), loss: 2.380984, imid loss: 0.249010, cmid loss: 2.131974 
Epoch (27), Batch(40/107), loss: 2.374516, imid loss: 0.250093, cmid loss: 2.124423 
Epoch (27), Batch(60/107), loss: 2.358091, imid loss: 0.250791, cmid loss: 2.107300 
Epoch (27), Batch(80/107), loss: 2.372068, imid loss: 0.251183, cmid loss: 2.120885 
Epoch (27), Batch(100/107), loss: 2.378928, imid loss: 0.251313, cmid loss: 2.127615 
Train 27, loss: 2.380777
Start validation
Val 27, loss: 4.058792
Linear Accuracy (val): 0.6215277777777778
==> Saving Best Model...
Start training epoch: (28/300)
Epoch (28), Batch(0/107), loss: 2.354392, imid loss: 0.234806, cmid loss: 2.119586 
Epoch (28), Batch(20/107), loss: 2.373612, imid loss: 0.250662, cmid loss: 2.122951 
Epoch (28), Batch(40/107), loss: 2.369769, imid loss: 0.249616, cmid loss: 2.120152 
Epoch (28), Batch(60/107), loss: 2.355375, imid loss: 0.246217, cmid loss: 2.109158 
Epoch (28), Batch(80/107), loss: 2.354302, imid loss: 0.247028, cmid loss: 2.107274 
Epoch (28), Batch(100/107), loss: 2.350049, imid loss: 0.245840, cmid loss: 2.104209 
Train 28, loss: 2.348316
Start validation
Val 28, loss: 11.294956
Linear Accuracy (val): 0.6050347222222222
Start training epoch: (29/300)
Epoch (29), Batch(0/107), loss: 2.474768, imid loss: 0.238187, cmid loss: 2.236581 
Epoch (29), Batch(20/107), loss: 2.341112, imid loss: 0.252556, cmid loss: 2.088556 
Epoch (29), Batch(40/107), loss: 2.346655, imid loss: 0.249982, cmid loss: 2.096672 
Epoch (29), Batch(60/107), loss: 2.344845, imid loss: 0.246444, cmid loss: 2.098402 
Epoch (29), Batch(80/107), loss: 2.333804, imid loss: 0.249060, cmid loss: 2.084744 
Epoch (29), Batch(100/107), loss: 2.332314, imid loss: 0.246718, cmid loss: 2.085596 
Train 29, loss: 2.334660
Start validation
Val 29, loss: 10.695297
Linear Accuracy (val): 0.5998263888888888
Start training epoch: (30/300)
Epoch (30), Batch(0/107), loss: 2.511478, imid loss: 0.262881, cmid loss: 2.248597 
Epoch (30), Batch(20/107), loss: 2.376625, imid loss: 0.248503, cmid loss: 2.128122 
Epoch (30), Batch(40/107), loss: 2.354498, imid loss: 0.247886, cmid loss: 2.106612 
Epoch (30), Batch(60/107), loss: 2.323151, imid loss: 0.247633, cmid loss: 2.075518 
Epoch (30), Batch(80/107), loss: 2.319263, imid loss: 0.248113, cmid loss: 2.071150 
Epoch (30), Batch(100/107), loss: 2.317261, imid loss: 0.247914, cmid loss: 2.069347 
Train 30, loss: 2.317425
Start validation
Val 30, loss: 11.246003
Linear Accuracy (val): 0.6015625
==> Saving...
Start training epoch: (31/300)
Epoch (31), Batch(0/107), loss: 2.216296, imid loss: 0.234805, cmid loss: 1.981491 
Epoch (31), Batch(20/107), loss: 2.268185, imid loss: 0.246130, cmid loss: 2.022055 
Epoch (31), Batch(40/107), loss: 2.276909, imid loss: 0.241111, cmid loss: 2.035798 
Epoch (31), Batch(60/107), loss: 2.291020, imid loss: 0.244707, cmid loss: 2.046313 
Epoch (31), Batch(80/107), loss: 2.282977, imid loss: 0.242767, cmid loss: 2.040210 
Epoch (31), Batch(100/107), loss: 2.289898, imid loss: 0.242719, cmid loss: 2.047179 
Train 31, loss: 2.289866
Start validation
Val 31, loss: 11.714860
Linear Accuracy (val): 0.6180555555555556
Start training epoch: (32/300)
Epoch (32), Batch(0/107), loss: 2.352706, imid loss: 0.263994, cmid loss: 2.088712 
Epoch (32), Batch(20/107), loss: 2.214642, imid loss: 0.238863, cmid loss: 1.975779 
Epoch (32), Batch(40/107), loss: 2.233078, imid loss: 0.240905, cmid loss: 1.992174 
Epoch (32), Batch(60/107), loss: 2.248591, imid loss: 0.241156, cmid loss: 2.007435 
Epoch (32), Batch(80/107), loss: 2.267970, imid loss: 0.243705, cmid loss: 2.024264 
Epoch (32), Batch(100/107), loss: 2.267458, imid loss: 0.243272, cmid loss: 2.024186 
Train 32, loss: 2.260173
Start validation
Val 32, loss: 9.474702
Linear Accuracy (val): 0.6032986111111112
Start training epoch: (33/300)
Epoch (33), Batch(0/107), loss: 2.280514, imid loss: 0.248446, cmid loss: 2.032067 
Epoch (33), Batch(20/107), loss: 2.235430, imid loss: 0.242066, cmid loss: 1.993364 
Epoch (33), Batch(40/107), loss: 2.242415, imid loss: 0.249027, cmid loss: 1.993389 
Epoch (33), Batch(60/107), loss: 2.248462, imid loss: 0.245045, cmid loss: 2.003417 
Epoch (33), Batch(80/107), loss: 2.253505, imid loss: 0.243162, cmid loss: 2.010343 
Epoch (33), Batch(100/107), loss: 2.256677, imid loss: 0.243275, cmid loss: 2.013402 
Train 33, loss: 2.255735
Start validation
Val 33, loss: 10.674136
Linear Accuracy (val): 0.5859375
Start training epoch: (34/300)
Epoch (34), Batch(0/107), loss: 2.295074, imid loss: 0.221703, cmid loss: 2.073371 
Epoch (34), Batch(20/107), loss: 2.173375, imid loss: 0.226266, cmid loss: 1.947109 
Epoch (34), Batch(40/107), loss: 2.205426, imid loss: 0.232056, cmid loss: 1.973370 
Epoch (34), Batch(60/107), loss: 2.210231, imid loss: 0.233609, cmid loss: 1.976622 
Epoch (34), Batch(80/107), loss: 2.219202, imid loss: 0.236058, cmid loss: 1.983144 
Epoch (34), Batch(100/107), loss: 2.221279, imid loss: 0.237163, cmid loss: 1.984116 
Train 34, loss: 2.216079
Start validation
Val 34, loss: 10.612808
Linear Accuracy (val): 0.609375
Start training epoch: (35/300)
Epoch (35), Batch(0/107), loss: 2.363371, imid loss: 0.207827, cmid loss: 2.155543 
Epoch (35), Batch(20/107), loss: 2.245565, imid loss: 0.238526, cmid loss: 2.007039 
Epoch (35), Batch(40/107), loss: 2.225766, imid loss: 0.236458, cmid loss: 1.989309 
Epoch (35), Batch(60/107), loss: 2.233772, imid loss: 0.237301, cmid loss: 1.996470 
Epoch (35), Batch(80/107), loss: 2.223690, imid loss: 0.235367, cmid loss: 1.988323 
Epoch (35), Batch(100/107), loss: 2.218958, imid loss: 0.235754, cmid loss: 1.983204 
Train 35, loss: 2.217671
Start validation
Val 35, loss: 10.153641
Linear Accuracy (val): 0.6041666666666666
Start training epoch: (36/300)
Epoch (36), Batch(0/107), loss: 2.019382, imid loss: 0.232620, cmid loss: 1.786761 
Epoch (36), Batch(20/107), loss: 2.199870, imid loss: 0.235403, cmid loss: 1.964467 
Epoch (36), Batch(40/107), loss: 2.170128, imid loss: 0.236510, cmid loss: 1.933618 
Epoch (36), Batch(60/107), loss: 2.162091, imid loss: 0.233363, cmid loss: 1.928728 
Epoch (36), Batch(80/107), loss: 2.183538, imid loss: 0.233436, cmid loss: 1.950103 
Epoch (36), Batch(100/107), loss: 2.197328, imid loss: 0.233746, cmid loss: 1.963581 
Train 36, loss: 2.198489
Start validation
Val 36, loss: 10.718503
Linear Accuracy (val): 0.5920138888888888
Start training epoch: (37/300)
Epoch (37), Batch(0/107), loss: 2.340779, imid loss: 0.241677, cmid loss: 2.099102 
Epoch (37), Batch(20/107), loss: 2.225915, imid loss: 0.232182, cmid loss: 1.993733 
Epoch (37), Batch(40/107), loss: 2.217005, imid loss: 0.235232, cmid loss: 1.981773 
Epoch (37), Batch(60/107), loss: 2.178130, imid loss: 0.231210, cmid loss: 1.946920 
Epoch (37), Batch(80/107), loss: 2.181472, imid loss: 0.231719, cmid loss: 1.949752 
Epoch (37), Batch(100/107), loss: 2.173318, imid loss: 0.232463, cmid loss: 1.940854 
Train 37, loss: 2.174635
Start validation
Val 37, loss: 3.226417
Linear Accuracy (val): 0.6128472222222222
Start training epoch: (38/300)
Epoch (38), Batch(0/107), loss: 2.205564, imid loss: 0.224520, cmid loss: 1.981043 
Epoch (38), Batch(20/107), loss: 2.125074, imid loss: 0.233180, cmid loss: 1.891894 
Epoch (38), Batch(40/107), loss: 2.126935, imid loss: 0.231293, cmid loss: 1.895642 
Epoch (38), Batch(60/107), loss: 2.128761, imid loss: 0.228428, cmid loss: 1.900333 
Epoch (38), Batch(80/107), loss: 2.126777, imid loss: 0.228229, cmid loss: 1.898548 
Epoch (38), Batch(100/107), loss: 2.123450, imid loss: 0.228659, cmid loss: 1.894791 
Train 38, loss: 2.120167
Start validation
Val 38, loss: 4.195092
Linear Accuracy (val): 0.6189236111111112
Start training epoch: (39/300)
Epoch (39), Batch(0/107), loss: 2.230632, imid loss: 0.257355, cmid loss: 1.973277 
Epoch (39), Batch(20/107), loss: 2.132089, imid loss: 0.233701, cmid loss: 1.898388 
Epoch (39), Batch(40/107), loss: 2.133350, imid loss: 0.231310, cmid loss: 1.902040 
Epoch (39), Batch(60/107), loss: 2.116091, imid loss: 0.230358, cmid loss: 1.885734 
Epoch (39), Batch(80/107), loss: 2.107075, imid loss: 0.226859, cmid loss: 1.880216 
Epoch (39), Batch(100/107), loss: 2.113188, imid loss: 0.227751, cmid loss: 1.885438 
Train 39, loss: 2.108389
Start validation
Val 39, loss: 9.198709
Linear Accuracy (val): 0.6050347222222222
Start training epoch: (40/300)
Epoch (40), Batch(0/107), loss: 2.082275, imid loss: 0.213154, cmid loss: 1.869121 
Epoch (40), Batch(20/107), loss: 2.092142, imid loss: 0.234287, cmid loss: 1.857855 
Epoch (40), Batch(40/107), loss: 2.113598, imid loss: 0.232739, cmid loss: 1.880859 
Epoch (40), Batch(60/107), loss: 2.125246, imid loss: 0.231132, cmid loss: 1.894114 
Epoch (40), Batch(80/107), loss: 2.126765, imid loss: 0.231788, cmid loss: 1.894977 
Epoch (40), Batch(100/107), loss: 2.110991, imid loss: 0.229563, cmid loss: 1.881428 
Train 40, loss: 2.108356
Start validation
Val 40, loss: 3.583792
Linear Accuracy (val): 0.6128472222222222
==> Saving...
Start training epoch: (41/300)
Epoch (41), Batch(0/107), loss: 2.272578, imid loss: 0.226415, cmid loss: 2.046164 
Epoch (41), Batch(20/107), loss: 2.068023, imid loss: 0.216597, cmid loss: 1.851426 
Epoch (41), Batch(40/107), loss: 2.090002, imid loss: 0.221099, cmid loss: 1.868903 
Epoch (41), Batch(60/107), loss: 2.087812, imid loss: 0.221157, cmid loss: 1.866655 
Epoch (41), Batch(80/107), loss: 2.095424, imid loss: 0.225071, cmid loss: 1.870353 
Epoch (41), Batch(100/107), loss: 2.099580, imid loss: 0.226626, cmid loss: 1.872954 
Train 41, loss: 2.102692
Start validation
Val 41, loss: 8.124985
Linear Accuracy (val): 0.6137152777777778
Start training epoch: (42/300)
Epoch (42), Batch(0/107), loss: 2.124220, imid loss: 0.257353, cmid loss: 1.866868 
Epoch (42), Batch(20/107), loss: 2.045709, imid loss: 0.218562, cmid loss: 1.827147 
Epoch (42), Batch(40/107), loss: 2.067398, imid loss: 0.217341, cmid loss: 1.850057 
Epoch (42), Batch(60/107), loss: 2.080992, imid loss: 0.221016, cmid loss: 1.859976 
Epoch (42), Batch(80/107), loss: 2.083054, imid loss: 0.222902, cmid loss: 1.860152 
Epoch (42), Batch(100/107), loss: 2.087879, imid loss: 0.223791, cmid loss: 1.864089 
Train 42, loss: 2.083750
Start validation
Val 42, loss: 9.476240
Linear Accuracy (val): 0.6076388888888888
Start training epoch: (43/300)
Epoch (43), Batch(0/107), loss: 2.077765, imid loss: 0.251433, cmid loss: 1.826332 
Epoch (43), Batch(20/107), loss: 2.089320, imid loss: 0.225702, cmid loss: 1.863618 
Epoch (43), Batch(40/107), loss: 2.088543, imid loss: 0.223624, cmid loss: 1.864919 
Epoch (43), Batch(60/107), loss: 2.073860, imid loss: 0.221844, cmid loss: 1.852015 
Epoch (43), Batch(80/107), loss: 2.061614, imid loss: 0.222899, cmid loss: 1.838715 
Epoch (43), Batch(100/107), loss: 2.062408, imid loss: 0.224399, cmid loss: 1.838009 
Train 43, loss: 2.065022
Start validation
Val 43, loss: 8.192810
Linear Accuracy (val): 0.6102430555555556
Start training epoch: (44/300)
Epoch (44), Batch(0/107), loss: 2.196260, imid loss: 0.228599, cmid loss: 1.967661 
Epoch (44), Batch(20/107), loss: 2.084382, imid loss: 0.226818, cmid loss: 1.857564 
Epoch (44), Batch(40/107), loss: 2.070581, imid loss: 0.223089, cmid loss: 1.847492 
Epoch (44), Batch(60/107), loss: 2.059990, imid loss: 0.223316, cmid loss: 1.836673 
Epoch (44), Batch(80/107), loss: 2.049283, imid loss: 0.223853, cmid loss: 1.825430 
Epoch (44), Batch(100/107), loss: 2.040702, imid loss: 0.221328, cmid loss: 1.819374 
Train 44, loss: 2.037789
Start validation
Val 44, loss: 8.670314
Linear Accuracy (val): 0.6102430555555556
Start training epoch: (45/300)
Epoch (45), Batch(0/107), loss: 2.050888, imid loss: 0.216798, cmid loss: 1.834090 
Epoch (45), Batch(20/107), loss: 1.966821, imid loss: 0.210921, cmid loss: 1.755900 
Epoch (45), Batch(40/107), loss: 1.981911, imid loss: 0.218009, cmid loss: 1.763902 
Epoch (45), Batch(60/107), loss: 1.987873, imid loss: 0.217089, cmid loss: 1.770784 
Epoch (45), Batch(80/107), loss: 1.999180, imid loss: 0.217986, cmid loss: 1.781194 
Epoch (45), Batch(100/107), loss: 2.001067, imid loss: 0.218955, cmid loss: 1.782112 
Train 45, loss: 2.003061
Start validation
Val 45, loss: 9.061285
Linear Accuracy (val): 0.6111111111111112
Start training epoch: (46/300)
Epoch (46), Batch(0/107), loss: 1.868136, imid loss: 0.186086, cmid loss: 1.682051 
Epoch (46), Batch(20/107), loss: 2.014354, imid loss: 0.222600, cmid loss: 1.791754 
Epoch (46), Batch(40/107), loss: 2.028718, imid loss: 0.224927, cmid loss: 1.803792 
Epoch (46), Batch(60/107), loss: 2.038706, imid loss: 0.223331, cmid loss: 1.815376 
Epoch (46), Batch(80/107), loss: 2.035347, imid loss: 0.222995, cmid loss: 1.812353 
Epoch (46), Batch(100/107), loss: 2.038435, imid loss: 0.222248, cmid loss: 1.816187 
Train 46, loss: 2.035352
Start validation
Val 46, loss: 9.851046
Linear Accuracy (val): 0.5963541666666666
Start training epoch: (47/300)
Epoch (47), Batch(0/107), loss: 1.999566, imid loss: 0.210351, cmid loss: 1.789215 
Epoch (47), Batch(20/107), loss: 1.978052, imid loss: 0.220411, cmid loss: 1.757640 
Epoch (47), Batch(40/107), loss: 2.004680, imid loss: 0.219154, cmid loss: 1.785526 
Epoch (47), Batch(60/107), loss: 1.997641, imid loss: 0.215993, cmid loss: 1.781648 
Epoch (47), Batch(80/107), loss: 2.000905, imid loss: 0.218519, cmid loss: 1.782386 
Epoch (47), Batch(100/107), loss: 2.010825, imid loss: 0.220163, cmid loss: 1.790662 
Train 47, loss: 2.009787
Start validation
Val 47, loss: 9.814977
Linear Accuracy (val): 0.6059027777777778
Start training epoch: (48/300)
Epoch (48), Batch(0/107), loss: 1.867073, imid loss: 0.210032, cmid loss: 1.657041 
Epoch (48), Batch(20/107), loss: 1.999493, imid loss: 0.220772, cmid loss: 1.778721 
Epoch (48), Batch(40/107), loss: 1.984769, imid loss: 0.217036, cmid loss: 1.767732 
Epoch (48), Batch(60/107), loss: 1.996643, imid loss: 0.218266, cmid loss: 1.778378 
Epoch (48), Batch(80/107), loss: 2.013496, imid loss: 0.220916, cmid loss: 1.792580 
Epoch (48), Batch(100/107), loss: 2.010067, imid loss: 0.220459, cmid loss: 1.789608 
Train 48, loss: 2.010971
Start validation
Val 48, loss: 9.996835
Linear Accuracy (val): 0.6032986111111112
Start training epoch: (49/300)
Epoch (49), Batch(0/107), loss: 2.099500, imid loss: 0.194862, cmid loss: 1.904638 
Epoch (49), Batch(20/107), loss: 1.947777, imid loss: 0.209890, cmid loss: 1.737886 
Epoch (49), Batch(40/107), loss: 1.948457, imid loss: 0.212280, cmid loss: 1.736177 
Epoch (49), Batch(60/107), loss: 1.953195, imid loss: 0.214021, cmid loss: 1.739174 
Epoch (49), Batch(80/107), loss: 1.966302, imid loss: 0.213572, cmid loss: 1.752729 
Epoch (49), Batch(100/107), loss: 1.969976, imid loss: 0.213318, cmid loss: 1.756657 
Train 49, loss: 1.968616
Start validation
Val 49, loss: 9.890149
Linear Accuracy (val): 0.6085069444444444
Start training epoch: (50/300)
Epoch (50), Batch(0/107), loss: 1.934762, imid loss: 0.193515, cmid loss: 1.741246 
Epoch (50), Batch(20/107), loss: 1.995559, imid loss: 0.214741, cmid loss: 1.780817 
Epoch (50), Batch(40/107), loss: 1.957488, imid loss: 0.212312, cmid loss: 1.745176 
Epoch (50), Batch(60/107), loss: 1.967693, imid loss: 0.212532, cmid loss: 1.755161 
Epoch (50), Batch(80/107), loss: 1.969312, imid loss: 0.215493, cmid loss: 1.753819 
Epoch (50), Batch(100/107), loss: 1.968377, imid loss: 0.214785, cmid loss: 1.753592 
Train 50, loss: 1.968576
Start validation
Val 50, loss: 9.305087
Linear Accuracy (val): 0.6180555555555556
==> Saving...
Start training epoch: (51/300)
/home/kithmini.herath/codes/CrossPoint/vis_utils.py:29: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`). Consider using `matplotlib.pyplot.close()`.
  plt.figure()
Epoch (51), Batch(0/107), loss: 1.881303, imid loss: 0.257443, cmid loss: 1.623860 
Epoch (51), Batch(20/107), loss: 1.957825, imid loss: 0.219954, cmid loss: 1.737871 
Epoch (51), Batch(40/107), loss: 1.966668, imid loss: 0.217602, cmid loss: 1.749066 
Epoch (51), Batch(60/107), loss: 1.957700, imid loss: 0.215150, cmid loss: 1.742550 
Epoch (51), Batch(80/107), loss: 1.964447, imid loss: 0.213157, cmid loss: 1.751290 
Epoch (51), Batch(100/107), loss: 1.967937, imid loss: 0.214797, cmid loss: 1.753141 
Train 51, loss: 1.969176
Start validation
Val 51, loss: 10.756460
Linear Accuracy (val): 0.6024305555555556
Start training epoch: (52/300)
Epoch (52), Batch(0/107), loss: 2.068975, imid loss: 0.211272, cmid loss: 1.857702 
Epoch (52), Batch(20/107), loss: 1.917581, imid loss: 0.204992, cmid loss: 1.712589 
Epoch (52), Batch(40/107), loss: 1.934193, imid loss: 0.203323, cmid loss: 1.730871 
Epoch (52), Batch(60/107), loss: 1.942364, imid loss: 0.209890, cmid loss: 1.732474 
Epoch (52), Batch(80/107), loss: 1.947584, imid loss: 0.210773, cmid loss: 1.736810 
Epoch (52), Batch(100/107), loss: 1.934983, imid loss: 0.210273, cmid loss: 1.724710 
Train 52, loss: 1.935782
Start validation
Val 52, loss: 10.121692
Linear Accuracy (val): 0.6032986111111112
Start training epoch: (53/300)
Epoch (53), Batch(0/107), loss: 2.121351, imid loss: 0.217166, cmid loss: 1.904185 
Epoch (53), Batch(20/107), loss: 1.962275, imid loss: 0.216605, cmid loss: 1.745670 
Epoch (53), Batch(40/107), loss: 1.936769, imid loss: 0.211080, cmid loss: 1.725689 
Epoch (53), Batch(60/107), loss: 1.950118, imid loss: 0.212804, cmid loss: 1.737315 
Epoch (53), Batch(80/107), loss: 1.937918, imid loss: 0.212818, cmid loss: 1.725100 
Epoch (53), Batch(100/107), loss: 1.942007, imid loss: 0.212706, cmid loss: 1.729301 
Train 53, loss: 1.937039
Start validation
Val 53, loss: 9.506890
Linear Accuracy (val): 0.6032986111111112
Start training epoch: (54/300)
Epoch (54), Batch(0/107), loss: 1.903238, imid loss: 0.165502, cmid loss: 1.737735 
Epoch (54), Batch(20/107), loss: 1.950257, imid loss: 0.210325, cmid loss: 1.739932 
Epoch (54), Batch(40/107), loss: 1.947400, imid loss: 0.212603, cmid loss: 1.734797 
Epoch (54), Batch(60/107), loss: 1.923084, imid loss: 0.209826, cmid loss: 1.713258 
Epoch (54), Batch(80/107), loss: 1.911630, imid loss: 0.208803, cmid loss: 1.702827 
Epoch (54), Batch(100/107), loss: 1.915273, imid loss: 0.209211, cmid loss: 1.706062 
Train 54, loss: 1.911102
Start validation
Val 54, loss: 10.177137
Linear Accuracy (val): 0.6041666666666666
Start training epoch: (55/300)
Epoch (55), Batch(0/107), loss: 1.750199, imid loss: 0.182239, cmid loss: 1.567959 
Epoch (55), Batch(20/107), loss: 1.892162, imid loss: 0.208652, cmid loss: 1.683510 
Epoch (55), Batch(40/107), loss: 1.918913, imid loss: 0.209717, cmid loss: 1.709197 
Epoch (55), Batch(60/107), loss: 1.912325, imid loss: 0.211013, cmid loss: 1.701313 
Epoch (55), Batch(80/107), loss: 1.908394, imid loss: 0.211469, cmid loss: 1.696925 
Epoch (55), Batch(100/107), loss: 1.907460, imid loss: 0.211319, cmid loss: 1.696142 
Train 55, loss: 1.905327
Start validation
Val 55, loss: 10.930336
Linear Accuracy (val): 0.6128472222222222
Start training epoch: (56/300)
Epoch (56), Batch(0/107), loss: 1.911191, imid loss: 0.200826, cmid loss: 1.710365 
Epoch (56), Batch(20/107), loss: 1.857138, imid loss: 0.207862, cmid loss: 1.649275 
Epoch (56), Batch(40/107), loss: 1.875804, imid loss: 0.210885, cmid loss: 1.664919 
Epoch (56), Batch(60/107), loss: 1.886336, imid loss: 0.206420, cmid loss: 1.679916 
Epoch (56), Batch(80/107), loss: 1.885050, imid loss: 0.205243, cmid loss: 1.679807 
Epoch (56), Batch(100/107), loss: 1.881786, imid loss: 0.205404, cmid loss: 1.676382 
Train 56, loss: 1.877654
Start validation
Val 56, loss: 9.761125
Linear Accuracy (val): 0.6215277777777778
Start training epoch: (57/300)
Epoch (57), Batch(0/107), loss: 1.751314, imid loss: 0.201171, cmid loss: 1.550143 
Epoch (57), Batch(20/107), loss: 1.922481, imid loss: 0.205303, cmid loss: 1.717177 
Epoch (57), Batch(40/107), loss: 1.905550, imid loss: 0.206075, cmid loss: 1.699475 
Epoch (57), Batch(60/107), loss: 1.893503, imid loss: 0.204857, cmid loss: 1.688647 
Epoch (57), Batch(80/107), loss: 1.888434, imid loss: 0.203867, cmid loss: 1.684567 
Epoch (57), Batch(100/107), loss: 1.885691, imid loss: 0.205179, cmid loss: 1.680511 
Train 57, loss: 1.886413
Start validation
Val 57, loss: 10.438789
Linear Accuracy (val): 0.6015625
Start training epoch: (58/300)
Epoch (58), Batch(0/107), loss: 2.113940, imid loss: 0.203257, cmid loss: 1.910684 
Epoch (58), Batch(20/107), loss: 1.901063, imid loss: 0.204323, cmid loss: 1.696740 
Epoch (58), Batch(40/107), loss: 1.892931, imid loss: 0.208100, cmid loss: 1.684832 
Epoch (58), Batch(60/107), loss: 1.881551, imid loss: 0.205601, cmid loss: 1.675950 
Epoch (58), Batch(80/107), loss: 1.884551, imid loss: 0.205577, cmid loss: 1.678973 
Epoch (58), Batch(100/107), loss: 1.868189, imid loss: 0.206518, cmid loss: 1.661672 
Train 58, loss: 1.867552
Start validation
Val 58, loss: 10.352926
Linear Accuracy (val): 0.6085069444444444
Start training epoch: (59/300)
Epoch (59), Batch(0/107), loss: 2.058786, imid loss: 0.216411, cmid loss: 1.842375 
Epoch (59), Batch(20/107), loss: 1.857508, imid loss: 0.203203, cmid loss: 1.654304 
Epoch (59), Batch(40/107), loss: 1.829092, imid loss: 0.201825, cmid loss: 1.627267 
Epoch (59), Batch(60/107), loss: 1.825121, imid loss: 0.201778, cmid loss: 1.623343 
Epoch (59), Batch(80/107), loss: 1.843483, imid loss: 0.204190, cmid loss: 1.639293 
Epoch (59), Batch(100/107), loss: 1.837700, imid loss: 0.203853, cmid loss: 1.633847 
Train 59, loss: 1.841375
Start validation
Val 59, loss: 10.509445
Linear Accuracy (val): 0.6059027777777778
Start training epoch: (60/300)
Epoch (60), Batch(0/107), loss: 2.051304, imid loss: 0.178307, cmid loss: 1.872997 
Epoch (60), Batch(20/107), loss: 1.862487, imid loss: 0.196486, cmid loss: 1.666001 
Epoch (60), Batch(40/107), loss: 1.840826, imid loss: 0.200388, cmid loss: 1.640439 
Epoch (60), Batch(60/107), loss: 1.826681, imid loss: 0.200676, cmid loss: 1.626005 
Epoch (60), Batch(80/107), loss: 1.827169, imid loss: 0.200880, cmid loss: 1.626289 
Epoch (60), Batch(100/107), loss: 1.827914, imid loss: 0.199714, cmid loss: 1.628200 
Train 60, loss: 1.835219
Start validation
Val 60, loss: 11.022161
Linear Accuracy (val): 0.6171875
==> Saving...
Start training epoch: (61/300)
Epoch (61), Batch(0/107), loss: 1.905618, imid loss: 0.177328, cmid loss: 1.728290 
Epoch (61), Batch(20/107), loss: 1.820012, imid loss: 0.196640, cmid loss: 1.623372 
Epoch (61), Batch(40/107), loss: 1.839135, imid loss: 0.199067, cmid loss: 1.640069 
Epoch (61), Batch(60/107), loss: 1.840008, imid loss: 0.199068, cmid loss: 1.640941 
Epoch (61), Batch(80/107), loss: 1.836241, imid loss: 0.199952, cmid loss: 1.636289 
Epoch (61), Batch(100/107), loss: 1.822780, imid loss: 0.199453, cmid loss: 1.623327 
Train 61, loss: 1.819351
Start validation
Val 61, loss: 10.181355
Linear Accuracy (val): 0.5946180555555556
Start training epoch: (62/300)
Epoch (62), Batch(0/107), loss: 1.851454, imid loss: 0.187861, cmid loss: 1.663593 
Epoch (62), Batch(20/107), loss: 1.834042, imid loss: 0.198368, cmid loss: 1.635674 
Epoch (62), Batch(40/107), loss: 1.810149, imid loss: 0.194285, cmid loss: 1.615864 
Epoch (62), Batch(60/107), loss: 1.817449, imid loss: 0.194484, cmid loss: 1.622965 
Epoch (62), Batch(80/107), loss: 1.806139, imid loss: 0.195708, cmid loss: 1.610430 
Epoch (62), Batch(100/107), loss: 1.817444, imid loss: 0.197151, cmid loss: 1.620293 
Train 62, loss: 1.817252
Start validation
Val 62, loss: 11.376656
Linear Accuracy (val): 0.6059027777777778
Start training epoch: (63/300)
Epoch (63), Batch(0/107), loss: 1.782762, imid loss: 0.190953, cmid loss: 1.591809 
Epoch (63), Batch(20/107), loss: 1.784805, imid loss: 0.195721, cmid loss: 1.589084 
Epoch (63), Batch(40/107), loss: 1.804621, imid loss: 0.201241, cmid loss: 1.603381 
Epoch (63), Batch(60/107), loss: 1.807783, imid loss: 0.199625, cmid loss: 1.608159 
Epoch (63), Batch(80/107), loss: 1.808777, imid loss: 0.198830, cmid loss: 1.609947 
Epoch (63), Batch(100/107), loss: 1.818581, imid loss: 0.198979, cmid loss: 1.619602 
Train 63, loss: 1.816291
Start validation
Val 63, loss: 9.990916
Linear Accuracy (val): 0.6024305555555556
Start training epoch: (64/300)
Epoch (64), Batch(0/107), loss: 1.565154, imid loss: 0.183553, cmid loss: 1.381601 
Epoch (64), Batch(20/107), loss: 1.803550, imid loss: 0.191872, cmid loss: 1.611678 
Epoch (64), Batch(40/107), loss: 1.829932, imid loss: 0.195333, cmid loss: 1.634599 
Epoch (64), Batch(60/107), loss: 1.802665, imid loss: 0.197140, cmid loss: 1.605525 
Epoch (64), Batch(80/107), loss: 1.798157, imid loss: 0.194073, cmid loss: 1.604084 
Epoch (64), Batch(100/107), loss: 1.801003, imid loss: 0.196770, cmid loss: 1.604233 
Train 64, loss: 1.804160
Start validation
Val 64, loss: 4.739175
Linear Accuracy (val): 0.6163194444444444
Start training epoch: (65/300)
Epoch (65), Batch(0/107), loss: 1.835414, imid loss: 0.205203, cmid loss: 1.630211 
Epoch (65), Batch(20/107), loss: 1.779529, imid loss: 0.192885, cmid loss: 1.586644 
Epoch (65), Batch(40/107), loss: 1.774784, imid loss: 0.193127, cmid loss: 1.581657 
Epoch (65), Batch(60/107), loss: 1.767961, imid loss: 0.194624, cmid loss: 1.573337 
Epoch (65), Batch(80/107), loss: 1.776235, imid loss: 0.198576, cmid loss: 1.577659 
Epoch (65), Batch(100/107), loss: 1.774952, imid loss: 0.195675, cmid loss: 1.579277 
Train 65, loss: 1.776095
Start validation
Val 65, loss: 8.513818
Linear Accuracy (val): 0.6085069444444444
Start training epoch: (66/300)
Epoch (66), Batch(0/107), loss: 1.829958, imid loss: 0.234927, cmid loss: 1.595031 
Epoch (66), Batch(20/107), loss: 1.791992, imid loss: 0.196065, cmid loss: 1.595926 
Epoch (66), Batch(40/107), loss: 1.799857, imid loss: 0.196703, cmid loss: 1.603154 
Epoch (66), Batch(60/107), loss: 1.807272, imid loss: 0.196688, cmid loss: 1.610584 
Epoch (66), Batch(80/107), loss: 1.805915, imid loss: 0.195168, cmid loss: 1.610747 
Epoch (66), Batch(100/107), loss: 1.804747, imid loss: 0.193492, cmid loss: 1.611255 
Train 66, loss: 1.806179
Start validation
Val 66, loss: 10.255680
Linear Accuracy (val): 0.5972222222222222
Start training epoch: (67/300)
Epoch (67), Batch(0/107), loss: 1.834772, imid loss: 0.168016, cmid loss: 1.666755 
Epoch (67), Batch(20/107), loss: 1.774173, imid loss: 0.184504, cmid loss: 1.589669 
Epoch (67), Batch(40/107), loss: 1.788216, imid loss: 0.190691, cmid loss: 1.597525 
Epoch (67), Batch(60/107), loss: 1.802828, imid loss: 0.195130, cmid loss: 1.607698 
Epoch (67), Batch(80/107), loss: 1.802418, imid loss: 0.195231, cmid loss: 1.607187 
Epoch (67), Batch(100/107), loss: 1.802956, imid loss: 0.194934, cmid loss: 1.608022 
Train 67, loss: 1.797160
Start validation
Val 67, loss: 10.796510
Linear Accuracy (val): 0.6111111111111112
Start training epoch: (68/300)
Epoch (68), Batch(0/107), loss: 1.775664, imid loss: 0.173305, cmid loss: 1.602359 
Epoch (68), Batch(20/107), loss: 1.736744, imid loss: 0.183261, cmid loss: 1.553483 
Epoch (68), Batch(40/107), loss: 1.760965, imid loss: 0.187693, cmid loss: 1.573271 
Epoch (68), Batch(60/107), loss: 1.777211, imid loss: 0.191799, cmid loss: 1.585411 
Epoch (68), Batch(80/107), loss: 1.780519, imid loss: 0.192561, cmid loss: 1.587958 
Epoch (68), Batch(100/107), loss: 1.778724, imid loss: 0.192846, cmid loss: 1.585879 
Train 68, loss: 1.779667
Start validation
Val 68, loss: 9.720962
Linear Accuracy (val): 0.6041666666666666
Start training epoch: (69/300)
Epoch (69), Batch(0/107), loss: 1.623116, imid loss: 0.204992, cmid loss: 1.418123 
Epoch (69), Batch(20/107), loss: 1.766262, imid loss: 0.199296, cmid loss: 1.566966 
Epoch (69), Batch(40/107), loss: 1.769379, imid loss: 0.197738, cmid loss: 1.571642 
Epoch (69), Batch(60/107), loss: 1.758234, imid loss: 0.196031, cmid loss: 1.562204 
Epoch (69), Batch(80/107), loss: 1.761424, imid loss: 0.193763, cmid loss: 1.567661 
Epoch (69), Batch(100/107), loss: 1.761242, imid loss: 0.193421, cmid loss: 1.567821 
Train 69, loss: 1.760512
Start validation
Val 69, loss: 9.363532
Linear Accuracy (val): 0.5963541666666666
Start training epoch: (70/300)
Epoch (70), Batch(0/107), loss: 1.671224, imid loss: 0.184025, cmid loss: 1.487200 
Epoch (70), Batch(20/107), loss: 1.750989, imid loss: 0.184889, cmid loss: 1.566100 
Epoch (70), Batch(40/107), loss: 1.752318, imid loss: 0.186380, cmid loss: 1.565938 
Epoch (70), Batch(60/107), loss: 1.766036, imid loss: 0.188014, cmid loss: 1.578022 
Epoch (70), Batch(80/107), loss: 1.760091, imid loss: 0.189668, cmid loss: 1.570423 
Epoch (70), Batch(100/107), loss: 1.760333, imid loss: 0.189235, cmid loss: 1.571098 
Train 70, loss: 1.761076
Start validation
Val 70, loss: 11.019051
Linear Accuracy (val): 0.6163194444444444
==> Saving...
Start training epoch: (71/300)
Epoch (71), Batch(0/107), loss: 1.639532, imid loss: 0.171475, cmid loss: 1.468058 
Epoch (71), Batch(20/107), loss: 1.807840, imid loss: 0.197581, cmid loss: 1.610259 
Epoch (71), Batch(40/107), loss: 1.798234, imid loss: 0.196784, cmid loss: 1.601449 
Epoch (71), Batch(60/107), loss: 1.774781, imid loss: 0.193279, cmid loss: 1.581502 
Epoch (71), Batch(80/107), loss: 1.769953, imid loss: 0.193590, cmid loss: 1.576363 
Epoch (71), Batch(100/107), loss: 1.768648, imid loss: 0.192752, cmid loss: 1.575896 
Train 71, loss: 1.763470
Start validation
Val 71, loss: 10.186518
Linear Accuracy (val): 0.6067708333333334
Start training epoch: (72/300)
Epoch (72), Batch(0/107), loss: 1.638047, imid loss: 0.183458, cmid loss: 1.454589 
Epoch (72), Batch(20/107), loss: 1.693202, imid loss: 0.187279, cmid loss: 1.505922 
Epoch (72), Batch(40/107), loss: 1.732693, imid loss: 0.191568, cmid loss: 1.541125 
Epoch (72), Batch(60/107), loss: 1.744713, imid loss: 0.194258, cmid loss: 1.550455 
Epoch (72), Batch(80/107), loss: 1.732536, imid loss: 0.193393, cmid loss: 1.539143 
Epoch (72), Batch(100/107), loss: 1.728350, imid loss: 0.192385, cmid loss: 1.535964 
Train 72, loss: 1.728049
Start validation
Val 72, loss: 8.780441
Linear Accuracy (val): 0.6197916666666666
Start training epoch: (73/300)
Epoch (73), Batch(0/107), loss: 1.745877, imid loss: 0.173844, cmid loss: 1.572033 
Epoch (73), Batch(20/107), loss: 1.735795, imid loss: 0.189934, cmid loss: 1.545861 
Epoch (73), Batch(40/107), loss: 1.722553, imid loss: 0.192235, cmid loss: 1.530318 
Epoch (73), Batch(60/107), loss: 1.718800, imid loss: 0.190842, cmid loss: 1.527958 
Epoch (73), Batch(80/107), loss: 1.717881, imid loss: 0.189113, cmid loss: 1.528768 
Epoch (73), Batch(100/107), loss: 1.715550, imid loss: 0.187698, cmid loss: 1.527852 
Train 73, loss: 1.722580
Start validation
Val 73, loss: 5.023404
Linear Accuracy (val): 0.6006944444444444
Start training epoch: (74/300)
Epoch (74), Batch(0/107), loss: 1.565136, imid loss: 0.173935, cmid loss: 1.391201 
Epoch (74), Batch(20/107), loss: 1.754283, imid loss: 0.191000, cmid loss: 1.563283 
Epoch (74), Batch(40/107), loss: 1.738750, imid loss: 0.189514, cmid loss: 1.549236 
Epoch (74), Batch(60/107), loss: 1.725213, imid loss: 0.191806, cmid loss: 1.533407 
Epoch (74), Batch(80/107), loss: 1.719953, imid loss: 0.189802, cmid loss: 1.530151 
Epoch (74), Batch(100/107), loss: 1.715886, imid loss: 0.190383, cmid loss: 1.525504 
Train 74, loss: 1.712408
Start validation
Val 74, loss: 9.413593
Linear Accuracy (val): 0.6102430555555556
Start training epoch: (75/300)
Epoch (75), Batch(0/107), loss: 1.859697, imid loss: 0.186899, cmid loss: 1.672799 
Epoch (75), Batch(20/107), loss: 1.743090, imid loss: 0.186527, cmid loss: 1.556564 
Epoch (75), Batch(40/107), loss: 1.720477, imid loss: 0.187107, cmid loss: 1.533370 
Epoch (75), Batch(60/107), loss: 1.703199, imid loss: 0.187724, cmid loss: 1.515475 
Epoch (75), Batch(80/107), loss: 1.707536, imid loss: 0.187893, cmid loss: 1.519643 
Epoch (75), Batch(100/107), loss: 1.703677, imid loss: 0.187883, cmid loss: 1.515793 
Train 75, loss: 1.709610
Start validation
Val 75, loss: 4.349611
Linear Accuracy (val): 0.6111111111111112
Start training epoch: (76/300)
Epoch (76), Batch(0/107), loss: 1.711512, imid loss: 0.188352, cmid loss: 1.523161 
Epoch (76), Batch(20/107), loss: 1.694266, imid loss: 0.190818, cmid loss: 1.503448 
Epoch (76), Batch(40/107), loss: 1.691692, imid loss: 0.188456, cmid loss: 1.503237 
Epoch (76), Batch(60/107), loss: 1.691657, imid loss: 0.187760, cmid loss: 1.503897 
Epoch (76), Batch(80/107), loss: 1.678863, imid loss: 0.185005, cmid loss: 1.493857 
Epoch (76), Batch(100/107), loss: 1.684203, imid loss: 0.184752, cmid loss: 1.499451 
Train 76, loss: 1.686558
Start validation
Val 76, loss: 9.657385
Linear Accuracy (val): 0.6006944444444444
Start training epoch: (77/300)
Epoch (77), Batch(0/107), loss: 1.821695, imid loss: 0.218419, cmid loss: 1.603276 
Epoch (77), Batch(20/107), loss: 1.668751, imid loss: 0.182346, cmid loss: 1.486405 
Epoch (77), Batch(40/107), loss: 1.684966, imid loss: 0.183833, cmid loss: 1.501133 
Epoch (77), Batch(60/107), loss: 1.678970, imid loss: 0.181266, cmid loss: 1.497705 
Epoch (77), Batch(80/107), loss: 1.681597, imid loss: 0.183068, cmid loss: 1.498529 
Epoch (77), Batch(100/107), loss: 1.684004, imid loss: 0.184761, cmid loss: 1.499244 
Train 77, loss: 1.682836
Start validation
Val 77, loss: 10.087071
Linear Accuracy (val): 0.6111111111111112
Start training epoch: (78/300)
Epoch (78), Batch(0/107), loss: 1.979890, imid loss: 0.189214, cmid loss: 1.790676 
Epoch (78), Batch(20/107), loss: 1.710178, imid loss: 0.183106, cmid loss: 1.527072 
Epoch (78), Batch(40/107), loss: 1.712548, imid loss: 0.185128, cmid loss: 1.527420 
Epoch (78), Batch(60/107), loss: 1.698052, imid loss: 0.183108, cmid loss: 1.514944 
Epoch (78), Batch(80/107), loss: 1.698449, imid loss: 0.183508, cmid loss: 1.514941 
Epoch (78), Batch(100/107), loss: 1.693352, imid loss: 0.183174, cmid loss: 1.510177 
Train 78, loss: 1.696937
Start validation
Val 78, loss: 9.958564
Linear Accuracy (val): 0.6041666666666666
Start training epoch: (79/300)
Epoch (79), Batch(0/107), loss: 1.745299, imid loss: 0.182025, cmid loss: 1.563274 
Epoch (79), Batch(20/107), loss: 1.670988, imid loss: 0.185286, cmid loss: 1.485702 
Epoch (79), Batch(40/107), loss: 1.677998, imid loss: 0.181656, cmid loss: 1.496342 
Epoch (79), Batch(60/107), loss: 1.683019, imid loss: 0.185710, cmid loss: 1.497309 
Epoch (79), Batch(80/107), loss: 1.685454, imid loss: 0.186920, cmid loss: 1.498534 
Epoch (79), Batch(100/107), loss: 1.678895, imid loss: 0.186474, cmid loss: 1.492421 
Train 79, loss: 1.675636
Start validation
Val 79, loss: 10.266493
Linear Accuracy (val): 0.6111111111111112
Start training epoch: (80/300)
Epoch (80), Batch(0/107), loss: 1.674840, imid loss: 0.197516, cmid loss: 1.477324 
Epoch (80), Batch(20/107), loss: 1.682109, imid loss: 0.184345, cmid loss: 1.497764 
Epoch (80), Batch(40/107), loss: 1.672350, imid loss: 0.181894, cmid loss: 1.490456 
Epoch (80), Batch(60/107), loss: 1.673882, imid loss: 0.183492, cmid loss: 1.490389 
Epoch (80), Batch(80/107), loss: 1.677895, imid loss: 0.182193, cmid loss: 1.495702 
Epoch (80), Batch(100/107), loss: 1.672759, imid loss: 0.182209, cmid loss: 1.490550 
Train 80, loss: 1.673288
Start validation
Val 80, loss: 11.082987
Linear Accuracy (val): 0.5946180555555556
==> Saving...
Start training epoch: (81/300)
Epoch (81), Batch(0/107), loss: 1.640689, imid loss: 0.147015, cmid loss: 1.493674 
Epoch (81), Batch(20/107), loss: 1.622348, imid loss: 0.175331, cmid loss: 1.447017 
Epoch (81), Batch(40/107), loss: 1.636418, imid loss: 0.175750, cmid loss: 1.460669 
Epoch (81), Batch(60/107), loss: 1.634280, imid loss: 0.178762, cmid loss: 1.455518 
Epoch (81), Batch(80/107), loss: 1.639956, imid loss: 0.180408, cmid loss: 1.459548 
Epoch (81), Batch(100/107), loss: 1.642926, imid loss: 0.181270, cmid loss: 1.461656 
Train 81, loss: 1.642666
Start validation
Val 81, loss: 11.133275
Linear Accuracy (val): 0.6032986111111112
Start training epoch: (82/300)
Epoch (82), Batch(0/107), loss: 1.656055, imid loss: 0.184489, cmid loss: 1.471566 
Epoch (82), Batch(20/107), loss: 1.657132, imid loss: 0.181327, cmid loss: 1.475806 
Epoch (82), Batch(40/107), loss: 1.656886, imid loss: 0.184932, cmid loss: 1.471954 
Epoch (82), Batch(60/107), loss: 1.639624, imid loss: 0.185863, cmid loss: 1.453761 
Epoch (82), Batch(80/107), loss: 1.651621, imid loss: 0.184690, cmid loss: 1.466931 
Epoch (82), Batch(100/107), loss: 1.640226, imid loss: 0.182629, cmid loss: 1.457598 
Train 82, loss: 1.641503
Start validation
Val 82, loss: 10.517906
Linear Accuracy (val): 0.6050347222222222
Start training epoch: (83/300)
Epoch (83), Batch(0/107), loss: 1.467445, imid loss: 0.143360, cmid loss: 1.324085 
Epoch (83), Batch(20/107), loss: 1.647692, imid loss: 0.178598, cmid loss: 1.469094 
Epoch (83), Batch(40/107), loss: 1.647485, imid loss: 0.181620, cmid loss: 1.465865 
Epoch (83), Batch(60/107), loss: 1.657044, imid loss: 0.182797, cmid loss: 1.474248 
Epoch (83), Batch(80/107), loss: 1.648229, imid loss: 0.182076, cmid loss: 1.466153 
Epoch (83), Batch(100/107), loss: 1.655770, imid loss: 0.181869, cmid loss: 1.473900 
Train 83, loss: 1.654226
Start validation
Val 83, loss: 9.777568
Linear Accuracy (val): 0.6119791666666666
Start training epoch: (84/300)
Epoch (84), Batch(0/107), loss: 1.748133, imid loss: 0.178876, cmid loss: 1.569257 
Epoch (84), Batch(20/107), loss: 1.654898, imid loss: 0.174625, cmid loss: 1.480273 
Epoch (84), Batch(40/107), loss: 1.647536, imid loss: 0.175488, cmid loss: 1.472048 
Epoch (84), Batch(60/107), loss: 1.657078, imid loss: 0.174883, cmid loss: 1.482195 
Epoch (84), Batch(80/107), loss: 1.655727, imid loss: 0.175892, cmid loss: 1.479835 
Epoch (84), Batch(100/107), loss: 1.651125, imid loss: 0.176819, cmid loss: 1.474306 
Train 84, loss: 1.650414
Start validation
Val 84, loss: 9.827691
Linear Accuracy (val): 0.6067708333333334
Start training epoch: (85/300)
Epoch (85), Batch(0/107), loss: 1.555672, imid loss: 0.186549, cmid loss: 1.369123 
Epoch (85), Batch(20/107), loss: 1.630200, imid loss: 0.183056, cmid loss: 1.447145 
Epoch (85), Batch(40/107), loss: 1.611140, imid loss: 0.178728, cmid loss: 1.432412 
Epoch (85), Batch(60/107), loss: 1.634673, imid loss: 0.178636, cmid loss: 1.456037 
Epoch (85), Batch(80/107), loss: 1.642500, imid loss: 0.178104, cmid loss: 1.464395 
Epoch (85), Batch(100/107), loss: 1.654129, imid loss: 0.178919, cmid loss: 1.475210 
Train 85, loss: 1.652725
Start validation
Val 85, loss: 10.976192
Linear Accuracy (val): 0.5928819444444444
Start training epoch: (86/300)
Epoch (86), Batch(0/107), loss: 1.678420, imid loss: 0.166417, cmid loss: 1.512003 
Epoch (86), Batch(20/107), loss: 1.636874, imid loss: 0.183662, cmid loss: 1.453212 
Epoch (86), Batch(40/107), loss: 1.626889, imid loss: 0.183062, cmid loss: 1.443827 
Epoch (86), Batch(60/107), loss: 1.623502, imid loss: 0.179010, cmid loss: 1.444492 
Epoch (86), Batch(80/107), loss: 1.619038, imid loss: 0.178349, cmid loss: 1.440689 
Epoch (86), Batch(100/107), loss: 1.609509, imid loss: 0.176576, cmid loss: 1.432932 
Train 86, loss: 1.611566
Start validation
Val 86, loss: 9.773923
Linear Accuracy (val): 0.6024305555555556
Start training epoch: (87/300)
Epoch (87), Batch(0/107), loss: 1.806410, imid loss: 0.179207, cmid loss: 1.627203 
Epoch (87), Batch(20/107), loss: 1.613119, imid loss: 0.176549, cmid loss: 1.436570 
Epoch (87), Batch(40/107), loss: 1.611657, imid loss: 0.178438, cmid loss: 1.433220 
Epoch (87), Batch(60/107), loss: 1.621120, imid loss: 0.178195, cmid loss: 1.442925 
Epoch (87), Batch(80/107), loss: 1.625091, imid loss: 0.177986, cmid loss: 1.447105 
Epoch (87), Batch(100/107), loss: 1.632732, imid loss: 0.179509, cmid loss: 1.453222 
Train 87, loss: 1.631543
Start validation
Val 87, loss: 10.880013
Linear Accuracy (val): 0.6206597222222222
Start training epoch: (88/300)
Epoch (88), Batch(0/107), loss: 1.580730, imid loss: 0.170056, cmid loss: 1.410675 
Epoch (88), Batch(20/107), loss: 1.556404, imid loss: 0.173120, cmid loss: 1.383284 
Epoch (88), Batch(40/107), loss: 1.582919, imid loss: 0.174131, cmid loss: 1.408788 
Epoch (88), Batch(60/107), loss: 1.583456, imid loss: 0.175297, cmid loss: 1.408158 
Epoch (88), Batch(80/107), loss: 1.589605, imid loss: 0.175525, cmid loss: 1.414080 
Epoch (88), Batch(100/107), loss: 1.594939, imid loss: 0.175990, cmid loss: 1.418950 
Train 88, loss: 1.592598
Start validation
Val 88, loss: 10.765342
Linear Accuracy (val): 0.6032986111111112
Start training epoch: (89/300)
Epoch (89), Batch(0/107), loss: 1.621214, imid loss: 0.188737, cmid loss: 1.432476 
Epoch (89), Batch(20/107), loss: 1.602552, imid loss: 0.176345, cmid loss: 1.426207 
Epoch (89), Batch(40/107), loss: 1.601677, imid loss: 0.174354, cmid loss: 1.427323 
Epoch (89), Batch(60/107), loss: 1.605061, imid loss: 0.177120, cmid loss: 1.427940 
Epoch (89), Batch(80/107), loss: 1.595413, imid loss: 0.176698, cmid loss: 1.418715 
Epoch (89), Batch(100/107), loss: 1.593135, imid loss: 0.177452, cmid loss: 1.415683 
Train 89, loss: 1.593628
Start validation
Val 89, loss: 10.355390
Linear Accuracy (val): 0.5902777777777778
Start training epoch: (90/300)
Epoch (90), Batch(0/107), loss: 1.624822, imid loss: 0.167850, cmid loss: 1.456972 
Epoch (90), Batch(20/107), loss: 1.638072, imid loss: 0.178161, cmid loss: 1.459910 
Epoch (90), Batch(40/107), loss: 1.620755, imid loss: 0.177511, cmid loss: 1.443244 
Epoch (90), Batch(60/107), loss: 1.611140, imid loss: 0.178672, cmid loss: 1.432468 
Epoch (90), Batch(80/107), loss: 1.610014, imid loss: 0.177888, cmid loss: 1.432127 
Epoch (90), Batch(100/107), loss: 1.603173, imid loss: 0.176536, cmid loss: 1.426637 
Train 90, loss: 1.602958
Start validation
Val 90, loss: 9.521284
Linear Accuracy (val): 0.6059027777777778
==> Saving...
Start training epoch: (91/300)
Epoch (91), Batch(0/107), loss: 1.547397, imid loss: 0.156355, cmid loss: 1.391042 
Epoch (91), Batch(20/107), loss: 1.603042, imid loss: 0.170865, cmid loss: 1.432177 
Epoch (91), Batch(40/107), loss: 1.599428, imid loss: 0.172527, cmid loss: 1.426901 
Epoch (91), Batch(60/107), loss: 1.598850, imid loss: 0.173428, cmid loss: 1.425422 
Epoch (91), Batch(80/107), loss: 1.602775, imid loss: 0.175684, cmid loss: 1.427091 
Epoch (91), Batch(100/107), loss: 1.599191, imid loss: 0.175082, cmid loss: 1.424109 
Train 91, loss: 1.600219
Start validation
Val 91, loss: 10.587416
Linear Accuracy (val): 0.6024305555555556
Start training epoch: (92/300)
Epoch (92), Batch(0/107), loss: 1.656429, imid loss: 0.203548, cmid loss: 1.452881 
Epoch (92), Batch(20/107), loss: 1.574509, imid loss: 0.179100, cmid loss: 1.395409 
Epoch (92), Batch(40/107), loss: 1.592753, imid loss: 0.179743, cmid loss: 1.413011 
Epoch (92), Batch(60/107), loss: 1.577675, imid loss: 0.177257, cmid loss: 1.400418 
Epoch (92), Batch(80/107), loss: 1.590791, imid loss: 0.178701, cmid loss: 1.412089 
Epoch (92), Batch(100/107), loss: 1.587800, imid loss: 0.177860, cmid loss: 1.409940 
Train 92, loss: 1.592493
Start validation
Val 92, loss: 7.645791
Linear Accuracy (val): 0.6119791666666666
Start training epoch: (93/300)
Epoch (93), Batch(0/107), loss: 1.529591, imid loss: 0.188872, cmid loss: 1.340719 
Epoch (93), Batch(20/107), loss: 1.558613, imid loss: 0.175454, cmid loss: 1.383158 
Epoch (93), Batch(40/107), loss: 1.592947, imid loss: 0.175489, cmid loss: 1.417458 
Epoch (93), Batch(60/107), loss: 1.591381, imid loss: 0.175322, cmid loss: 1.416059 
Epoch (93), Batch(80/107), loss: 1.589460, imid loss: 0.174023, cmid loss: 1.415437 
Epoch (93), Batch(100/107), loss: 1.583547, imid loss: 0.171803, cmid loss: 1.411744 
Train 93, loss: 1.582523
Start validation
Val 93, loss: 12.209751
Linear Accuracy (val): 0.5946180555555556
Start training epoch: (94/300)
Epoch (94), Batch(0/107), loss: 1.742701, imid loss: 0.162607, cmid loss: 1.580094 
Epoch (94), Batch(20/107), loss: 1.574160, imid loss: 0.167194, cmid loss: 1.406966 
Epoch (94), Batch(40/107), loss: 1.574331, imid loss: 0.172932, cmid loss: 1.401399 
Epoch (94), Batch(60/107), loss: 1.564356, imid loss: 0.173372, cmid loss: 1.390984 
Epoch (94), Batch(80/107), loss: 1.553204, imid loss: 0.171210, cmid loss: 1.381994 
Epoch (94), Batch(100/107), loss: 1.559154, imid loss: 0.171755, cmid loss: 1.387398 
Train 94, loss: 1.561334
Start validation
Val 94, loss: 9.621337
Linear Accuracy (val): 0.6041666666666666
Start training epoch: (95/300)
Epoch (95), Batch(0/107), loss: 1.414049, imid loss: 0.159538, cmid loss: 1.254511 
Epoch (95), Batch(20/107), loss: 1.536536, imid loss: 0.171756, cmid loss: 1.364780 
Epoch (95), Batch(40/107), loss: 1.563513, imid loss: 0.173813, cmid loss: 1.389700 
Epoch (95), Batch(60/107), loss: 1.565201, imid loss: 0.172585, cmid loss: 1.392616 
Epoch (95), Batch(80/107), loss: 1.565656, imid loss: 0.175138, cmid loss: 1.390518 
Epoch (95), Batch(100/107), loss: 1.574402, imid loss: 0.174028, cmid loss: 1.400374 
Train 95, loss: 1.577170
Start validation
Val 95, loss: 9.203137
Linear Accuracy (val): 0.6085069444444444
Start training epoch: (96/300)
Epoch (96), Batch(0/107), loss: 1.442242, imid loss: 0.162838, cmid loss: 1.279404 
Epoch (96), Batch(20/107), loss: 1.583453, imid loss: 0.172623, cmid loss: 1.410830 
Epoch (96), Batch(40/107), loss: 1.561152, imid loss: 0.170253, cmid loss: 1.390899 
Epoch (96), Batch(60/107), loss: 1.543362, imid loss: 0.169951, cmid loss: 1.373411 
Epoch (96), Batch(80/107), loss: 1.534522, imid loss: 0.170557, cmid loss: 1.363965 
Epoch (96), Batch(100/107), loss: 1.539577, imid loss: 0.169777, cmid loss: 1.369801 
Train 96, loss: 1.539842
Start validation
Val 96, loss: 5.580211
Linear Accuracy (val): 0.59375
Start training epoch: (97/300)
Epoch (97), Batch(0/107), loss: 1.551929, imid loss: 0.172386, cmid loss: 1.379543 
Epoch (97), Batch(20/107), loss: 1.575349, imid loss: 0.178175, cmid loss: 1.397174 
Epoch (97), Batch(40/107), loss: 1.575655, imid loss: 0.174909, cmid loss: 1.400747 
Epoch (97), Batch(60/107), loss: 1.584229, imid loss: 0.175104, cmid loss: 1.409126 
Epoch (97), Batch(80/107), loss: 1.586967, imid loss: 0.176308, cmid loss: 1.410659 
Epoch (97), Batch(100/107), loss: 1.580743, imid loss: 0.176404, cmid loss: 1.404339 
Train 97, loss: 1.577167
Start validation
Val 97, loss: 10.617398
Linear Accuracy (val): 0.6059027777777778
Start training epoch: (98/300)
Epoch (98), Batch(0/107), loss: 1.664437, imid loss: 0.201002, cmid loss: 1.463435 
Epoch (98), Batch(20/107), loss: 1.551702, imid loss: 0.173759, cmid loss: 1.377943 
Epoch (98), Batch(40/107), loss: 1.539342, imid loss: 0.166543, cmid loss: 1.372799 
Epoch (98), Batch(60/107), loss: 1.535511, imid loss: 0.165497, cmid loss: 1.370014 
Epoch (98), Batch(80/107), loss: 1.544051, imid loss: 0.167747, cmid loss: 1.376304 
Epoch (98), Batch(100/107), loss: 1.545841, imid loss: 0.168079, cmid loss: 1.377763 
Train 98, loss: 1.548819
Start validation
Val 98, loss: 11.827726
Linear Accuracy (val): 0.6059027777777778
Start training epoch: (99/300)
Epoch (99), Batch(0/107), loss: 1.705954, imid loss: 0.200327, cmid loss: 1.505627 
Epoch (99), Batch(20/107), loss: 1.574023, imid loss: 0.180268, cmid loss: 1.393755 
Epoch (99), Batch(40/107), loss: 1.556294, imid loss: 0.174186, cmid loss: 1.382108 
Epoch (99), Batch(60/107), loss: 1.540921, imid loss: 0.173314, cmid loss: 1.367607 
Epoch (99), Batch(80/107), loss: 1.540604, imid loss: 0.171706, cmid loss: 1.368898 
Epoch (99), Batch(100/107), loss: 1.552417, imid loss: 0.172503, cmid loss: 1.379915 
Train 99, loss: 1.550022
Start validation
Val 99, loss: 10.638873
Linear Accuracy (val): 0.609375
Start training epoch: (100/300)
Epoch (100), Batch(0/107), loss: 1.676766, imid loss: 0.188591, cmid loss: 1.488175 
Epoch (100), Batch(20/107), loss: 1.524400, imid loss: 0.169921, cmid loss: 1.354479 
Epoch (100), Batch(40/107), loss: 1.534124, imid loss: 0.172043, cmid loss: 1.362081 
Epoch (100), Batch(60/107), loss: 1.542119, imid loss: 0.170774, cmid loss: 1.371345 
Epoch (100), Batch(80/107), loss: 1.544358, imid loss: 0.172096, cmid loss: 1.372262 
Epoch (100), Batch(100/107), loss: 1.538995, imid loss: 0.171685, cmid loss: 1.367310 
Train 100, loss: 1.538705
Start validation
Val 100, loss: 10.749927
Linear Accuracy (val): 0.6085069444444444
==> Saving...
Start training epoch: (101/300)
Epoch (101), Batch(0/107), loss: 1.712125, imid loss: 0.191175, cmid loss: 1.520950 
Epoch (101), Batch(20/107), loss: 1.513179, imid loss: 0.171359, cmid loss: 1.341820 
Epoch (101), Batch(40/107), loss: 1.510304, imid loss: 0.170774, cmid loss: 1.339530 
Epoch (101), Batch(60/107), loss: 1.530368, imid loss: 0.168664, cmid loss: 1.361704 
Epoch (101), Batch(80/107), loss: 1.536415, imid loss: 0.168568, cmid loss: 1.367847 
Epoch (101), Batch(100/107), loss: 1.540683, imid loss: 0.167870, cmid loss: 1.372813 
Train 101, loss: 1.540892
Start validation
Val 101, loss: 9.676514
Linear Accuracy (val): 0.6032986111111112
Start training epoch: (102/300)
Epoch (102), Batch(0/107), loss: 1.305200, imid loss: 0.127886, cmid loss: 1.177314 
Epoch (102), Batch(20/107), loss: 1.575798, imid loss: 0.166234, cmid loss: 1.409564 
Epoch (102), Batch(40/107), loss: 1.565927, imid loss: 0.170195, cmid loss: 1.395732 
Epoch (102), Batch(60/107), loss: 1.536040, imid loss: 0.170444, cmid loss: 1.365596 
Epoch (102), Batch(80/107), loss: 1.528542, imid loss: 0.167748, cmid loss: 1.360794 
Epoch (102), Batch(100/107), loss: 1.527562, imid loss: 0.167260, cmid loss: 1.360302 
Train 102, loss: 1.524149
Start validation
Val 102, loss: 9.966344
Linear Accuracy (val): 0.6015625
Start training epoch: (103/300)
Epoch (103), Batch(0/107), loss: 1.553549, imid loss: 0.158356, cmid loss: 1.395192 
Epoch (103), Batch(20/107), loss: 1.523123, imid loss: 0.167696, cmid loss: 1.355428 
Epoch (103), Batch(40/107), loss: 1.538825, imid loss: 0.166883, cmid loss: 1.371942 
Epoch (103), Batch(60/107), loss: 1.520167, imid loss: 0.166244, cmid loss: 1.353923 
Epoch (103), Batch(80/107), loss: 1.522614, imid loss: 0.166990, cmid loss: 1.355624 
Epoch (103), Batch(100/107), loss: 1.522839, imid loss: 0.168452, cmid loss: 1.354387 
Train 103, loss: 1.521387
Start validation
Val 103, loss: 10.371239
Linear Accuracy (val): 0.6050347222222222
Start training epoch: (104/300)
Epoch (104), Batch(0/107), loss: 1.343838, imid loss: 0.154925, cmid loss: 1.188913 
Epoch (104), Batch(20/107), loss: 1.505088, imid loss: 0.170296, cmid loss: 1.334792 
Epoch (104), Batch(40/107), loss: 1.505943, imid loss: 0.167855, cmid loss: 1.338088 
Epoch (104), Batch(60/107), loss: 1.499283, imid loss: 0.167462, cmid loss: 1.331821 
Epoch (104), Batch(80/107), loss: 1.501562, imid loss: 0.167142, cmid loss: 1.334419 
Epoch (104), Batch(100/107), loss: 1.512919, imid loss: 0.166981, cmid loss: 1.345938 
Train 104, loss: 1.514931
Start validation
Val 104, loss: 9.726148
Linear Accuracy (val): 0.5954861111111112
Start training epoch: (105/300)
Epoch (105), Batch(0/107), loss: 1.493147, imid loss: 0.132044, cmid loss: 1.361103 
Epoch (105), Batch(20/107), loss: 1.502925, imid loss: 0.166481, cmid loss: 1.336444 
Epoch (105), Batch(40/107), loss: 1.480308, imid loss: 0.162894, cmid loss: 1.317414 
Epoch (105), Batch(60/107), loss: 1.496790, imid loss: 0.164416, cmid loss: 1.332375 
Epoch (105), Batch(80/107), loss: 1.488699, imid loss: 0.163105, cmid loss: 1.325594 
Epoch (105), Batch(100/107), loss: 1.485828, imid loss: 0.164080, cmid loss: 1.321748 
Train 105, loss: 1.487381
Start validation
Val 105, loss: 10.478300
Linear Accuracy (val): 0.5980902777777778
Start training epoch: (106/300)
Epoch (106), Batch(0/107), loss: 1.568625, imid loss: 0.155629, cmid loss: 1.412996 
Epoch (106), Batch(20/107), loss: 1.469142, imid loss: 0.160673, cmid loss: 1.308470 
Epoch (106), Batch(40/107), loss: 1.477669, imid loss: 0.164805, cmid loss: 1.312864 
Epoch (106), Batch(60/107), loss: 1.479980, imid loss: 0.163790, cmid loss: 1.316190 
Epoch (106), Batch(80/107), loss: 1.488928, imid loss: 0.162559, cmid loss: 1.326369 
Epoch (106), Batch(100/107), loss: 1.491434, imid loss: 0.163424, cmid loss: 1.328010 
Train 106, loss: 1.489605
Start validation
Val 106, loss: 7.068999
Linear Accuracy (val): 0.6006944444444444
Start training epoch: (107/300)
Epoch (107), Batch(0/107), loss: 1.442052, imid loss: 0.159608, cmid loss: 1.282444 
Epoch (107), Batch(20/107), loss: 1.487265, imid loss: 0.167063, cmid loss: 1.320202 
Epoch (107), Batch(40/107), loss: 1.486017, imid loss: 0.166711, cmid loss: 1.319306 
Epoch (107), Batch(60/107), loss: 1.496136, imid loss: 0.166577, cmid loss: 1.329559 
Epoch (107), Batch(80/107), loss: 1.486458, imid loss: 0.165265, cmid loss: 1.321194 
Epoch (107), Batch(100/107), loss: 1.491484, imid loss: 0.165347, cmid loss: 1.326137 
Train 107, loss: 1.490006
Start validation
Val 107, loss: 9.819464
Linear Accuracy (val): 0.6067708333333334
Start training epoch: (108/300)
Epoch (108), Batch(0/107), loss: 1.675928, imid loss: 0.227188, cmid loss: 1.448740 
Epoch (108), Batch(20/107), loss: 1.476646, imid loss: 0.162676, cmid loss: 1.313970 
Epoch (108), Batch(40/107), loss: 1.493433, imid loss: 0.167066, cmid loss: 1.326368 
Epoch (108), Batch(60/107), loss: 1.497229, imid loss: 0.165760, cmid loss: 1.331469 
Epoch (108), Batch(80/107), loss: 1.492219, imid loss: 0.165510, cmid loss: 1.326709 
Epoch (108), Batch(100/107), loss: 1.484157, imid loss: 0.164778, cmid loss: 1.319379 
Train 108, loss: 1.485592
Start validation
Val 108, loss: 10.818146
Linear Accuracy (val): 0.6076388888888888
Start training epoch: (109/300)
Epoch (109), Batch(0/107), loss: 1.355445, imid loss: 0.150941, cmid loss: 1.204504 
Epoch (109), Batch(20/107), loss: 1.506815, imid loss: 0.168705, cmid loss: 1.338110 
Epoch (109), Batch(40/107), loss: 1.491773, imid loss: 0.166899, cmid loss: 1.324874 
Epoch (109), Batch(60/107), loss: 1.487204, imid loss: 0.167666, cmid loss: 1.319538 
Epoch (109), Batch(80/107), loss: 1.492062, imid loss: 0.165098, cmid loss: 1.326964 
Epoch (109), Batch(100/107), loss: 1.490285, imid loss: 0.165421, cmid loss: 1.324864 
Train 109, loss: 1.493697
Start validation
Val 109, loss: 7.952127
Linear Accuracy (val): 0.6102430555555556
Start training epoch: (110/300)
Epoch (110), Batch(0/107), loss: 1.638291, imid loss: 0.178494, cmid loss: 1.459797 
Epoch (110), Batch(20/107), loss: 1.473292, imid loss: 0.167723, cmid loss: 1.305569 
Epoch (110), Batch(40/107), loss: 1.480787, imid loss: 0.166733, cmid loss: 1.314054 
Epoch (110), Batch(60/107), loss: 1.475940, imid loss: 0.165723, cmid loss: 1.310217 
Epoch (110), Batch(80/107), loss: 1.475627, imid loss: 0.164691, cmid loss: 1.310936 
Epoch (110), Batch(100/107), loss: 1.473150, imid loss: 0.163336, cmid loss: 1.309815 
Train 110, loss: 1.476143
Start validation
Val 110, loss: 11.378495
Linear Accuracy (val): 0.6059027777777778
==> Saving...
Start training epoch: (111/300)
Epoch (111), Batch(0/107), loss: 1.514449, imid loss: 0.160534, cmid loss: 1.353915 
Epoch (111), Batch(20/107), loss: 1.473956, imid loss: 0.164212, cmid loss: 1.309744 
Epoch (111), Batch(40/107), loss: 1.483629, imid loss: 0.166460, cmid loss: 1.317169 
Epoch (111), Batch(60/107), loss: 1.476022, imid loss: 0.164910, cmid loss: 1.311112 
Epoch (111), Batch(80/107), loss: 1.488027, imid loss: 0.166597, cmid loss: 1.321431 
Epoch (111), Batch(100/107), loss: 1.496133, imid loss: 0.168583, cmid loss: 1.327550 
Train 111, loss: 1.493705
Start validation
Val 111, loss: 8.290673
Linear Accuracy (val): 0.6041666666666666
Start training epoch: (112/300)
Epoch (112), Batch(0/107), loss: 1.305743, imid loss: 0.158826, cmid loss: 1.146917 
Epoch (112), Batch(20/107), loss: 1.438296, imid loss: 0.156656, cmid loss: 1.281640 
Epoch (112), Batch(40/107), loss: 1.449520, imid loss: 0.160316, cmid loss: 1.289204 
Epoch (112), Batch(60/107), loss: 1.461693, imid loss: 0.162414, cmid loss: 1.299279 
Epoch (112), Batch(80/107), loss: 1.469113, imid loss: 0.160541, cmid loss: 1.308572 
Epoch (112), Batch(100/107), loss: 1.463021, imid loss: 0.162028, cmid loss: 1.300993 
Train 112, loss: 1.463841
Start validation
Val 112, loss: 9.131078
Linear Accuracy (val): 0.6171875
Start training epoch: (113/300)
Epoch (113), Batch(0/107), loss: 1.373456, imid loss: 0.161275, cmid loss: 1.212182 
Epoch (113), Batch(20/107), loss: 1.464500, imid loss: 0.155069, cmid loss: 1.309432 
Epoch (113), Batch(40/107), loss: 1.461478, imid loss: 0.161152, cmid loss: 1.300326 
Epoch (113), Batch(60/107), loss: 1.466740, imid loss: 0.162853, cmid loss: 1.303887 
Epoch (113), Batch(80/107), loss: 1.470166, imid loss: 0.162903, cmid loss: 1.307262 
Epoch (113), Batch(100/107), loss: 1.467076, imid loss: 0.162523, cmid loss: 1.304553 
Train 113, loss: 1.464226
Start validation
Val 113, loss: 9.672015
Linear Accuracy (val): 0.6050347222222222
Start training epoch: (114/300)
Epoch (114), Batch(0/107), loss: 1.502004, imid loss: 0.153102, cmid loss: 1.348902 
Epoch (114), Batch(20/107), loss: 1.526399, imid loss: 0.170019, cmid loss: 1.356381 
Epoch (114), Batch(40/107), loss: 1.497246, imid loss: 0.165716, cmid loss: 1.331530 
Epoch (114), Batch(60/107), loss: 1.491845, imid loss: 0.166446, cmid loss: 1.325399 
Epoch (114), Batch(80/107), loss: 1.480763, imid loss: 0.164519, cmid loss: 1.316245 
Epoch (114), Batch(100/107), loss: 1.484940, imid loss: 0.166204, cmid loss: 1.318736 
Train 114, loss: 1.483361
Start validation
Val 114, loss: 10.617099
Linear Accuracy (val): 0.6137152777777778
Start training epoch: (115/300)
Epoch (115), Batch(0/107), loss: 1.636209, imid loss: 0.158014, cmid loss: 1.478195 
Epoch (115), Batch(20/107), loss: 1.457634, imid loss: 0.165357, cmid loss: 1.292278 
Epoch (115), Batch(40/107), loss: 1.450197, imid loss: 0.161995, cmid loss: 1.288202 
Epoch (115), Batch(60/107), loss: 1.449739, imid loss: 0.160382, cmid loss: 1.289357 
Epoch (115), Batch(80/107), loss: 1.458780, imid loss: 0.161802, cmid loss: 1.296977 
Epoch (115), Batch(100/107), loss: 1.459952, imid loss: 0.160938, cmid loss: 1.299014 
Train 115, loss: 1.463545
Start validation
Val 115, loss: 9.584009
Linear Accuracy (val): 0.6050347222222222
Start training epoch: (116/300)
Epoch (116), Batch(0/107), loss: 1.543215, imid loss: 0.175523, cmid loss: 1.367692 
Epoch (116), Batch(20/107), loss: 1.446742, imid loss: 0.162720, cmid loss: 1.284022 
Epoch (116), Batch(40/107), loss: 1.452575, imid loss: 0.163939, cmid loss: 1.288636 
Epoch (116), Batch(60/107), loss: 1.472824, imid loss: 0.164287, cmid loss: 1.308536 
Epoch (116), Batch(80/107), loss: 1.459454, imid loss: 0.161901, cmid loss: 1.297553 
Epoch (116), Batch(100/107), loss: 1.463585, imid loss: 0.162222, cmid loss: 1.301362 
Train 116, loss: 1.464648
Start validation
Val 116, loss: 11.295130
Linear Accuracy (val): 0.5894097222222222
Start training epoch: (117/300)
Epoch (117), Batch(0/107), loss: 1.316638, imid loss: 0.161893, cmid loss: 1.154745 
Epoch (117), Batch(20/107), loss: 1.461665, imid loss: 0.160352, cmid loss: 1.301314 
Epoch (117), Batch(40/107), loss: 1.431750, imid loss: 0.159258, cmid loss: 1.272492 
Epoch (117), Batch(60/107), loss: 1.434309, imid loss: 0.160527, cmid loss: 1.273782 
Epoch (117), Batch(80/107), loss: 1.440557, imid loss: 0.160340, cmid loss: 1.280218 
Epoch (117), Batch(100/107), loss: 1.440475, imid loss: 0.161264, cmid loss: 1.279211 
Train 117, loss: 1.437867
Start validation
Val 117, loss: 10.136436
Linear Accuracy (val): 0.6085069444444444
Start training epoch: (118/300)
Epoch (118), Batch(0/107), loss: 1.303502, imid loss: 0.196645, cmid loss: 1.106858 
Epoch (118), Batch(20/107), loss: 1.401177, imid loss: 0.169018, cmid loss: 1.232159 
Epoch (118), Batch(40/107), loss: 1.428788, imid loss: 0.162912, cmid loss: 1.265876 
Epoch (118), Batch(60/107), loss: 1.429532, imid loss: 0.161499, cmid loss: 1.268033 
Epoch (118), Batch(80/107), loss: 1.434499, imid loss: 0.159595, cmid loss: 1.274903 
Epoch (118), Batch(100/107), loss: 1.433800, imid loss: 0.160215, cmid loss: 1.273585 
Train 118, loss: 1.435898
Start validation
Val 118, loss: 11.887965
Linear Accuracy (val): 0.6041666666666666
Start training epoch: (119/300)
Epoch (119), Batch(0/107), loss: 1.307431, imid loss: 0.179767, cmid loss: 1.127665 
Epoch (119), Batch(20/107), loss: 1.429459, imid loss: 0.158191, cmid loss: 1.271268 
Epoch (119), Batch(40/107), loss: 1.438689, imid loss: 0.155566, cmid loss: 1.283123 
Epoch (119), Batch(60/107), loss: 1.436459, imid loss: 0.158643, cmid loss: 1.277816 
Epoch (119), Batch(80/107), loss: 1.440507, imid loss: 0.157314, cmid loss: 1.283193 
Epoch (119), Batch(100/107), loss: 1.440783, imid loss: 0.157722, cmid loss: 1.283060 
Train 119, loss: 1.443575
Start validation
Val 119, loss: 11.585218
Linear Accuracy (val): 0.6111111111111112
Start training epoch: (120/300)
Epoch (120), Batch(0/107), loss: 1.682298, imid loss: 0.164686, cmid loss: 1.517612 
Epoch (120), Batch(20/107), loss: 1.432990, imid loss: 0.155109, cmid loss: 1.277881 
Epoch (120), Batch(40/107), loss: 1.429151, imid loss: 0.157048, cmid loss: 1.272103 
Epoch (120), Batch(60/107), loss: 1.431201, imid loss: 0.158309, cmid loss: 1.272892 
Epoch (120), Batch(80/107), loss: 1.432335, imid loss: 0.159489, cmid loss: 1.272845 
Epoch (120), Batch(100/107), loss: 1.434565, imid loss: 0.158672, cmid loss: 1.275894 
Train 120, loss: 1.434529
Start validation
Val 120, loss: 8.757341
Linear Accuracy (val): 0.6111111111111112
==> Saving...
Start training epoch: (121/300)
Epoch (121), Batch(0/107), loss: 1.564293, imid loss: 0.146221, cmid loss: 1.418071 
Epoch (121), Batch(20/107), loss: 1.443839, imid loss: 0.160868, cmid loss: 1.282970 
Epoch (121), Batch(40/107), loss: 1.442496, imid loss: 0.159724, cmid loss: 1.282772 
Epoch (121), Batch(60/107), loss: 1.438341, imid loss: 0.161254, cmid loss: 1.277087 
Epoch (121), Batch(80/107), loss: 1.429968, imid loss: 0.159507, cmid loss: 1.270461 
Epoch (121), Batch(100/107), loss: 1.428829, imid loss: 0.159629, cmid loss: 1.269200 
Train 121, loss: 1.429167
Start validation
Val 121, loss: 9.245737
Linear Accuracy (val): 0.5998263888888888
Start training epoch: (122/300)
Epoch (122), Batch(0/107), loss: 1.387223, imid loss: 0.143133, cmid loss: 1.244090 
Epoch (122), Batch(20/107), loss: 1.388327, imid loss: 0.154715, cmid loss: 1.233612 
Epoch (122), Batch(40/107), loss: 1.400730, imid loss: 0.158265, cmid loss: 1.242465 
Epoch (122), Batch(60/107), loss: 1.399304, imid loss: 0.159619, cmid loss: 1.239684 
Epoch (122), Batch(80/107), loss: 1.407844, imid loss: 0.159110, cmid loss: 1.248735 
Epoch (122), Batch(100/107), loss: 1.405907, imid loss: 0.158803, cmid loss: 1.247104 
Train 122, loss: 1.410393
Start validation
Val 122, loss: 9.952691
Linear Accuracy (val): 0.6085069444444444
Start training epoch: (123/300)
Epoch (123), Batch(0/107), loss: 1.344188, imid loss: 0.187867, cmid loss: 1.156321 
Epoch (123), Batch(20/107), loss: 1.426775, imid loss: 0.158254, cmid loss: 1.268521 
Epoch (123), Batch(40/107), loss: 1.431916, imid loss: 0.158003, cmid loss: 1.273914 
Epoch (123), Batch(60/107), loss: 1.426817, imid loss: 0.157603, cmid loss: 1.269214 
Epoch (123), Batch(80/107), loss: 1.426051, imid loss: 0.157511, cmid loss: 1.268540 
Epoch (123), Batch(100/107), loss: 1.425964, imid loss: 0.157751, cmid loss: 1.268213 
Train 123, loss: 1.424418
Start validation
Val 123, loss: 10.132480
Linear Accuracy (val): 0.5972222222222222
Start training epoch: (124/300)
Epoch (124), Batch(0/107), loss: 1.633867, imid loss: 0.158786, cmid loss: 1.475082 
Epoch (124), Batch(20/107), loss: 1.444080, imid loss: 0.150151, cmid loss: 1.293928 
Epoch (124), Batch(40/107), loss: 1.443240, imid loss: 0.156742, cmid loss: 1.286499 
Epoch (124), Batch(60/107), loss: 1.421556, imid loss: 0.156417, cmid loss: 1.265140 
Epoch (124), Batch(80/107), loss: 1.425073, imid loss: 0.157173, cmid loss: 1.267900 
Epoch (124), Batch(100/107), loss: 1.417030, imid loss: 0.156992, cmid loss: 1.260038 
Train 124, loss: 1.416343
Start validation
Val 124, loss: 11.921392
Linear Accuracy (val): 0.6006944444444444
Start training epoch: (125/300)
Epoch (125), Batch(0/107), loss: 1.326231, imid loss: 0.150862, cmid loss: 1.175369 
Epoch (125), Batch(20/107), loss: 1.404152, imid loss: 0.154636, cmid loss: 1.249516 
Epoch (125), Batch(40/107), loss: 1.404310, imid loss: 0.150143, cmid loss: 1.254167 
Epoch (125), Batch(60/107), loss: 1.409047, imid loss: 0.153445, cmid loss: 1.255601 
Epoch (125), Batch(80/107), loss: 1.416838, imid loss: 0.155060, cmid loss: 1.261778 
Epoch (125), Batch(100/107), loss: 1.422625, imid loss: 0.156108, cmid loss: 1.266517 
Train 125, loss: 1.422421
Start validation
Val 125, loss: 11.365116
Linear Accuracy (val): 0.5946180555555556
Start training epoch: (126/300)
Epoch (126), Batch(0/107), loss: 1.383728, imid loss: 0.137096, cmid loss: 1.246632 
Epoch (126), Batch(20/107), loss: 1.418568, imid loss: 0.152500, cmid loss: 1.266068 
Epoch (126), Batch(40/107), loss: 1.407171, imid loss: 0.151488, cmid loss: 1.255683 
Epoch (126), Batch(60/107), loss: 1.407224, imid loss: 0.156156, cmid loss: 1.251068 
Epoch (126), Batch(80/107), loss: 1.413871, imid loss: 0.157310, cmid loss: 1.256561 
Epoch (126), Batch(100/107), loss: 1.409668, imid loss: 0.156833, cmid loss: 1.252835 
Train 126, loss: 1.403511
Start validation
Val 126, loss: 10.574585
Linear Accuracy (val): 0.6076388888888888
Start training epoch: (127/300)
Epoch (127), Batch(0/107), loss: 1.427387, imid loss: 0.150155, cmid loss: 1.277231 
Epoch (127), Batch(20/107), loss: 1.399387, imid loss: 0.149184, cmid loss: 1.250203 
Epoch (127), Batch(40/107), loss: 1.387747, imid loss: 0.155021, cmid loss: 1.232726 
Epoch (127), Batch(60/107), loss: 1.386587, imid loss: 0.154395, cmid loss: 1.232192 
Epoch (127), Batch(80/107), loss: 1.397231, imid loss: 0.157121, cmid loss: 1.240111 
Epoch (127), Batch(100/107), loss: 1.392330, imid loss: 0.156362, cmid loss: 1.235968 
Train 127, loss: 1.391043
Start validation
Val 127, loss: 10.903141
Linear Accuracy (val): 0.6102430555555556
Start training epoch: (128/300)
Epoch (128), Batch(0/107), loss: 1.468907, imid loss: 0.187906, cmid loss: 1.281001 
Epoch (128), Batch(20/107), loss: 1.384340, imid loss: 0.152155, cmid loss: 1.232185 
Epoch (128), Batch(40/107), loss: 1.380649, imid loss: 0.151537, cmid loss: 1.229112 
Epoch (128), Batch(60/107), loss: 1.380942, imid loss: 0.152550, cmid loss: 1.228393 
Epoch (128), Batch(80/107), loss: 1.397441, imid loss: 0.153702, cmid loss: 1.243740 
Epoch (128), Batch(100/107), loss: 1.392596, imid loss: 0.152386, cmid loss: 1.240209 
Train 128, loss: 1.392345
Start validation
Val 128, loss: 9.882874
Linear Accuracy (val): 0.6032986111111112
Start training epoch: (129/300)
Epoch (129), Batch(0/107), loss: 1.334046, imid loss: 0.159506, cmid loss: 1.174541 
Epoch (129), Batch(20/107), loss: 1.346086, imid loss: 0.153488, cmid loss: 1.192597 
Epoch (129), Batch(40/107), loss: 1.375683, imid loss: 0.154108, cmid loss: 1.221575 
Epoch (129), Batch(60/107), loss: 1.377753, imid loss: 0.154098, cmid loss: 1.223654 
Epoch (129), Batch(80/107), loss: 1.380811, imid loss: 0.157641, cmid loss: 1.223170 
Epoch (129), Batch(100/107), loss: 1.384418, imid loss: 0.156523, cmid loss: 1.227895 
Train 129, loss: 1.386225
Start validation
Val 129, loss: 9.108134
Linear Accuracy (val): 0.6137152777777778
Start training epoch: (130/300)
Epoch (130), Batch(0/107), loss: 1.293229, imid loss: 0.128299, cmid loss: 1.164930 
Epoch (130), Batch(20/107), loss: 1.400805, imid loss: 0.157147, cmid loss: 1.243658 
Epoch (130), Batch(40/107), loss: 1.414887, imid loss: 0.162257, cmid loss: 1.252631 
Epoch (130), Batch(60/107), loss: 1.404309, imid loss: 0.158507, cmid loss: 1.245802 
Epoch (130), Batch(80/107), loss: 1.391779, imid loss: 0.155891, cmid loss: 1.235888 
Epoch (130), Batch(100/107), loss: 1.391523, imid loss: 0.155174, cmid loss: 1.236349 
Train 130, loss: 1.391459
Start validation
Val 130, loss: 10.140132
Linear Accuracy (val): 0.609375
==> Saving...
Start training epoch: (131/300)
Epoch (131), Batch(0/107), loss: 1.440605, imid loss: 0.165139, cmid loss: 1.275465 
Epoch (131), Batch(20/107), loss: 1.394663, imid loss: 0.158569, cmid loss: 1.236093 
Epoch (131), Batch(40/107), loss: 1.388099, imid loss: 0.159847, cmid loss: 1.228252 
Epoch (131), Batch(60/107), loss: 1.394023, imid loss: 0.157224, cmid loss: 1.236799 
Epoch (131), Batch(80/107), loss: 1.404235, imid loss: 0.157353, cmid loss: 1.246882 
Epoch (131), Batch(100/107), loss: 1.399943, imid loss: 0.156664, cmid loss: 1.243279 
Train 131, loss: 1.400718
Start validation
Val 131, loss: 9.249397
Linear Accuracy (val): 0.5980902777777778
Start training epoch: (132/300)
Epoch (132), Batch(0/107), loss: 1.377652, imid loss: 0.165618, cmid loss: 1.212034 
Epoch (132), Batch(20/107), loss: 1.365427, imid loss: 0.149260, cmid loss: 1.216167 
Epoch (132), Batch(40/107), loss: 1.356157, imid loss: 0.148480, cmid loss: 1.207678 
Epoch (132), Batch(60/107), loss: 1.367031, imid loss: 0.151030, cmid loss: 1.216000 
Epoch (132), Batch(80/107), loss: 1.363401, imid loss: 0.152732, cmid loss: 1.210669 
Epoch (132), Batch(100/107), loss: 1.364231, imid loss: 0.151861, cmid loss: 1.212369 
Train 132, loss: 1.364051
Start validation
Val 132, loss: 11.746917
Linear Accuracy (val): 0.5980902777777778
Start training epoch: (133/300)
Epoch (133), Batch(0/107), loss: 1.382252, imid loss: 0.171135, cmid loss: 1.211117 
Epoch (133), Batch(20/107), loss: 1.400826, imid loss: 0.158512, cmid loss: 1.242313 
Epoch (133), Batch(40/107), loss: 1.352260, imid loss: 0.150941, cmid loss: 1.201319 
Epoch (133), Batch(60/107), loss: 1.364800, imid loss: 0.152865, cmid loss: 1.211935 
Epoch (133), Batch(80/107), loss: 1.366622, imid loss: 0.154024, cmid loss: 1.212598 
Epoch (133), Batch(100/107), loss: 1.367509, imid loss: 0.153570, cmid loss: 1.213939 
Train 133, loss: 1.367286
Start validation
Val 133, loss: 10.233793
Linear Accuracy (val): 0.6024305555555556
Start training epoch: (134/300)
Epoch (134), Batch(0/107), loss: 1.407009, imid loss: 0.139126, cmid loss: 1.267884 
Epoch (134), Batch(20/107), loss: 1.344068, imid loss: 0.154348, cmid loss: 1.189720 
Epoch (134), Batch(40/107), loss: 1.368388, imid loss: 0.152424, cmid loss: 1.215965 
Epoch (134), Batch(60/107), loss: 1.354056, imid loss: 0.153235, cmid loss: 1.200821 
Epoch (134), Batch(80/107), loss: 1.350323, imid loss: 0.153276, cmid loss: 1.197046 
Epoch (134), Batch(100/107), loss: 1.360343, imid loss: 0.154044, cmid loss: 1.206299 
Train 134, loss: 1.367351
Start validation
Val 134, loss: 10.021405
Linear Accuracy (val): 0.6189236111111112
Start training epoch: (135/300)
Epoch (135), Batch(0/107), loss: 1.381124, imid loss: 0.175499, cmid loss: 1.205625 
Epoch (135), Batch(20/107), loss: 1.393130, imid loss: 0.165905, cmid loss: 1.227225 
Epoch (135), Batch(40/107), loss: 1.389218, imid loss: 0.159633, cmid loss: 1.229585 
Epoch (135), Batch(60/107), loss: 1.383335, imid loss: 0.158464, cmid loss: 1.224871 
Epoch (135), Batch(80/107), loss: 1.382359, imid loss: 0.158057, cmid loss: 1.224303 
Epoch (135), Batch(100/107), loss: 1.382603, imid loss: 0.157976, cmid loss: 1.224627 
Train 135, loss: 1.383716
Start validation
Val 135, loss: 9.761334
Linear Accuracy (val): 0.6111111111111112
Start training epoch: (136/300)
Epoch (136), Batch(0/107), loss: 1.291227, imid loss: 0.187946, cmid loss: 1.103281 
Epoch (136), Batch(20/107), loss: 1.353045, imid loss: 0.154192, cmid loss: 1.198852 
Epoch (136), Batch(40/107), loss: 1.351602, imid loss: 0.151322, cmid loss: 1.200280 
Epoch (136), Batch(60/107), loss: 1.354722, imid loss: 0.150456, cmid loss: 1.204266 
Epoch (136), Batch(80/107), loss: 1.355237, imid loss: 0.150942, cmid loss: 1.204295 
Epoch (136), Batch(100/107), loss: 1.357424, imid loss: 0.150266, cmid loss: 1.207157 
Train 136, loss: 1.357796
Start validation
Val 136, loss: 9.317787
Linear Accuracy (val): 0.6154513888888888
Start training epoch: (137/300)
Epoch (137), Batch(0/107), loss: 1.403765, imid loss: 0.158842, cmid loss: 1.244922 
Epoch (137), Batch(20/107), loss: 1.341360, imid loss: 0.151800, cmid loss: 1.189560 
Epoch (137), Batch(40/107), loss: 1.349800, imid loss: 0.153402, cmid loss: 1.196398 
Epoch (137), Batch(60/107), loss: 1.340142, imid loss: 0.150207, cmid loss: 1.189935 
Epoch (137), Batch(80/107), loss: 1.341553, imid loss: 0.149763, cmid loss: 1.191789 
Epoch (137), Batch(100/107), loss: 1.341464, imid loss: 0.150970, cmid loss: 1.190494 
Train 137, loss: 1.338344
Start validation
Val 137, loss: 7.780552
Linear Accuracy (val): 0.6111111111111112
Start training epoch: (138/300)
Epoch (138), Batch(0/107), loss: 1.371457, imid loss: 0.149403, cmid loss: 1.222054 
Epoch (138), Batch(20/107), loss: 1.337418, imid loss: 0.154339, cmid loss: 1.183079 
Epoch (138), Batch(40/107), loss: 1.342227, imid loss: 0.151693, cmid loss: 1.190535 
Epoch (138), Batch(60/107), loss: 1.359461, imid loss: 0.150790, cmid loss: 1.208671 
Epoch (138), Batch(80/107), loss: 1.356266, imid loss: 0.150971, cmid loss: 1.205296 
Epoch (138), Batch(100/107), loss: 1.362677, imid loss: 0.152550, cmid loss: 1.210126 
Train 138, loss: 1.362176
Start validation
Val 138, loss: 9.519143
Linear Accuracy (val): 0.6041666666666666
Start training epoch: (139/300)
Epoch (139), Batch(0/107), loss: 1.361204, imid loss: 0.120858, cmid loss: 1.240346 
Epoch (139), Batch(20/107), loss: 1.371386, imid loss: 0.155452, cmid loss: 1.215934 
Epoch (139), Batch(40/107), loss: 1.364479, imid loss: 0.153966, cmid loss: 1.210513 
Epoch (139), Batch(60/107), loss: 1.354400, imid loss: 0.153109, cmid loss: 1.201292 
Epoch (139), Batch(80/107), loss: 1.355682, imid loss: 0.151181, cmid loss: 1.204501 
Epoch (139), Batch(100/107), loss: 1.349170, imid loss: 0.150824, cmid loss: 1.198347 
Train 139, loss: 1.354577
Start validation
Val 139, loss: 2.717900
Linear Accuracy (val): 0.6241319444444444
==> Saving Best Model...
Start training epoch: (140/300)
Epoch (140), Batch(0/107), loss: 1.397513, imid loss: 0.148988, cmid loss: 1.248526 
Epoch (140), Batch(20/107), loss: 1.366346, imid loss: 0.157421, cmid loss: 1.208926 
Epoch (140), Batch(40/107), loss: 1.363053, imid loss: 0.155303, cmid loss: 1.207750 
Epoch (140), Batch(60/107), loss: 1.348141, imid loss: 0.153462, cmid loss: 1.194678 
Epoch (140), Batch(80/107), loss: 1.334176, imid loss: 0.150334, cmid loss: 1.183841 
Epoch (140), Batch(100/107), loss: 1.340666, imid loss: 0.152198, cmid loss: 1.188468 
Train 140, loss: 1.341444
Start validation
Val 140, loss: 9.510653
Linear Accuracy (val): 0.6015625
==> Saving...
Start training epoch: (141/300)
Epoch (141), Batch(0/107), loss: 1.245122, imid loss: 0.141605, cmid loss: 1.103517 
Epoch (141), Batch(20/107), loss: 1.367908, imid loss: 0.158336, cmid loss: 1.209573 
Epoch (141), Batch(40/107), loss: 1.355522, imid loss: 0.152980, cmid loss: 1.202542 
Epoch (141), Batch(60/107), loss: 1.346284, imid loss: 0.151749, cmid loss: 1.194535 
Epoch (141), Batch(80/107), loss: 1.347852, imid loss: 0.151913, cmid loss: 1.195940 
Epoch (141), Batch(100/107), loss: 1.343164, imid loss: 0.151974, cmid loss: 1.191189 
Train 141, loss: 1.345219
Start validation
Val 141, loss: 9.922984
Linear Accuracy (val): 0.5998263888888888
Start training epoch: (142/300)
Epoch (142), Batch(0/107), loss: 1.183829, imid loss: 0.121631, cmid loss: 1.062199 
Epoch (142), Batch(20/107), loss: 1.314088, imid loss: 0.153670, cmid loss: 1.160418 
Epoch (142), Batch(40/107), loss: 1.337745, imid loss: 0.150607, cmid loss: 1.187138 
Epoch (142), Batch(60/107), loss: 1.350997, imid loss: 0.150767, cmid loss: 1.200230 
Epoch (142), Batch(80/107), loss: 1.347101, imid loss: 0.149081, cmid loss: 1.198020 
Epoch (142), Batch(100/107), loss: 1.343699, imid loss: 0.148759, cmid loss: 1.194940 
Train 142, loss: 1.342344
Start validation
Val 142, loss: 8.435708
Linear Accuracy (val): 0.6137152777777778
Start training epoch: (143/300)
Epoch (143), Batch(0/107), loss: 1.417413, imid loss: 0.154069, cmid loss: 1.263344 
Epoch (143), Batch(20/107), loss: 1.333933, imid loss: 0.149258, cmid loss: 1.184674 
Epoch (143), Batch(40/107), loss: 1.353011, imid loss: 0.151525, cmid loss: 1.201486 
Epoch (143), Batch(60/107), loss: 1.335981, imid loss: 0.150390, cmid loss: 1.185592 
Epoch (143), Batch(80/107), loss: 1.325786, imid loss: 0.150412, cmid loss: 1.175374 
Epoch (143), Batch(100/107), loss: 1.321696, imid loss: 0.149489, cmid loss: 1.172207 
Train 143, loss: 1.323259
Start validation
Val 143, loss: 11.678313
Linear Accuracy (val): 0.5989583333333334
Start training epoch: (144/300)
Epoch (144), Batch(0/107), loss: 1.242220, imid loss: 0.150912, cmid loss: 1.091308 
Epoch (144), Batch(20/107), loss: 1.339177, imid loss: 0.153424, cmid loss: 1.185753 
Epoch (144), Batch(40/107), loss: 1.310959, imid loss: 0.150037, cmid loss: 1.160923 
Epoch (144), Batch(60/107), loss: 1.308505, imid loss: 0.148777, cmid loss: 1.159728 
Epoch (144), Batch(80/107), loss: 1.310976, imid loss: 0.145592, cmid loss: 1.165384 
Epoch (144), Batch(100/107), loss: 1.309333, imid loss: 0.145092, cmid loss: 1.164242 
Train 144, loss: 1.311678
Start validation
Val 144, loss: 6.546534
Linear Accuracy (val): 0.6154513888888888
Start training epoch: (145/300)
Epoch (145), Batch(0/107), loss: 1.278810, imid loss: 0.122921, cmid loss: 1.155889 
Epoch (145), Batch(20/107), loss: 1.351675, imid loss: 0.146506, cmid loss: 1.205169 
Epoch (145), Batch(40/107), loss: 1.333393, imid loss: 0.148781, cmid loss: 1.184611 
Epoch (145), Batch(60/107), loss: 1.322269, imid loss: 0.147647, cmid loss: 1.174622 
Epoch (145), Batch(80/107), loss: 1.323613, imid loss: 0.148096, cmid loss: 1.175517 
Epoch (145), Batch(100/107), loss: 1.334546, imid loss: 0.148638, cmid loss: 1.185908 
Train 145, loss: 1.333652
Start validation
Val 145, loss: 11.614890
Linear Accuracy (val): 0.6102430555555556
Start training epoch: (146/300)
Epoch (146), Batch(0/107), loss: 1.300397, imid loss: 0.122745, cmid loss: 1.177652 
Epoch (146), Batch(20/107), loss: 1.359365, imid loss: 0.151321, cmid loss: 1.208043 
Epoch (146), Batch(40/107), loss: 1.329172, imid loss: 0.150038, cmid loss: 1.179134 
Epoch (146), Batch(60/107), loss: 1.324130, imid loss: 0.150026, cmid loss: 1.174104 
Epoch (146), Batch(80/107), loss: 1.326197, imid loss: 0.147991, cmid loss: 1.178207 
Epoch (146), Batch(100/107), loss: 1.311930, imid loss: 0.148594, cmid loss: 1.163336 
Train 146, loss: 1.311718
Start validation
Val 146, loss: 10.351362
Linear Accuracy (val): 0.6006944444444444
Start training epoch: (147/300)
Epoch (147), Batch(0/107), loss: 1.363088, imid loss: 0.149818, cmid loss: 1.213271 
Epoch (147), Batch(20/107), loss: 1.324159, imid loss: 0.148638, cmid loss: 1.175521 
Epoch (147), Batch(40/107), loss: 1.323859, imid loss: 0.148100, cmid loss: 1.175759 
Epoch (147), Batch(60/107), loss: 1.303802, imid loss: 0.147387, cmid loss: 1.156415 
Epoch (147), Batch(80/107), loss: 1.305704, imid loss: 0.149239, cmid loss: 1.156465 
Epoch (147), Batch(100/107), loss: 1.305583, imid loss: 0.150689, cmid loss: 1.154894 
Train 147, loss: 1.305776
Start validation
Val 147, loss: 8.397334
Linear Accuracy (val): 0.6015625
Start training epoch: (148/300)
Epoch (148), Batch(0/107), loss: 1.424895, imid loss: 0.150883, cmid loss: 1.274012 
Epoch (148), Batch(20/107), loss: 1.252961, imid loss: 0.146319, cmid loss: 1.106642 
Epoch (148), Batch(40/107), loss: 1.277553, imid loss: 0.147641, cmid loss: 1.129912 
Epoch (148), Batch(60/107), loss: 1.288085, imid loss: 0.146506, cmid loss: 1.141579 
Epoch (148), Batch(80/107), loss: 1.294412, imid loss: 0.147310, cmid loss: 1.147103 
Epoch (148), Batch(100/107), loss: 1.301224, imid loss: 0.147874, cmid loss: 1.153351 
Train 148, loss: 1.298016
Start validation
Val 148, loss: 8.992241
Linear Accuracy (val): 0.6145833333333334
Start training epoch: (149/300)
Epoch (149), Batch(0/107), loss: 1.550186, imid loss: 0.198322, cmid loss: 1.351864 
Epoch (149), Batch(20/107), loss: 1.312314, imid loss: 0.153168, cmid loss: 1.159146 
Epoch (149), Batch(40/107), loss: 1.291788, imid loss: 0.149338, cmid loss: 1.142450 
Epoch (149), Batch(60/107), loss: 1.298568, imid loss: 0.147421, cmid loss: 1.151146 
Epoch (149), Batch(80/107), loss: 1.290683, imid loss: 0.146655, cmid loss: 1.144028 
Epoch (149), Batch(100/107), loss: 1.292543, imid loss: 0.146087, cmid loss: 1.146455 
Train 149, loss: 1.293630
Start validation
Val 149, loss: 9.235488
Linear Accuracy (val): 0.6041666666666666
Start training epoch: (150/300)
Epoch (150), Batch(0/107), loss: 1.172021, imid loss: 0.151213, cmid loss: 1.020808 
Epoch (150), Batch(20/107), loss: 1.289429, imid loss: 0.148359, cmid loss: 1.141070 
Epoch (150), Batch(40/107), loss: 1.285233, imid loss: 0.146232, cmid loss: 1.139001 
Epoch (150), Batch(60/107), loss: 1.286456, imid loss: 0.145988, cmid loss: 1.140467 
Epoch (150), Batch(80/107), loss: 1.291064, imid loss: 0.147701, cmid loss: 1.143363 
Epoch (150), Batch(100/107), loss: 1.289793, imid loss: 0.146077, cmid loss: 1.143716 
Train 150, loss: 1.292105
Start validation
Val 150, loss: 9.278436
Linear Accuracy (val): 0.6015625
==> Saving...
Start training epoch: (151/300)
Epoch (151), Batch(0/107), loss: 1.313441, imid loss: 0.120864, cmid loss: 1.192577 
Epoch (151), Batch(20/107), loss: 1.291750, imid loss: 0.148638, cmid loss: 1.143111 
Epoch (151), Batch(40/107), loss: 1.299584, imid loss: 0.146078, cmid loss: 1.153505 
Epoch (151), Batch(60/107), loss: 1.289386, imid loss: 0.144803, cmid loss: 1.144583 
Epoch (151), Batch(80/107), loss: 1.301915, imid loss: 0.149241, cmid loss: 1.152675 
Epoch (151), Batch(100/107), loss: 1.295733, imid loss: 0.148539, cmid loss: 1.147193 
Train 151, loss: 1.296572
Start validation
Val 151, loss: 11.774207
Linear Accuracy (val): 0.5980902777777778
Start training epoch: (152/300)
Epoch (152), Batch(0/107), loss: 1.390271, imid loss: 0.142237, cmid loss: 1.248034 
Epoch (152), Batch(20/107), loss: 1.256346, imid loss: 0.139120, cmid loss: 1.117226 
Epoch (152), Batch(40/107), loss: 1.270439, imid loss: 0.139040, cmid loss: 1.131400 
Epoch (152), Batch(60/107), loss: 1.294003, imid loss: 0.145798, cmid loss: 1.148205 
Epoch (152), Batch(80/107), loss: 1.290914, imid loss: 0.145852, cmid loss: 1.145063 
Epoch (152), Batch(100/107), loss: 1.298642, imid loss: 0.146550, cmid loss: 1.152092 
Train 152, loss: 1.301052
Start validation
Val 152, loss: 9.855579
Linear Accuracy (val): 0.6067708333333334
Start training epoch: (153/300)
Epoch (153), Batch(0/107), loss: 1.304895, imid loss: 0.148838, cmid loss: 1.156057 
Epoch (153), Batch(20/107), loss: 1.309606, imid loss: 0.151657, cmid loss: 1.157949 
Epoch (153), Batch(40/107), loss: 1.317113, imid loss: 0.146601, cmid loss: 1.170512 
Epoch (153), Batch(60/107), loss: 1.311661, imid loss: 0.147399, cmid loss: 1.164262 
Epoch (153), Batch(80/107), loss: 1.302824, imid loss: 0.148098, cmid loss: 1.154726 
Epoch (153), Batch(100/107), loss: 1.298785, imid loss: 0.148120, cmid loss: 1.150665 
Train 153, loss: 1.298476
Start validation
Val 153, loss: 11.286944
Linear Accuracy (val): 0.6024305555555556
Start training epoch: (154/300)
Epoch (154), Batch(0/107), loss: 1.096936, imid loss: 0.130153, cmid loss: 0.966783 
Epoch (154), Batch(20/107), loss: 1.250095, imid loss: 0.145107, cmid loss: 1.104988 
Epoch (154), Batch(40/107), loss: 1.272914, imid loss: 0.145724, cmid loss: 1.127190 
Epoch (154), Batch(60/107), loss: 1.277255, imid loss: 0.147678, cmid loss: 1.129577 
Epoch (154), Batch(80/107), loss: 1.273390, imid loss: 0.146702, cmid loss: 1.126688 
Epoch (154), Batch(100/107), loss: 1.277020, imid loss: 0.146647, cmid loss: 1.130373 
Train 154, loss: 1.277494
Start validation
Val 154, loss: 10.610388
Linear Accuracy (val): 0.6102430555555556
Start training epoch: (155/300)
Epoch (155), Batch(0/107), loss: 1.499426, imid loss: 0.171910, cmid loss: 1.327517 
Epoch (155), Batch(20/107), loss: 1.318241, imid loss: 0.147889, cmid loss: 1.170352 
Epoch (155), Batch(40/107), loss: 1.299924, imid loss: 0.146997, cmid loss: 1.152927 
Epoch (155), Batch(60/107), loss: 1.282552, imid loss: 0.144588, cmid loss: 1.137964 
Epoch (155), Batch(80/107), loss: 1.287122, imid loss: 0.146914, cmid loss: 1.140208 
Epoch (155), Batch(100/107), loss: 1.285659, imid loss: 0.146730, cmid loss: 1.138929 
Train 155, loss: 1.284289
Start validation
Val 155, loss: 9.496363
Linear Accuracy (val): 0.6102430555555556
Start training epoch: (156/300)
Epoch (156), Batch(0/107), loss: 1.327828, imid loss: 0.161463, cmid loss: 1.166365 
Epoch (156), Batch(20/107), loss: 1.295233, imid loss: 0.146769, cmid loss: 1.148464 
Epoch (156), Batch(40/107), loss: 1.272561, imid loss: 0.145101, cmid loss: 1.127460 
Epoch (156), Batch(60/107), loss: 1.262044, imid loss: 0.143815, cmid loss: 1.118228 
Epoch (156), Batch(80/107), loss: 1.268328, imid loss: 0.144973, cmid loss: 1.123355 
Epoch (156), Batch(100/107), loss: 1.277550, imid loss: 0.145161, cmid loss: 1.132389 
Train 156, loss: 1.276710
Start validation
Val 156, loss: 9.123711
Linear Accuracy (val): 0.5989583333333334
Start training epoch: (157/300)
Epoch (157), Batch(0/107), loss: 1.233172, imid loss: 0.139367, cmid loss: 1.093805 
Epoch (157), Batch(20/107), loss: 1.274217, imid loss: 0.140691, cmid loss: 1.133526 
Epoch (157), Batch(40/107), loss: 1.263559, imid loss: 0.142387, cmid loss: 1.121172 
Epoch (157), Batch(60/107), loss: 1.269726, imid loss: 0.141564, cmid loss: 1.128162 
Epoch (157), Batch(80/107), loss: 1.264738, imid loss: 0.141631, cmid loss: 1.123107 
Epoch (157), Batch(100/107), loss: 1.268425, imid loss: 0.143156, cmid loss: 1.125270 
Train 157, loss: 1.271931
Start validation
Val 157, loss: 11.525971
Linear Accuracy (val): 0.5920138888888888
Start training epoch: (158/300)
Epoch (158), Batch(0/107), loss: 1.019768, imid loss: 0.135618, cmid loss: 0.884151 
Epoch (158), Batch(20/107), loss: 1.268633, imid loss: 0.147195, cmid loss: 1.121437 
Epoch (158), Batch(40/107), loss: 1.273423, imid loss: 0.148138, cmid loss: 1.125285 
Epoch (158), Batch(60/107), loss: 1.277260, imid loss: 0.146605, cmid loss: 1.130655 
Epoch (158), Batch(80/107), loss: 1.281029, imid loss: 0.144720, cmid loss: 1.136309 
Epoch (158), Batch(100/107), loss: 1.284952, imid loss: 0.144076, cmid loss: 1.140876 
Train 158, loss: 1.280077
Start validation
Val 158, loss: 9.445033
Linear Accuracy (val): 0.6015625
Start training epoch: (159/300)
Epoch (159), Batch(0/107), loss: 1.193125, imid loss: 0.149268, cmid loss: 1.043857 
Epoch (159), Batch(20/107), loss: 1.276658, imid loss: 0.139961, cmid loss: 1.136697 
Epoch (159), Batch(40/107), loss: 1.262074, imid loss: 0.139287, cmid loss: 1.122787 
Epoch (159), Batch(60/107), loss: 1.266748, imid loss: 0.139320, cmid loss: 1.127429 
Epoch (159), Batch(80/107), loss: 1.262324, imid loss: 0.139215, cmid loss: 1.123109 
Epoch (159), Batch(100/107), loss: 1.267889, imid loss: 0.140945, cmid loss: 1.126944 
Train 159, loss: 1.269762
Start validation
Val 159, loss: 9.863016
Linear Accuracy (val): 0.6041666666666666
Start training epoch: (160/300)
Epoch (160), Batch(0/107), loss: 1.413461, imid loss: 0.186801, cmid loss: 1.226660 
Epoch (160), Batch(20/107), loss: 1.270706, imid loss: 0.149126, cmid loss: 1.121581 
Epoch (160), Batch(40/107), loss: 1.288005, imid loss: 0.149459, cmid loss: 1.138546 
Epoch (160), Batch(60/107), loss: 1.277167, imid loss: 0.148195, cmid loss: 1.128972 
Epoch (160), Batch(80/107), loss: 1.275144, imid loss: 0.148837, cmid loss: 1.126307 
Epoch (160), Batch(100/107), loss: 1.268913, imid loss: 0.147914, cmid loss: 1.120999 
Train 160, loss: 1.271259
Start validation
Val 160, loss: 8.697223
Linear Accuracy (val): 0.6067708333333334
==> Saving...
Start training epoch: (161/300)
Epoch (161), Batch(0/107), loss: 1.299842, imid loss: 0.107179, cmid loss: 1.192663 
Epoch (161), Batch(20/107), loss: 1.291273, imid loss: 0.144539, cmid loss: 1.146735 
Epoch (161), Batch(40/107), loss: 1.273283, imid loss: 0.145072, cmid loss: 1.128211 
Epoch (161), Batch(60/107), loss: 1.266191, imid loss: 0.143086, cmid loss: 1.123105 
Epoch (161), Batch(80/107), loss: 1.257623, imid loss: 0.143961, cmid loss: 1.113662 
Epoch (161), Batch(100/107), loss: 1.262389, imid loss: 0.142584, cmid loss: 1.119805 
Train 161, loss: 1.261525
Start validation
Val 161, loss: 6.509671
Linear Accuracy (val): 0.6119791666666666
Start training epoch: (162/300)
Epoch (162), Batch(0/107), loss: 1.253703, imid loss: 0.163454, cmid loss: 1.090250 
Epoch (162), Batch(20/107), loss: 1.269630, imid loss: 0.136796, cmid loss: 1.132835 
Epoch (162), Batch(40/107), loss: 1.248946, imid loss: 0.137915, cmid loss: 1.111031 
Epoch (162), Batch(60/107), loss: 1.279727, imid loss: 0.142273, cmid loss: 1.137454 
Epoch (162), Batch(80/107), loss: 1.274051, imid loss: 0.143288, cmid loss: 1.130764 
Epoch (162), Batch(100/107), loss: 1.269652, imid loss: 0.143436, cmid loss: 1.126216 
Train 162, loss: 1.272933
Start validation
Val 162, loss: 10.665312
Linear Accuracy (val): 0.6180555555555556
Start training epoch: (163/300)
Epoch (163), Batch(0/107), loss: 1.209089, imid loss: 0.149304, cmid loss: 1.059785 
Epoch (163), Batch(20/107), loss: 1.256401, imid loss: 0.139653, cmid loss: 1.116748 
Epoch (163), Batch(40/107), loss: 1.258172, imid loss: 0.143651, cmid loss: 1.114521 
Epoch (163), Batch(60/107), loss: 1.253570, imid loss: 0.142198, cmid loss: 1.111372 
Epoch (163), Batch(80/107), loss: 1.256374, imid loss: 0.142254, cmid loss: 1.114120 
Epoch (163), Batch(100/107), loss: 1.264631, imid loss: 0.143107, cmid loss: 1.121524 
Train 163, loss: 1.265346
Start validation
Val 163, loss: 10.218781
Linear Accuracy (val): 0.609375
Start training epoch: (164/300)
Epoch (164), Batch(0/107), loss: 1.157045, imid loss: 0.117880, cmid loss: 1.039165 
Epoch (164), Batch(20/107), loss: 1.197658, imid loss: 0.127826, cmid loss: 1.069832 
Epoch (164), Batch(40/107), loss: 1.215960, imid loss: 0.137621, cmid loss: 1.078339 
Epoch (164), Batch(60/107), loss: 1.234883, imid loss: 0.139360, cmid loss: 1.095524 
Epoch (164), Batch(80/107), loss: 1.253501, imid loss: 0.141356, cmid loss: 1.112145 
Epoch (164), Batch(100/107), loss: 1.259741, imid loss: 0.142291, cmid loss: 1.117450 
Train 164, loss: 1.259288
Start validation
Val 164, loss: 9.876851
Linear Accuracy (val): 0.6145833333333334
Start training epoch: (165/300)
Epoch (165), Batch(0/107), loss: 1.215690, imid loss: 0.118037, cmid loss: 1.097653 
Epoch (165), Batch(20/107), loss: 1.222407, imid loss: 0.135606, cmid loss: 1.086801 
Epoch (165), Batch(40/107), loss: 1.240701, imid loss: 0.138606, cmid loss: 1.102095 
Epoch (165), Batch(60/107), loss: 1.240590, imid loss: 0.139245, cmid loss: 1.101346 
Epoch (165), Batch(80/107), loss: 1.247454, imid loss: 0.140089, cmid loss: 1.107365 
Epoch (165), Batch(100/107), loss: 1.243241, imid loss: 0.141269, cmid loss: 1.101972 
Train 165, loss: 1.240020
Start validation
Val 165, loss: 2.674402
Linear Accuracy (val): 0.6319444444444444
==> Saving Best Model...
Start training epoch: (166/300)
Epoch (166), Batch(0/107), loss: 1.263606, imid loss: 0.140743, cmid loss: 1.122862 
Epoch (166), Batch(20/107), loss: 1.246594, imid loss: 0.141464, cmid loss: 1.105130 
Epoch (166), Batch(40/107), loss: 1.258005, imid loss: 0.141574, cmid loss: 1.116432 
Epoch (166), Batch(60/107), loss: 1.265175, imid loss: 0.140187, cmid loss: 1.124988 
Epoch (166), Batch(80/107), loss: 1.260160, imid loss: 0.138726, cmid loss: 1.121434 
Epoch (166), Batch(100/107), loss: 1.253923, imid loss: 0.138501, cmid loss: 1.115422 
Train 166, loss: 1.251782
Start validation
Val 166, loss: 9.801306
Linear Accuracy (val): 0.609375
Start training epoch: (167/300)
Epoch (167), Batch(0/107), loss: 1.244400, imid loss: 0.122688, cmid loss: 1.121711 
Epoch (167), Batch(20/107), loss: 1.276073, imid loss: 0.140957, cmid loss: 1.135115 
Epoch (167), Batch(40/107), loss: 1.267821, imid loss: 0.141835, cmid loss: 1.125986 
Epoch (167), Batch(60/107), loss: 1.256412, imid loss: 0.140398, cmid loss: 1.116013 
Epoch (167), Batch(80/107), loss: 1.252400, imid loss: 0.140372, cmid loss: 1.112028 
Epoch (167), Batch(100/107), loss: 1.249604, imid loss: 0.141282, cmid loss: 1.108321 
Train 167, loss: 1.251866
Start validation
Val 167, loss: 9.331421
Linear Accuracy (val): 0.5980902777777778
Start training epoch: (168/300)
Epoch (168), Batch(0/107), loss: 1.369233, imid loss: 0.129067, cmid loss: 1.240166 
Epoch (168), Batch(20/107), loss: 1.232049, imid loss: 0.143601, cmid loss: 1.088448 
Epoch (168), Batch(40/107), loss: 1.247615, imid loss: 0.145674, cmid loss: 1.101941 
Epoch (168), Batch(60/107), loss: 1.251552, imid loss: 0.145285, cmid loss: 1.106268 
Epoch (168), Batch(80/107), loss: 1.249330, imid loss: 0.144392, cmid loss: 1.104938 
Epoch (168), Batch(100/107), loss: 1.240286, imid loss: 0.142964, cmid loss: 1.097322 
Train 168, loss: 1.241276
Start validation
Val 168, loss: 9.346773
Linear Accuracy (val): 0.6154513888888888
Start training epoch: (169/300)
Epoch (169), Batch(0/107), loss: 1.316109, imid loss: 0.143628, cmid loss: 1.172481 
Epoch (169), Batch(20/107), loss: 1.228839, imid loss: 0.136929, cmid loss: 1.091911 
Epoch (169), Batch(40/107), loss: 1.242767, imid loss: 0.138297, cmid loss: 1.104470 
Epoch (169), Batch(60/107), loss: 1.242368, imid loss: 0.139441, cmid loss: 1.102927 
Epoch (169), Batch(80/107), loss: 1.233120, imid loss: 0.138252, cmid loss: 1.094868 
Epoch (169), Batch(100/107), loss: 1.230805, imid loss: 0.138352, cmid loss: 1.092453 
Train 169, loss: 1.227812
Start validation
Val 169, loss: 11.276101
Linear Accuracy (val): 0.6059027777777778
Start training epoch: (170/300)
Epoch (170), Batch(0/107), loss: 1.271149, imid loss: 0.145138, cmid loss: 1.126011 
Epoch (170), Batch(20/107), loss: 1.213203, imid loss: 0.132751, cmid loss: 1.080451 
Epoch (170), Batch(40/107), loss: 1.230589, imid loss: 0.136368, cmid loss: 1.094221 
Epoch (170), Batch(60/107), loss: 1.231844, imid loss: 0.137068, cmid loss: 1.094775 
Epoch (170), Batch(80/107), loss: 1.226026, imid loss: 0.136760, cmid loss: 1.089265 
Epoch (170), Batch(100/107), loss: 1.234395, imid loss: 0.136637, cmid loss: 1.097758 
Train 170, loss: 1.235681
Start validation
Val 170, loss: 10.845449
Linear Accuracy (val): 0.6076388888888888
==> Saving...
Start training epoch: (171/300)
Epoch (171), Batch(0/107), loss: 1.182725, imid loss: 0.132276, cmid loss: 1.050449 
Epoch (171), Batch(20/107), loss: 1.263800, imid loss: 0.151521, cmid loss: 1.112280 
Epoch (171), Batch(40/107), loss: 1.249227, imid loss: 0.146158, cmid loss: 1.103070 
Epoch (171), Batch(60/107), loss: 1.249603, imid loss: 0.142758, cmid loss: 1.106846 
Epoch (171), Batch(80/107), loss: 1.245093, imid loss: 0.141593, cmid loss: 1.103501 
Epoch (171), Batch(100/107), loss: 1.248759, imid loss: 0.142708, cmid loss: 1.106051 
Train 171, loss: 1.253633
Start validation
Val 171, loss: 9.287101
Linear Accuracy (val): 0.6050347222222222
Start training epoch: (172/300)
Epoch (172), Batch(0/107), loss: 1.145760, imid loss: 0.112731, cmid loss: 1.033029 
Epoch (172), Batch(20/107), loss: 1.231794, imid loss: 0.144263, cmid loss: 1.087531 
Epoch (172), Batch(40/107), loss: 1.203752, imid loss: 0.140334, cmid loss: 1.063418 
Epoch (172), Batch(60/107), loss: 1.214597, imid loss: 0.139816, cmid loss: 1.074781 
Epoch (172), Batch(80/107), loss: 1.224223, imid loss: 0.140821, cmid loss: 1.083402 
Epoch (172), Batch(100/107), loss: 1.221876, imid loss: 0.141181, cmid loss: 1.080695 
Train 172, loss: 1.226013
Start validation
Val 172, loss: 9.073177
Linear Accuracy (val): 0.6041666666666666
Start training epoch: (173/300)
Epoch (173), Batch(0/107), loss: 1.225586, imid loss: 0.129448, cmid loss: 1.096138 
Epoch (173), Batch(20/107), loss: 1.272097, imid loss: 0.146765, cmid loss: 1.125332 
Epoch (173), Batch(40/107), loss: 1.219345, imid loss: 0.137450, cmid loss: 1.081896 
Epoch (173), Batch(60/107), loss: 1.224300, imid loss: 0.137219, cmid loss: 1.087081 
Epoch (173), Batch(80/107), loss: 1.223644, imid loss: 0.138422, cmid loss: 1.085222 
Epoch (173), Batch(100/107), loss: 1.223710, imid loss: 0.140419, cmid loss: 1.083291 
Train 173, loss: 1.222292
Start validation
Val 173, loss: 11.445683
Linear Accuracy (val): 0.6119791666666666
Start training epoch: (174/300)
Epoch (174), Batch(0/107), loss: 1.357462, imid loss: 0.155454, cmid loss: 1.202008 
Epoch (174), Batch(20/107), loss: 1.228933, imid loss: 0.134678, cmid loss: 1.094256 
Epoch (174), Batch(40/107), loss: 1.241421, imid loss: 0.141066, cmid loss: 1.100355 
Epoch (174), Batch(60/107), loss: 1.245406, imid loss: 0.142214, cmid loss: 1.103192 
Epoch (174), Batch(80/107), loss: 1.238846, imid loss: 0.142662, cmid loss: 1.096185 
Epoch (174), Batch(100/107), loss: 1.238831, imid loss: 0.141548, cmid loss: 1.097283 
Train 174, loss: 1.241316
Start validation
Val 174, loss: 2.695553
Linear Accuracy (val): 0.6189236111111112
Start training epoch: (175/300)
Epoch (175), Batch(0/107), loss: 1.324596, imid loss: 0.150187, cmid loss: 1.174409 
Epoch (175), Batch(20/107), loss: 1.231408, imid loss: 0.139829, cmid loss: 1.091579 
Epoch (175), Batch(40/107), loss: 1.208104, imid loss: 0.140789, cmid loss: 1.067315 
Epoch (175), Batch(60/107), loss: 1.209083, imid loss: 0.139665, cmid loss: 1.069418 
Epoch (175), Batch(80/107), loss: 1.213601, imid loss: 0.140444, cmid loss: 1.073157 
Epoch (175), Batch(100/107), loss: 1.212856, imid loss: 0.140353, cmid loss: 1.072503 
Train 175, loss: 1.215806
Start validation
Val 175, loss: 6.169118
Linear Accuracy (val): 0.6145833333333334
Start training epoch: (176/300)
Epoch (176), Batch(0/107), loss: 1.181864, imid loss: 0.135704, cmid loss: 1.046160 
Epoch (176), Batch(20/107), loss: 1.201401, imid loss: 0.138495, cmid loss: 1.062907 
Epoch (176), Batch(40/107), loss: 1.218900, imid loss: 0.138031, cmid loss: 1.080869 
Epoch (176), Batch(60/107), loss: 1.214607, imid loss: 0.137812, cmid loss: 1.076795 
Epoch (176), Batch(80/107), loss: 1.215896, imid loss: 0.137806, cmid loss: 1.078090 
Epoch (176), Batch(100/107), loss: 1.210916, imid loss: 0.137094, cmid loss: 1.073822 
Train 176, loss: 1.211949
Start validation
Val 176, loss: 9.772415
Linear Accuracy (val): 0.6180555555555556
Start training epoch: (177/300)
Epoch (177), Batch(0/107), loss: 1.194196, imid loss: 0.132916, cmid loss: 1.061280 
Epoch (177), Batch(20/107), loss: 1.229890, imid loss: 0.143452, cmid loss: 1.086438 
Epoch (177), Batch(40/107), loss: 1.231064, imid loss: 0.139273, cmid loss: 1.091791 
Epoch (177), Batch(60/107), loss: 1.222609, imid loss: 0.139773, cmid loss: 1.082836 
Epoch (177), Batch(80/107), loss: 1.222462, imid loss: 0.139406, cmid loss: 1.083056 
Epoch (177), Batch(100/107), loss: 1.213546, imid loss: 0.138621, cmid loss: 1.074925 
Train 177, loss: 1.212706
Start validation
Val 177, loss: 3.716027
Linear Accuracy (val): 0.6215277777777778
Start training epoch: (178/300)
Epoch (178), Batch(0/107), loss: 1.210106, imid loss: 0.140280, cmid loss: 1.069827 
Epoch (178), Batch(20/107), loss: 1.162284, imid loss: 0.135266, cmid loss: 1.027019 
Epoch (178), Batch(40/107), loss: 1.180122, imid loss: 0.137264, cmid loss: 1.042859 
Epoch (178), Batch(60/107), loss: 1.180473, imid loss: 0.136493, cmid loss: 1.043981 
Epoch (178), Batch(80/107), loss: 1.188058, imid loss: 0.136135, cmid loss: 1.051923 
Epoch (178), Batch(100/107), loss: 1.189331, imid loss: 0.136241, cmid loss: 1.053090 
Train 178, loss: 1.194431
Start validation
Val 178, loss: 11.251002
Linear Accuracy (val): 0.6050347222222222
Start training epoch: (179/300)
Epoch (179), Batch(0/107), loss: 1.360028, imid loss: 0.186819, cmid loss: 1.173209 
Epoch (179), Batch(20/107), loss: 1.183657, imid loss: 0.141224, cmid loss: 1.042433 
Epoch (179), Batch(40/107), loss: 1.190245, imid loss: 0.137803, cmid loss: 1.052442 
Epoch (179), Batch(60/107), loss: 1.203768, imid loss: 0.139333, cmid loss: 1.064436 
Epoch (179), Batch(80/107), loss: 1.205830, imid loss: 0.138888, cmid loss: 1.066942 
Epoch (179), Batch(100/107), loss: 1.206355, imid loss: 0.138378, cmid loss: 1.067977 
Train 179, loss: 1.203805
Start validation
Val 179, loss: 9.893564
Linear Accuracy (val): 0.6154513888888888
Start training epoch: (180/300)
Epoch (180), Batch(0/107), loss: 1.332753, imid loss: 0.134592, cmid loss: 1.198161 
Epoch (180), Batch(20/107), loss: 1.236030, imid loss: 0.140175, cmid loss: 1.095855 
Epoch (180), Batch(40/107), loss: 1.225921, imid loss: 0.139341, cmid loss: 1.086580 
Epoch (180), Batch(60/107), loss: 1.217485, imid loss: 0.139594, cmid loss: 1.077891 
Epoch (180), Batch(80/107), loss: 1.214055, imid loss: 0.138582, cmid loss: 1.075473 
Epoch (180), Batch(100/107), loss: 1.212803, imid loss: 0.139229, cmid loss: 1.073574 
Train 180, loss: 1.214174
Start validation
Val 180, loss: 11.457219
Linear Accuracy (val): 0.5998263888888888
==> Saving...
Start training epoch: (181/300)
Epoch (181), Batch(0/107), loss: 1.024904, imid loss: 0.132416, cmid loss: 0.892489 
Epoch (181), Batch(20/107), loss: 1.168687, imid loss: 0.134816, cmid loss: 1.033871 
Epoch (181), Batch(40/107), loss: 1.198545, imid loss: 0.136721, cmid loss: 1.061824 
Epoch (181), Batch(60/107), loss: 1.191618, imid loss: 0.136507, cmid loss: 1.055111 
Epoch (181), Batch(80/107), loss: 1.196104, imid loss: 0.135430, cmid loss: 1.060675 
Epoch (181), Batch(100/107), loss: 1.197069, imid loss: 0.135351, cmid loss: 1.061718 
Train 181, loss: 1.193526
Start validation
Val 181, loss: 11.268604
Linear Accuracy (val): 0.5876736111111112
Start training epoch: (182/300)
Epoch (182), Batch(0/107), loss: 1.196110, imid loss: 0.117473, cmid loss: 1.078637 
Epoch (182), Batch(20/107), loss: 1.218935, imid loss: 0.135845, cmid loss: 1.083090 
Epoch (182), Batch(40/107), loss: 1.225304, imid loss: 0.138855, cmid loss: 1.086449 
Epoch (182), Batch(60/107), loss: 1.202638, imid loss: 0.137638, cmid loss: 1.064999 
Epoch (182), Batch(80/107), loss: 1.200333, imid loss: 0.139593, cmid loss: 1.060740 
Epoch (182), Batch(100/107), loss: 1.196322, imid loss: 0.139053, cmid loss: 1.057269 
Train 182, loss: 1.194062
Start validation
Val 182, loss: 8.972355
Linear Accuracy (val): 0.6076388888888888
Start training epoch: (183/300)
Epoch (183), Batch(0/107), loss: 1.107275, imid loss: 0.160547, cmid loss: 0.946728 
Epoch (183), Batch(20/107), loss: 1.166914, imid loss: 0.129950, cmid loss: 1.036964 
Epoch (183), Batch(40/107), loss: 1.179974, imid loss: 0.134578, cmid loss: 1.045396 
Epoch (183), Batch(60/107), loss: 1.180016, imid loss: 0.134419, cmid loss: 1.045597 
Epoch (183), Batch(80/107), loss: 1.176426, imid loss: 0.135751, cmid loss: 1.040674 
Epoch (183), Batch(100/107), loss: 1.177585, imid loss: 0.135831, cmid loss: 1.041755 
Train 183, loss: 1.174014
Start validation
Val 183, loss: 9.946247
Linear Accuracy (val): 0.6015625
Start training epoch: (184/300)
Epoch (184), Batch(0/107), loss: 1.105306, imid loss: 0.125362, cmid loss: 0.979945 
Epoch (184), Batch(20/107), loss: 1.208730, imid loss: 0.134619, cmid loss: 1.074111 
Epoch (184), Batch(40/107), loss: 1.177839, imid loss: 0.136761, cmid loss: 1.041078 
Epoch (184), Batch(60/107), loss: 1.196244, imid loss: 0.136820, cmid loss: 1.059424 
Epoch (184), Batch(80/107), loss: 1.196065, imid loss: 0.139240, cmid loss: 1.056825 
Epoch (184), Batch(100/107), loss: 1.192898, imid loss: 0.136894, cmid loss: 1.056004 
Train 184, loss: 1.190686
Start validation
Val 184, loss: 11.076732
Linear Accuracy (val): 0.5954861111111112
Start training epoch: (185/300)
Epoch (185), Batch(0/107), loss: 1.201106, imid loss: 0.111375, cmid loss: 1.089731 
Epoch (185), Batch(20/107), loss: 1.164597, imid loss: 0.127741, cmid loss: 1.036856 
Epoch (185), Batch(40/107), loss: 1.187557, imid loss: 0.130455, cmid loss: 1.057102 
Epoch (185), Batch(60/107), loss: 1.190639, imid loss: 0.132749, cmid loss: 1.057890 
Epoch (185), Batch(80/107), loss: 1.192283, imid loss: 0.132560, cmid loss: 1.059723 
Epoch (185), Batch(100/107), loss: 1.192115, imid loss: 0.133616, cmid loss: 1.058499 
Train 185, loss: 1.187923
Start validation
Val 185, loss: 9.508587
Linear Accuracy (val): 0.5989583333333334
Start training epoch: (186/300)
Epoch (186), Batch(0/107), loss: 1.248707, imid loss: 0.132693, cmid loss: 1.116014 
Epoch (186), Batch(20/107), loss: 1.165759, imid loss: 0.131207, cmid loss: 1.034552 
Epoch (186), Batch(40/107), loss: 1.183173, imid loss: 0.133493, cmid loss: 1.049681 
Epoch (186), Batch(60/107), loss: 1.179420, imid loss: 0.134601, cmid loss: 1.044818 
Epoch (186), Batch(80/107), loss: 1.185924, imid loss: 0.134765, cmid loss: 1.051158 
Epoch (186), Batch(100/107), loss: 1.191652, imid loss: 0.135846, cmid loss: 1.055806 
Train 186, loss: 1.192209
Start validation
Val 186, loss: 9.213843
Linear Accuracy (val): 0.6102430555555556
Start training epoch: (187/300)
Epoch (187), Batch(0/107), loss: 1.236205, imid loss: 0.202771, cmid loss: 1.033434 
Epoch (187), Batch(20/107), loss: 1.166018, imid loss: 0.138078, cmid loss: 1.027941 
Epoch (187), Batch(40/107), loss: 1.166884, imid loss: 0.137473, cmid loss: 1.029411 
Epoch (187), Batch(60/107), loss: 1.181024, imid loss: 0.136792, cmid loss: 1.044233 
Epoch (187), Batch(80/107), loss: 1.183962, imid loss: 0.136643, cmid loss: 1.047318 
Epoch (187), Batch(100/107), loss: 1.183079, imid loss: 0.135341, cmid loss: 1.047737 
Train 187, loss: 1.183809
Start validation
Val 187, loss: 2.114198
Linear Accuracy (val): 0.6154513888888888
Start training epoch: (188/300)
Epoch (188), Batch(0/107), loss: 1.267466, imid loss: 0.144852, cmid loss: 1.122614 
Epoch (188), Batch(20/107), loss: 1.172834, imid loss: 0.134068, cmid loss: 1.038766 
Epoch (188), Batch(40/107), loss: 1.163142, imid loss: 0.128420, cmid loss: 1.034721 
Epoch (188), Batch(60/107), loss: 1.166650, imid loss: 0.129879, cmid loss: 1.036771 
Epoch (188), Batch(80/107), loss: 1.157791, imid loss: 0.131738, cmid loss: 1.026053 
Epoch (188), Batch(100/107), loss: 1.158286, imid loss: 0.131333, cmid loss: 1.026953 
Train 188, loss: 1.162781
Start validation
Val 188, loss: 10.236411
Linear Accuracy (val): 0.5998263888888888
Start training epoch: (189/300)
Epoch (189), Batch(0/107), loss: 1.016213, imid loss: 0.136618, cmid loss: 0.879595 
Epoch (189), Batch(20/107), loss: 1.153624, imid loss: 0.137167, cmid loss: 1.016456 
Epoch (189), Batch(40/107), loss: 1.147103, imid loss: 0.137445, cmid loss: 1.009658 
Epoch (189), Batch(60/107), loss: 1.146146, imid loss: 0.134508, cmid loss: 1.011638 
Epoch (189), Batch(80/107), loss: 1.156792, imid loss: 0.133577, cmid loss: 1.023216 
Epoch (189), Batch(100/107), loss: 1.162020, imid loss: 0.134360, cmid loss: 1.027660 
Train 189, loss: 1.163146
Start validation
Val 189, loss: 8.517041
Linear Accuracy (val): 0.6206597222222222
Start training epoch: (190/300)
Epoch (190), Batch(0/107), loss: 1.178200, imid loss: 0.128851, cmid loss: 1.049349 
Epoch (190), Batch(20/107), loss: 1.156380, imid loss: 0.138771, cmid loss: 1.017609 
Epoch (190), Batch(40/107), loss: 1.167285, imid loss: 0.138612, cmid loss: 1.028672 
Epoch (190), Batch(60/107), loss: 1.160104, imid loss: 0.137003, cmid loss: 1.023100 
Epoch (190), Batch(80/107), loss: 1.166370, imid loss: 0.135565, cmid loss: 1.030805 
Epoch (190), Batch(100/107), loss: 1.172028, imid loss: 0.136411, cmid loss: 1.035617 
Train 190, loss: 1.169671
Start validation
Val 190, loss: 11.220985
Linear Accuracy (val): 0.6171875
==> Saving...
Start training epoch: (191/300)
Epoch (191), Batch(0/107), loss: 0.944645, imid loss: 0.136534, cmid loss: 0.808111 
Epoch (191), Batch(20/107), loss: 1.170828, imid loss: 0.139995, cmid loss: 1.030833 
Epoch (191), Batch(40/107), loss: 1.154409, imid loss: 0.135896, cmid loss: 1.018513 
Epoch (191), Batch(60/107), loss: 1.153013, imid loss: 0.134028, cmid loss: 1.018985 
Epoch (191), Batch(80/107), loss: 1.160863, imid loss: 0.135160, cmid loss: 1.025703 
Epoch (191), Batch(100/107), loss: 1.158747, imid loss: 0.135267, cmid loss: 1.023479 
Train 191, loss: 1.159033
Start validation
Val 191, loss: 9.592905
Linear Accuracy (val): 0.6102430555555556
Start training epoch: (192/300)
Epoch (192), Batch(0/107), loss: 1.181965, imid loss: 0.125275, cmid loss: 1.056690 
Epoch (192), Batch(20/107), loss: 1.113589, imid loss: 0.123249, cmid loss: 0.990340 
Epoch (192), Batch(40/107), loss: 1.143172, imid loss: 0.126420, cmid loss: 1.016753 
Epoch (192), Batch(60/107), loss: 1.153167, imid loss: 0.129764, cmid loss: 1.023403 
Epoch (192), Batch(80/107), loss: 1.157126, imid loss: 0.130703, cmid loss: 1.026423 
Epoch (192), Batch(100/107), loss: 1.154939, imid loss: 0.133036, cmid loss: 1.021902 
Train 192, loss: 1.155035
Start validation
Val 192, loss: 9.381424
Linear Accuracy (val): 0.6076388888888888
Start training epoch: (193/300)
Epoch (193), Batch(0/107), loss: 1.207678, imid loss: 0.157122, cmid loss: 1.050555 
Epoch (193), Batch(20/107), loss: 1.151845, imid loss: 0.134384, cmid loss: 1.017461 
Epoch (193), Batch(40/107), loss: 1.160481, imid loss: 0.135487, cmid loss: 1.024994 
Epoch (193), Batch(60/107), loss: 1.169587, imid loss: 0.134348, cmid loss: 1.035239 
Epoch (193), Batch(80/107), loss: 1.174701, imid loss: 0.134126, cmid loss: 1.040575 
Epoch (193), Batch(100/107), loss: 1.171419, imid loss: 0.133390, cmid loss: 1.038028 
Train 193, loss: 1.172051
Start validation
Val 193, loss: 9.131228
Linear Accuracy (val): 0.6163194444444444
Start training epoch: (194/300)
Epoch (194), Batch(0/107), loss: 1.157062, imid loss: 0.123228, cmid loss: 1.033835 
Epoch (194), Batch(20/107), loss: 1.167328, imid loss: 0.136475, cmid loss: 1.030853 
Epoch (194), Batch(40/107), loss: 1.168722, imid loss: 0.137750, cmid loss: 1.030972 
Epoch (194), Batch(60/107), loss: 1.172769, imid loss: 0.136641, cmid loss: 1.036128 
Epoch (194), Batch(80/107), loss: 1.164239, imid loss: 0.136091, cmid loss: 1.028148 
Epoch (194), Batch(100/107), loss: 1.172272, imid loss: 0.134610, cmid loss: 1.037662 
Train 194, loss: 1.170793
Start validation
Val 194, loss: 8.432919
Linear Accuracy (val): 0.6050347222222222
Start training epoch: (195/300)
Epoch (195), Batch(0/107), loss: 1.197198, imid loss: 0.141892, cmid loss: 1.055306 
Epoch (195), Batch(20/107), loss: 1.163045, imid loss: 0.130923, cmid loss: 1.032122 
Epoch (195), Batch(40/107), loss: 1.167776, imid loss: 0.130522, cmid loss: 1.037254 
Epoch (195), Batch(60/107), loss: 1.164490, imid loss: 0.130972, cmid loss: 1.033518 
Epoch (195), Batch(80/107), loss: 1.161662, imid loss: 0.132178, cmid loss: 1.029484 
Epoch (195), Batch(100/107), loss: 1.164428, imid loss: 0.131898, cmid loss: 1.032529 
Train 195, loss: 1.161427
Start validation
Val 195, loss: 8.624500
Linear Accuracy (val): 0.6137152777777778
Start training epoch: (196/300)
Epoch (196), Batch(0/107), loss: 0.969957, imid loss: 0.103603, cmid loss: 0.866353 
Epoch (196), Batch(20/107), loss: 1.130892, imid loss: 0.128650, cmid loss: 1.002242 
Epoch (196), Batch(40/107), loss: 1.144035, imid loss: 0.130496, cmid loss: 1.013538 
Epoch (196), Batch(60/107), loss: 1.143813, imid loss: 0.131269, cmid loss: 1.012544 
Epoch (196), Batch(80/107), loss: 1.147188, imid loss: 0.132873, cmid loss: 1.014315 
Epoch (196), Batch(100/107), loss: 1.151537, imid loss: 0.131350, cmid loss: 1.020187 
Train 196, loss: 1.150439
Start validation
Val 196, loss: 11.028576
Linear Accuracy (val): 0.6015625
Start training epoch: (197/300)
Epoch (197), Batch(0/107), loss: 1.183723, imid loss: 0.116181, cmid loss: 1.067542 
Epoch (197), Batch(20/107), loss: 1.135719, imid loss: 0.134697, cmid loss: 1.001021 
Epoch (197), Batch(40/107), loss: 1.139954, imid loss: 0.136551, cmid loss: 1.003403 
Epoch (197), Batch(60/107), loss: 1.147362, imid loss: 0.135951, cmid loss: 1.011411 
Epoch (197), Batch(80/107), loss: 1.142913, imid loss: 0.135301, cmid loss: 1.007612 
Epoch (197), Batch(100/107), loss: 1.145296, imid loss: 0.135223, cmid loss: 1.010073 
Train 197, loss: 1.144925
Start validation
Val 197, loss: 8.382174
Linear Accuracy (val): 0.6067708333333334
Start training epoch: (198/300)
Epoch (198), Batch(0/107), loss: 1.136501, imid loss: 0.148634, cmid loss: 0.987867 
Epoch (198), Batch(20/107), loss: 1.145621, imid loss: 0.134811, cmid loss: 1.010810 
Epoch (198), Batch(40/107), loss: 1.141287, imid loss: 0.134864, cmid loss: 1.006423 
Epoch (198), Batch(60/107), loss: 1.141142, imid loss: 0.136077, cmid loss: 1.005065 
Epoch (198), Batch(80/107), loss: 1.145619, imid loss: 0.136577, cmid loss: 1.009042 
Epoch (198), Batch(100/107), loss: 1.142298, imid loss: 0.135216, cmid loss: 1.007082 
Train 198, loss: 1.142903
Start validation
Val 198, loss: 9.752009
Linear Accuracy (val): 0.6050347222222222
Start training epoch: (199/300)
Epoch (199), Batch(0/107), loss: 1.059391, imid loss: 0.106038, cmid loss: 0.953353 
Epoch (199), Batch(20/107), loss: 1.151079, imid loss: 0.131030, cmid loss: 1.020048 
Epoch (199), Batch(40/107), loss: 1.159229, imid loss: 0.134757, cmid loss: 1.024471 
Epoch (199), Batch(60/107), loss: 1.165703, imid loss: 0.137933, cmid loss: 1.027770 
Epoch (199), Batch(80/107), loss: 1.159900, imid loss: 0.137401, cmid loss: 1.022499 
Epoch (199), Batch(100/107), loss: 1.148893, imid loss: 0.136170, cmid loss: 1.012723 
Train 199, loss: 1.150076
Start validation
Val 199, loss: 9.217070
Linear Accuracy (val): 0.6128472222222222
Start training epoch: (200/300)
Epoch (200), Batch(0/107), loss: 1.107735, imid loss: 0.117591, cmid loss: 0.990144 
Epoch (200), Batch(20/107), loss: 1.145320, imid loss: 0.136534, cmid loss: 1.008785 
Epoch (200), Batch(40/107), loss: 1.148854, imid loss: 0.134080, cmid loss: 1.014774 
Epoch (200), Batch(60/107), loss: 1.150356, imid loss: 0.135959, cmid loss: 1.014397 
Epoch (200), Batch(80/107), loss: 1.149498, imid loss: 0.134930, cmid loss: 1.014569 
Epoch (200), Batch(100/107), loss: 1.156433, imid loss: 0.136299, cmid loss: 1.020134 
Train 200, loss: 1.155977
Start validation
Val 200, loss: 9.193591
Linear Accuracy (val): 0.609375
==> Saving...
Start training epoch: (201/300)
Epoch (201), Batch(0/107), loss: 0.954433, imid loss: 0.137818, cmid loss: 0.816615 
Epoch (201), Batch(20/107), loss: 1.100809, imid loss: 0.137544, cmid loss: 0.963265 
Epoch (201), Batch(40/107), loss: 1.109663, imid loss: 0.136673, cmid loss: 0.972990 
Epoch (201), Batch(60/107), loss: 1.123599, imid loss: 0.136131, cmid loss: 0.987468 
Epoch (201), Batch(80/107), loss: 1.132799, imid loss: 0.136021, cmid loss: 0.996778 
Epoch (201), Batch(100/107), loss: 1.129270, imid loss: 0.133403, cmid loss: 0.995867 
Train 201, loss: 1.129499
Start validation
Val 201, loss: 8.949192
Linear Accuracy (val): 0.6050347222222222
Start training epoch: (202/300)
Epoch (202), Batch(0/107), loss: 1.262048, imid loss: 0.151306, cmid loss: 1.110742 
Epoch (202), Batch(20/107), loss: 1.091064, imid loss: 0.130533, cmid loss: 0.960531 
Epoch (202), Batch(40/107), loss: 1.122094, imid loss: 0.130454, cmid loss: 0.991641 
Epoch (202), Batch(60/107), loss: 1.134690, imid loss: 0.131364, cmid loss: 1.003326 
Epoch (202), Batch(80/107), loss: 1.130958, imid loss: 0.130344, cmid loss: 1.000614 
Epoch (202), Batch(100/107), loss: 1.132572, imid loss: 0.130738, cmid loss: 1.001834 
Train 202, loss: 1.132958
Start validation
Val 202, loss: 8.411947
Linear Accuracy (val): 0.6059027777777778
Start training epoch: (203/300)
Epoch (203), Batch(0/107), loss: 1.148922, imid loss: 0.122387, cmid loss: 1.026535 
Epoch (203), Batch(20/107), loss: 1.126904, imid loss: 0.130474, cmid loss: 0.996430 
Epoch (203), Batch(40/107), loss: 1.143805, imid loss: 0.132798, cmid loss: 1.011007 
Epoch (203), Batch(60/107), loss: 1.134417, imid loss: 0.133167, cmid loss: 1.001250 
Epoch (203), Batch(80/107), loss: 1.129206, imid loss: 0.131940, cmid loss: 0.997266 
Epoch (203), Batch(100/107), loss: 1.139251, imid loss: 0.131615, cmid loss: 1.007636 
Train 203, loss: 1.138362
Start validation
Val 203, loss: 11.369452
Linear Accuracy (val): 0.6076388888888888
Start training epoch: (204/300)
Epoch (204), Batch(0/107), loss: 1.221709, imid loss: 0.137514, cmid loss: 1.084195 
Epoch (204), Batch(20/107), loss: 1.145346, imid loss: 0.135309, cmid loss: 1.010037 
Epoch (204), Batch(40/107), loss: 1.128453, imid loss: 0.133375, cmid loss: 0.995078 
Epoch (204), Batch(60/107), loss: 1.132779, imid loss: 0.131425, cmid loss: 1.001354 
Epoch (204), Batch(80/107), loss: 1.134707, imid loss: 0.132204, cmid loss: 1.002503 
Epoch (204), Batch(100/107), loss: 1.134254, imid loss: 0.133678, cmid loss: 1.000577 
Train 204, loss: 1.135771
Start validation
Val 204, loss: 9.256425
Linear Accuracy (val): 0.6111111111111112
Start training epoch: (205/300)
Epoch (205), Batch(0/107), loss: 1.262076, imid loss: 0.125698, cmid loss: 1.136378 
Epoch (205), Batch(20/107), loss: 1.152094, imid loss: 0.132854, cmid loss: 1.019240 
Epoch (205), Batch(40/107), loss: 1.131976, imid loss: 0.127560, cmid loss: 1.004416 
Epoch (205), Batch(60/107), loss: 1.131031, imid loss: 0.129232, cmid loss: 1.001800 
Epoch (205), Batch(80/107), loss: 1.130730, imid loss: 0.130039, cmid loss: 1.000691 
Epoch (205), Batch(100/107), loss: 1.126719, imid loss: 0.130589, cmid loss: 0.996130 
Train 205, loss: 1.126450
Start validation
Val 205, loss: 11.271699
Linear Accuracy (val): 0.6006944444444444
Start training epoch: (206/300)
Epoch (206), Batch(0/107), loss: 1.084883, imid loss: 0.112811, cmid loss: 0.972073 
Epoch (206), Batch(20/107), loss: 1.133584, imid loss: 0.127939, cmid loss: 1.005645 
Epoch (206), Batch(40/107), loss: 1.119388, imid loss: 0.126828, cmid loss: 0.992560 
Epoch (206), Batch(60/107), loss: 1.127834, imid loss: 0.127408, cmid loss: 1.000426 
Epoch (206), Batch(80/107), loss: 1.139342, imid loss: 0.130010, cmid loss: 1.009332 
Epoch (206), Batch(100/107), loss: 1.135887, imid loss: 0.131181, cmid loss: 1.004705 
Train 206, loss: 1.133006
Start validation
Val 206, loss: 11.096011
Linear Accuracy (val): 0.6128472222222222
Start training epoch: (207/300)
Epoch (207), Batch(0/107), loss: 1.151211, imid loss: 0.117514, cmid loss: 1.033697 
Epoch (207), Batch(20/107), loss: 1.127123, imid loss: 0.131158, cmid loss: 0.995965 
Epoch (207), Batch(40/107), loss: 1.120535, imid loss: 0.132450, cmid loss: 0.988085 
Epoch (207), Batch(60/107), loss: 1.120008, imid loss: 0.129589, cmid loss: 0.990420 
Epoch (207), Batch(80/107), loss: 1.121361, imid loss: 0.130686, cmid loss: 0.990675 
Epoch (207), Batch(100/107), loss: 1.125192, imid loss: 0.130896, cmid loss: 0.994296 
Train 207, loss: 1.121536
Start validation
Val 207, loss: 11.054789
Linear Accuracy (val): 0.6180555555555556
Start training epoch: (208/300)
Epoch (208), Batch(0/107), loss: 1.069570, imid loss: 0.117142, cmid loss: 0.952428 
Epoch (208), Batch(20/107), loss: 1.119097, imid loss: 0.130016, cmid loss: 0.989081 
Epoch (208), Batch(40/107), loss: 1.111502, imid loss: 0.129428, cmid loss: 0.982074 
Epoch (208), Batch(60/107), loss: 1.115564, imid loss: 0.130034, cmid loss: 0.985530 
Epoch (208), Batch(80/107), loss: 1.114212, imid loss: 0.131166, cmid loss: 0.983046 
Epoch (208), Batch(100/107), loss: 1.111188, imid loss: 0.131029, cmid loss: 0.980159 
Train 208, loss: 1.111258
Start validation
Val 208, loss: 10.128525
Linear Accuracy (val): 0.6102430555555556
Start training epoch: (209/300)
Epoch (209), Batch(0/107), loss: 1.056260, imid loss: 0.093983, cmid loss: 0.962277 
Epoch (209), Batch(20/107), loss: 1.158579, imid loss: 0.131604, cmid loss: 1.026975 
Epoch (209), Batch(40/107), loss: 1.129872, imid loss: 0.127927, cmid loss: 1.001946 
Epoch (209), Batch(60/107), loss: 1.134244, imid loss: 0.131533, cmid loss: 1.002710 
Epoch (209), Batch(80/107), loss: 1.130692, imid loss: 0.132239, cmid loss: 0.998453 
Epoch (209), Batch(100/107), loss: 1.126389, imid loss: 0.132404, cmid loss: 0.993985 
Train 209, loss: 1.125479
Start validation
Val 209, loss: 9.349732
Linear Accuracy (val): 0.6215277777777778
Start training epoch: (210/300)
Epoch (210), Batch(0/107), loss: 1.030365, imid loss: 0.100007, cmid loss: 0.930358 
Epoch (210), Batch(20/107), loss: 1.144141, imid loss: 0.127109, cmid loss: 1.017032 
Epoch (210), Batch(40/107), loss: 1.130875, imid loss: 0.129692, cmid loss: 1.001183 
Epoch (210), Batch(60/107), loss: 1.125174, imid loss: 0.130967, cmid loss: 0.994207 
Epoch (210), Batch(80/107), loss: 1.133289, imid loss: 0.132212, cmid loss: 1.001076 
Epoch (210), Batch(100/107), loss: 1.126849, imid loss: 0.131679, cmid loss: 0.995170 
Train 210, loss: 1.128632
Start validation
Val 210, loss: 2.058661
Linear Accuracy (val): 0.6128472222222222
==> Saving...
Start training epoch: (211/300)
Epoch (211), Batch(0/107), loss: 1.139141, imid loss: 0.131254, cmid loss: 1.007887 
Epoch (211), Batch(20/107), loss: 1.115880, imid loss: 0.129807, cmid loss: 0.986073 
Epoch (211), Batch(40/107), loss: 1.121117, imid loss: 0.132374, cmid loss: 0.988743 
Epoch (211), Batch(60/107), loss: 1.121283, imid loss: 0.132264, cmid loss: 0.989020 
Epoch (211), Batch(80/107), loss: 1.122292, imid loss: 0.131317, cmid loss: 0.990975 
Epoch (211), Batch(100/107), loss: 1.124170, imid loss: 0.132211, cmid loss: 0.991959 
Train 211, loss: 1.121125
Start validation
Val 211, loss: 9.867518
Linear Accuracy (val): 0.6197916666666666
Start training epoch: (212/300)
Epoch (212), Batch(0/107), loss: 0.975171, imid loss: 0.110946, cmid loss: 0.864225 
Epoch (212), Batch(20/107), loss: 1.128356, imid loss: 0.128512, cmid loss: 0.999844 
Epoch (212), Batch(40/107), loss: 1.116202, imid loss: 0.124437, cmid loss: 0.991765 
Epoch (212), Batch(60/107), loss: 1.118087, imid loss: 0.125540, cmid loss: 0.992547 
Epoch (212), Batch(80/107), loss: 1.111300, imid loss: 0.125945, cmid loss: 0.985355 
Epoch (212), Batch(100/107), loss: 1.105986, imid loss: 0.127019, cmid loss: 0.978967 
Train 212, loss: 1.106805
Start validation
Val 212, loss: 8.400458
Linear Accuracy (val): 0.6189236111111112
Start training epoch: (213/300)
Epoch (213), Batch(0/107), loss: 1.055867, imid loss: 0.120821, cmid loss: 0.935046 
Epoch (213), Batch(20/107), loss: 1.131394, imid loss: 0.128798, cmid loss: 1.002595 
Epoch (213), Batch(40/107), loss: 1.107401, imid loss: 0.128980, cmid loss: 0.978421 
Epoch (213), Batch(60/107), loss: 1.116526, imid loss: 0.128430, cmid loss: 0.988097 
Epoch (213), Batch(80/107), loss: 1.119844, imid loss: 0.129265, cmid loss: 0.990580 
Epoch (213), Batch(100/107), loss: 1.117280, imid loss: 0.129841, cmid loss: 0.987439 
Train 213, loss: 1.114974
Start validation
Val 213, loss: 8.495276
Linear Accuracy (val): 0.6067708333333334
Start training epoch: (214/300)
Epoch (214), Batch(0/107), loss: 1.046929, imid loss: 0.116668, cmid loss: 0.930261 
Epoch (214), Batch(20/107), loss: 1.118870, imid loss: 0.133423, cmid loss: 0.985448 
Epoch (214), Batch(40/107), loss: 1.115649, imid loss: 0.130267, cmid loss: 0.985382 
Epoch (214), Batch(60/107), loss: 1.117550, imid loss: 0.131284, cmid loss: 0.986266 
Epoch (214), Batch(80/107), loss: 1.117611, imid loss: 0.129981, cmid loss: 0.987630 
Epoch (214), Batch(100/107), loss: 1.114114, imid loss: 0.128843, cmid loss: 0.985271 
Train 214, loss: 1.110072
Start validation
Val 214, loss: 2.552818
Linear Accuracy (val): 0.6171875
Start training epoch: (215/300)
Epoch (215), Batch(0/107), loss: 1.241447, imid loss: 0.138301, cmid loss: 1.103147 
Epoch (215), Batch(20/107), loss: 1.111531, imid loss: 0.131887, cmid loss: 0.979644 
Epoch (215), Batch(40/107), loss: 1.119981, imid loss: 0.133386, cmid loss: 0.986594 
Epoch (215), Batch(60/107), loss: 1.109412, imid loss: 0.132540, cmid loss: 0.976872 
Epoch (215), Batch(80/107), loss: 1.111749, imid loss: 0.132029, cmid loss: 0.979720 
Epoch (215), Batch(100/107), loss: 1.114900, imid loss: 0.132831, cmid loss: 0.982069 
Train 215, loss: 1.118658
Start validation
Val 215, loss: 11.417368
Linear Accuracy (val): 0.6041666666666666
Start training epoch: (216/300)
Epoch (216), Batch(0/107), loss: 1.096986, imid loss: 0.114182, cmid loss: 0.982804 
Epoch (216), Batch(20/107), loss: 1.090030, imid loss: 0.123803, cmid loss: 0.966228 
Epoch (216), Batch(40/107), loss: 1.099823, imid loss: 0.125491, cmid loss: 0.974333 
Epoch (216), Batch(60/107), loss: 1.096805, imid loss: 0.125881, cmid loss: 0.970924 
Epoch (216), Batch(80/107), loss: 1.103956, imid loss: 0.126918, cmid loss: 0.977038 
Epoch (216), Batch(100/107), loss: 1.100998, imid loss: 0.125664, cmid loss: 0.975334 
Train 216, loss: 1.098562
Start validation
Val 216, loss: 11.305119
Linear Accuracy (val): 0.5946180555555556
Start training epoch: (217/300)
Epoch (217), Batch(0/107), loss: 1.053637, imid loss: 0.107075, cmid loss: 0.946562 
Epoch (217), Batch(20/107), loss: 1.091964, imid loss: 0.130038, cmid loss: 0.961927 
Epoch (217), Batch(40/107), loss: 1.119436, imid loss: 0.130541, cmid loss: 0.988895 
Epoch (217), Batch(60/107), loss: 1.105955, imid loss: 0.130102, cmid loss: 0.975853 
Epoch (217), Batch(80/107), loss: 1.102171, imid loss: 0.128913, cmid loss: 0.973258 
Epoch (217), Batch(100/107), loss: 1.102780, imid loss: 0.128245, cmid loss: 0.974535 
Train 217, loss: 1.102536
Start validation
Val 217, loss: 9.675306
Linear Accuracy (val): 0.6171875
Start training epoch: (218/300)
Epoch (218), Batch(0/107), loss: 0.893997, imid loss: 0.107085, cmid loss: 0.786912 
Epoch (218), Batch(20/107), loss: 1.079638, imid loss: 0.124061, cmid loss: 0.955576 
Epoch (218), Batch(40/107), loss: 1.083291, imid loss: 0.125840, cmid loss: 0.957451 
Epoch (218), Batch(60/107), loss: 1.095782, imid loss: 0.126537, cmid loss: 0.969245 
Epoch (218), Batch(80/107), loss: 1.104116, imid loss: 0.127378, cmid loss: 0.976738 
Epoch (218), Batch(100/107), loss: 1.097514, imid loss: 0.127587, cmid loss: 0.969927 
Train 218, loss: 1.095956
Start validation
Val 218, loss: 2.533866
Linear Accuracy (val): 0.6137152777777778
Start training epoch: (219/300)
Epoch (219), Batch(0/107), loss: 1.081192, imid loss: 0.138404, cmid loss: 0.942788 
Epoch (219), Batch(20/107), loss: 1.097224, imid loss: 0.128055, cmid loss: 0.969169 
Epoch (219), Batch(40/107), loss: 1.084285, imid loss: 0.127726, cmid loss: 0.956558 
Epoch (219), Batch(60/107), loss: 1.088447, imid loss: 0.128936, cmid loss: 0.959511 
Epoch (219), Batch(80/107), loss: 1.084523, imid loss: 0.126788, cmid loss: 0.957735 
Epoch (219), Batch(100/107), loss: 1.087295, imid loss: 0.128071, cmid loss: 0.959224 
Train 219, loss: 1.088735
Start validation
Val 219, loss: 3.057724
Linear Accuracy (val): 0.6197916666666666
Start training epoch: (220/300)
Epoch (220), Batch(0/107), loss: 1.002330, imid loss: 0.095088, cmid loss: 0.907242 
Epoch (220), Batch(20/107), loss: 1.047623, imid loss: 0.120751, cmid loss: 0.926872 
Epoch (220), Batch(40/107), loss: 1.075099, imid loss: 0.126143, cmid loss: 0.948955 
Epoch (220), Batch(60/107), loss: 1.083427, imid loss: 0.127607, cmid loss: 0.955820 
Epoch (220), Batch(80/107), loss: 1.087308, imid loss: 0.126869, cmid loss: 0.960438 
Epoch (220), Batch(100/107), loss: 1.095658, imid loss: 0.128887, cmid loss: 0.966770 
Train 220, loss: 1.099302
Start validation
Val 220, loss: 11.317083
Linear Accuracy (val): 0.6085069444444444
==> Saving...
Start training epoch: (221/300)
Epoch (221), Batch(0/107), loss: 0.996246, imid loss: 0.104720, cmid loss: 0.891526 
Epoch (221), Batch(20/107), loss: 1.054330, imid loss: 0.115131, cmid loss: 0.939199 
Epoch (221), Batch(40/107), loss: 1.061341, imid loss: 0.121254, cmid loss: 0.940087 
Epoch (221), Batch(60/107), loss: 1.067420, imid loss: 0.124409, cmid loss: 0.943011 
Epoch (221), Batch(80/107), loss: 1.081132, imid loss: 0.126117, cmid loss: 0.955015 
Epoch (221), Batch(100/107), loss: 1.085082, imid loss: 0.127529, cmid loss: 0.957553 
Train 221, loss: 1.083486
Start validation
Val 221, loss: 8.604847
Linear Accuracy (val): 0.6206597222222222
Start training epoch: (222/300)
Epoch (222), Batch(0/107), loss: 0.956955, imid loss: 0.115987, cmid loss: 0.840969 
Epoch (222), Batch(20/107), loss: 1.062692, imid loss: 0.124453, cmid loss: 0.938239 
Epoch (222), Batch(40/107), loss: 1.085630, imid loss: 0.126740, cmid loss: 0.958890 
Epoch (222), Batch(60/107), loss: 1.092432, imid loss: 0.127245, cmid loss: 0.965187 
Epoch (222), Batch(80/107), loss: 1.094494, imid loss: 0.127096, cmid loss: 0.967398 
Epoch (222), Batch(100/107), loss: 1.096166, imid loss: 0.127750, cmid loss: 0.968416 
Train 222, loss: 1.097476
Start validation
Val 222, loss: 11.228444
Linear Accuracy (val): 0.609375
Start training epoch: (223/300)
Epoch (223), Batch(0/107), loss: 1.094441, imid loss: 0.149769, cmid loss: 0.944672 
Epoch (223), Batch(20/107), loss: 1.073518, imid loss: 0.118624, cmid loss: 0.954894 
Epoch (223), Batch(40/107), loss: 1.071390, imid loss: 0.121030, cmid loss: 0.950360 
Epoch (223), Batch(60/107), loss: 1.068116, imid loss: 0.123092, cmid loss: 0.945024 
Epoch (223), Batch(80/107), loss: 1.073961, imid loss: 0.125472, cmid loss: 0.948489 
Epoch (223), Batch(100/107), loss: 1.074454, imid loss: 0.125177, cmid loss: 0.949278 
Train 223, loss: 1.071626
Start validation
Val 223, loss: 6.014338
Linear Accuracy (val): 0.6119791666666666
Start training epoch: (224/300)
Epoch (224), Batch(0/107), loss: 1.226381, imid loss: 0.154755, cmid loss: 1.071626 
Epoch (224), Batch(20/107), loss: 1.088397, imid loss: 0.128766, cmid loss: 0.959630 
Epoch (224), Batch(40/107), loss: 1.087155, imid loss: 0.128665, cmid loss: 0.958490 
Epoch (224), Batch(60/107), loss: 1.077086, imid loss: 0.128967, cmid loss: 0.948119 
Epoch (224), Batch(80/107), loss: 1.085355, imid loss: 0.129524, cmid loss: 0.955831 
Epoch (224), Batch(100/107), loss: 1.083474, imid loss: 0.129389, cmid loss: 0.954085 
Train 224, loss: 1.086603
Start validation
Val 224, loss: 9.945280
Linear Accuracy (val): 0.6137152777777778
Start training epoch: (225/300)
Epoch (225), Batch(0/107), loss: 1.005117, imid loss: 0.096487, cmid loss: 0.908630 
Epoch (225), Batch(20/107), loss: 1.095512, imid loss: 0.130243, cmid loss: 0.965269 
Epoch (225), Batch(40/107), loss: 1.093834, imid loss: 0.127270, cmid loss: 0.966564 
Epoch (225), Batch(60/107), loss: 1.102033, imid loss: 0.128011, cmid loss: 0.974022 
Epoch (225), Batch(80/107), loss: 1.099841, imid loss: 0.127832, cmid loss: 0.972009 
Epoch (225), Batch(100/107), loss: 1.096878, imid loss: 0.128224, cmid loss: 0.968653 
Train 225, loss: 1.096352
Start validation
Val 225, loss: 11.151203
Linear Accuracy (val): 0.6223958333333334
Start training epoch: (226/300)
Epoch (226), Batch(0/107), loss: 0.996346, imid loss: 0.125259, cmid loss: 0.871087 
Epoch (226), Batch(20/107), loss: 1.092590, imid loss: 0.131548, cmid loss: 0.961042 
Epoch (226), Batch(40/107), loss: 1.089113, imid loss: 0.131360, cmid loss: 0.957753 
Epoch (226), Batch(60/107), loss: 1.092895, imid loss: 0.131550, cmid loss: 0.961345 
Epoch (226), Batch(80/107), loss: 1.089162, imid loss: 0.129955, cmid loss: 0.959207 
Epoch (226), Batch(100/107), loss: 1.091076, imid loss: 0.128671, cmid loss: 0.962405 
Train 226, loss: 1.089523
Start validation
Val 226, loss: 11.370978
Linear Accuracy (val): 0.6067708333333334
Start training epoch: (227/300)
Epoch (227), Batch(0/107), loss: 1.064697, imid loss: 0.107575, cmid loss: 0.957122 
Epoch (227), Batch(20/107), loss: 1.071902, imid loss: 0.122873, cmid loss: 0.949029 
Epoch (227), Batch(40/107), loss: 1.092131, imid loss: 0.124767, cmid loss: 0.967364 
Epoch (227), Batch(60/107), loss: 1.079554, imid loss: 0.123147, cmid loss: 0.956407 
Epoch (227), Batch(80/107), loss: 1.083381, imid loss: 0.124313, cmid loss: 0.959068 
Epoch (227), Batch(100/107), loss: 1.087690, imid loss: 0.125532, cmid loss: 0.962158 
Train 227, loss: 1.085981
Start validation
Val 227, loss: 1.781028
Linear Accuracy (val): 0.6163194444444444
Start training epoch: (228/300)
Epoch (228), Batch(0/107), loss: 1.191116, imid loss: 0.168621, cmid loss: 1.022494 
Epoch (228), Batch(20/107), loss: 1.130210, imid loss: 0.130773, cmid loss: 0.999437 
Epoch (228), Batch(40/107), loss: 1.096932, imid loss: 0.126936, cmid loss: 0.969996 
Epoch (228), Batch(60/107), loss: 1.101952, imid loss: 0.125867, cmid loss: 0.976085 
Epoch (228), Batch(80/107), loss: 1.102074, imid loss: 0.127434, cmid loss: 0.974640 
Epoch (228), Batch(100/107), loss: 1.101086, imid loss: 0.127928, cmid loss: 0.973158 
Train 228, loss: 1.103321
Start validation
Val 228, loss: 11.260861
Linear Accuracy (val): 0.6006944444444444
Start training epoch: (229/300)
Epoch (229), Batch(0/107), loss: 0.978425, imid loss: 0.110475, cmid loss: 0.867950 
Epoch (229), Batch(20/107), loss: 1.059158, imid loss: 0.130409, cmid loss: 0.928750 
Epoch (229), Batch(40/107), loss: 1.063749, imid loss: 0.126002, cmid loss: 0.937747 
Epoch (229), Batch(60/107), loss: 1.070326, imid loss: 0.125158, cmid loss: 0.945169 
Epoch (229), Batch(80/107), loss: 1.070303, imid loss: 0.126097, cmid loss: 0.944205 
Epoch (229), Batch(100/107), loss: 1.071634, imid loss: 0.126521, cmid loss: 0.945113 
Train 229, loss: 1.070584
Start validation
Val 229, loss: 8.841427
Linear Accuracy (val): 0.6050347222222222
Start training epoch: (230/300)
Epoch (230), Batch(0/107), loss: 1.065055, imid loss: 0.150322, cmid loss: 0.914734 
Epoch (230), Batch(20/107), loss: 1.086204, imid loss: 0.125677, cmid loss: 0.960527 
Epoch (230), Batch(40/107), loss: 1.065815, imid loss: 0.125749, cmid loss: 0.940066 
Epoch (230), Batch(60/107), loss: 1.080456, imid loss: 0.127190, cmid loss: 0.953267 
Epoch (230), Batch(80/107), loss: 1.089230, imid loss: 0.126728, cmid loss: 0.962503 
Epoch (230), Batch(100/107), loss: 1.080457, imid loss: 0.126080, cmid loss: 0.954376 
Train 230, loss: 1.079721
Start validation
Val 230, loss: 11.140390
Linear Accuracy (val): 0.609375
==> Saving...
Start training epoch: (231/300)
Epoch (231), Batch(0/107), loss: 1.183337, imid loss: 0.128901, cmid loss: 1.054435 
Epoch (231), Batch(20/107), loss: 1.097802, imid loss: 0.134123, cmid loss: 0.963679 
Epoch (231), Batch(40/107), loss: 1.070743, imid loss: 0.132619, cmid loss: 0.938123 
Epoch (231), Batch(60/107), loss: 1.068506, imid loss: 0.128221, cmid loss: 0.940285 
Epoch (231), Batch(80/107), loss: 1.072235, imid loss: 0.127484, cmid loss: 0.944752 
Epoch (231), Batch(100/107), loss: 1.066986, imid loss: 0.126341, cmid loss: 0.940644 
Train 231, loss: 1.067034
Start validation
Val 231, loss: 9.735193
Linear Accuracy (val): 0.6102430555555556
Start training epoch: (232/300)
Epoch (232), Batch(0/107), loss: 0.937693, imid loss: 0.110559, cmid loss: 0.827133 
Epoch (232), Batch(20/107), loss: 1.075531, imid loss: 0.130708, cmid loss: 0.944824 
Epoch (232), Batch(40/107), loss: 1.070715, imid loss: 0.128152, cmid loss: 0.942563 
Epoch (232), Batch(60/107), loss: 1.068520, imid loss: 0.128903, cmid loss: 0.939617 
Epoch (232), Batch(80/107), loss: 1.069168, imid loss: 0.126943, cmid loss: 0.942225 
Epoch (232), Batch(100/107), loss: 1.074204, imid loss: 0.128172, cmid loss: 0.946032 
Train 232, loss: 1.073462
Start validation
Val 232, loss: 6.612900
Linear Accuracy (val): 0.6111111111111112
Start training epoch: (233/300)
Epoch (233), Batch(0/107), loss: 0.938297, imid loss: 0.124257, cmid loss: 0.814040 
Epoch (233), Batch(20/107), loss: 1.086137, imid loss: 0.131461, cmid loss: 0.954676 
Epoch (233), Batch(40/107), loss: 1.081250, imid loss: 0.127356, cmid loss: 0.953894 
Epoch (233), Batch(60/107), loss: 1.065429, imid loss: 0.126195, cmid loss: 0.939235 
Epoch (233), Batch(80/107), loss: 1.061405, imid loss: 0.125816, cmid loss: 0.935589 
Epoch (233), Batch(100/107), loss: 1.059518, imid loss: 0.125712, cmid loss: 0.933806 
Train 233, loss: 1.057883
Start validation
Val 233, loss: 8.667518
Linear Accuracy (val): 0.6050347222222222
Start training epoch: (234/300)
Epoch (234), Batch(0/107), loss: 1.045636, imid loss: 0.128472, cmid loss: 0.917164 
Epoch (234), Batch(20/107), loss: 1.088187, imid loss: 0.134158, cmid loss: 0.954029 
Epoch (234), Batch(40/107), loss: 1.086713, imid loss: 0.129143, cmid loss: 0.957570 
Epoch (234), Batch(60/107), loss: 1.083171, imid loss: 0.127092, cmid loss: 0.956079 
Epoch (234), Batch(80/107), loss: 1.087359, imid loss: 0.126943, cmid loss: 0.960416 
Epoch (234), Batch(100/107), loss: 1.092801, imid loss: 0.126624, cmid loss: 0.966177 
Train 234, loss: 1.093071
Start validation
Val 234, loss: 11.148459
Linear Accuracy (val): 0.5980902777777778
Start training epoch: (235/300)
Epoch (235), Batch(0/107), loss: 1.057461, imid loss: 0.117452, cmid loss: 0.940010 
Epoch (235), Batch(20/107), loss: 1.069584, imid loss: 0.127399, cmid loss: 0.942185 
Epoch (235), Batch(40/107), loss: 1.088508, imid loss: 0.127058, cmid loss: 0.961450 
Epoch (235), Batch(60/107), loss: 1.086963, imid loss: 0.126362, cmid loss: 0.960601 
Epoch (235), Batch(80/107), loss: 1.078742, imid loss: 0.125366, cmid loss: 0.953376 
Epoch (235), Batch(100/107), loss: 1.072010, imid loss: 0.124872, cmid loss: 0.947138 
Train 235, loss: 1.069745
Start validation
Val 235, loss: 11.376491
Linear Accuracy (val): 0.6015625
Start training epoch: (236/300)
Epoch (236), Batch(0/107), loss: 0.929018, imid loss: 0.105010, cmid loss: 0.824008 
Epoch (236), Batch(20/107), loss: 1.063552, imid loss: 0.129046, cmid loss: 0.934506 
Epoch (236), Batch(40/107), loss: 1.053133, imid loss: 0.128069, cmid loss: 0.925065 
Epoch (236), Batch(60/107), loss: 1.063458, imid loss: 0.127278, cmid loss: 0.936180 
Epoch (236), Batch(80/107), loss: 1.055923, imid loss: 0.127838, cmid loss: 0.928086 
Epoch (236), Batch(100/107), loss: 1.064508, imid loss: 0.128019, cmid loss: 0.936489 
Train 236, loss: 1.062445
Start validation
Val 236, loss: 9.064232
Linear Accuracy (val): 0.6154513888888888
Start training epoch: (237/300)
Epoch (237), Batch(0/107), loss: 1.365597, imid loss: 0.126512, cmid loss: 1.239085 
Epoch (237), Batch(20/107), loss: 1.064598, imid loss: 0.124979, cmid loss: 0.939619 
Epoch (237), Batch(40/107), loss: 1.058346, imid loss: 0.125051, cmid loss: 0.933296 
Epoch (237), Batch(60/107), loss: 1.054683, imid loss: 0.124122, cmid loss: 0.930561 
Epoch (237), Batch(80/107), loss: 1.060736, imid loss: 0.124157, cmid loss: 0.936579 
Epoch (237), Batch(100/107), loss: 1.058413, imid loss: 0.123468, cmid loss: 0.934945 
Train 237, loss: 1.059917
Start validation
Val 237, loss: 11.301331
Linear Accuracy (val): 0.5972222222222222
Start training epoch: (238/300)
Epoch (238), Batch(0/107), loss: 1.126740, imid loss: 0.140990, cmid loss: 0.985749 
Epoch (238), Batch(20/107), loss: 1.062413, imid loss: 0.125138, cmid loss: 0.937274 
Epoch (238), Batch(40/107), loss: 1.069927, imid loss: 0.124082, cmid loss: 0.945845 
Epoch (238), Batch(60/107), loss: 1.066423, imid loss: 0.124815, cmid loss: 0.941609 
Epoch (238), Batch(80/107), loss: 1.060695, imid loss: 0.123901, cmid loss: 0.936794 
Epoch (238), Batch(100/107), loss: 1.063306, imid loss: 0.123743, cmid loss: 0.939562 
Train 238, loss: 1.064856
Start validation
Val 238, loss: 8.335374
Linear Accuracy (val): 0.6128472222222222
Start training epoch: (239/300)
Epoch (239), Batch(0/107), loss: 1.056568, imid loss: 0.127638, cmid loss: 0.928930 
Epoch (239), Batch(20/107), loss: 1.037566, imid loss: 0.122382, cmid loss: 0.915184 
Epoch (239), Batch(40/107), loss: 1.036094, imid loss: 0.123071, cmid loss: 0.913024 
Epoch (239), Batch(60/107), loss: 1.038443, imid loss: 0.122697, cmid loss: 0.915746 
Epoch (239), Batch(80/107), loss: 1.044966, imid loss: 0.123427, cmid loss: 0.921539 
Epoch (239), Batch(100/107), loss: 1.045149, imid loss: 0.125143, cmid loss: 0.920007 
Train 239, loss: 1.048666
Start validation
Val 239, loss: 9.574170
Linear Accuracy (val): 0.6085069444444444
Start training epoch: (240/300)
Epoch (240), Batch(0/107), loss: 0.977858, imid loss: 0.100941, cmid loss: 0.876917 
Epoch (240), Batch(20/107), loss: 1.061466, imid loss: 0.125532, cmid loss: 0.935935 
Epoch (240), Batch(40/107), loss: 1.045308, imid loss: 0.123379, cmid loss: 0.921929 
Epoch (240), Batch(60/107), loss: 1.053447, imid loss: 0.122519, cmid loss: 0.930928 
Epoch (240), Batch(80/107), loss: 1.061210, imid loss: 0.123459, cmid loss: 0.937751 
Epoch (240), Batch(100/107), loss: 1.061550, imid loss: 0.122993, cmid loss: 0.938557 
Train 240, loss: 1.057764
Start validation
Val 240, loss: 11.228511
Linear Accuracy (val): 0.5902777777777778
==> Saving...
Start training epoch: (241/300)
Epoch (241), Batch(0/107), loss: 1.066382, imid loss: 0.097908, cmid loss: 0.968473 
Epoch (241), Batch(20/107), loss: 1.040190, imid loss: 0.124227, cmid loss: 0.915964 
Epoch (241), Batch(40/107), loss: 1.043810, imid loss: 0.124298, cmid loss: 0.919512 
Epoch (241), Batch(60/107), loss: 1.052715, imid loss: 0.126539, cmid loss: 0.926176 
Epoch (241), Batch(80/107), loss: 1.051403, imid loss: 0.126204, cmid loss: 0.925199 
Epoch (241), Batch(100/107), loss: 1.048005, imid loss: 0.126549, cmid loss: 0.921456 
Train 241, loss: 1.047336
Start validation
Val 241, loss: 11.226523
Linear Accuracy (val): 0.5980902777777778
Start training epoch: (242/300)
Epoch (242), Batch(0/107), loss: 0.974387, imid loss: 0.126589, cmid loss: 0.847798 
Epoch (242), Batch(20/107), loss: 1.054053, imid loss: 0.131683, cmid loss: 0.922371 
Epoch (242), Batch(40/107), loss: 1.066384, imid loss: 0.132442, cmid loss: 0.933942 
Epoch (242), Batch(60/107), loss: 1.076639, imid loss: 0.130165, cmid loss: 0.946474 
Epoch (242), Batch(80/107), loss: 1.069592, imid loss: 0.129024, cmid loss: 0.940568 
Epoch (242), Batch(100/107), loss: 1.068181, imid loss: 0.126380, cmid loss: 0.941800 
Train 242, loss: 1.069195
Start validation
Val 242, loss: 10.974545
Linear Accuracy (val): 0.5998263888888888
Start training epoch: (243/300)
Epoch (243), Batch(0/107), loss: 1.036429, imid loss: 0.129915, cmid loss: 0.906514 
Epoch (243), Batch(20/107), loss: 1.059476, imid loss: 0.123119, cmid loss: 0.936357 
Epoch (243), Batch(40/107), loss: 1.075154, imid loss: 0.121736, cmid loss: 0.953418 
Epoch (243), Batch(60/107), loss: 1.062946, imid loss: 0.121541, cmid loss: 0.941404 
Epoch (243), Batch(80/107), loss: 1.053786, imid loss: 0.120420, cmid loss: 0.933366 
Epoch (243), Batch(100/107), loss: 1.059019, imid loss: 0.121662, cmid loss: 0.937357 
Train 243, loss: 1.058338
Start validation
Val 243, loss: 5.068819
Linear Accuracy (val): 0.6015625
Start training epoch: (244/300)
Epoch (244), Batch(0/107), loss: 0.920089, imid loss: 0.099369, cmid loss: 0.820720 
Epoch (244), Batch(20/107), loss: 1.054164, imid loss: 0.125686, cmid loss: 0.928478 
Epoch (244), Batch(40/107), loss: 1.039903, imid loss: 0.125176, cmid loss: 0.914727 
Epoch (244), Batch(60/107), loss: 1.056560, imid loss: 0.126682, cmid loss: 0.929878 
Epoch (244), Batch(80/107), loss: 1.056529, imid loss: 0.125114, cmid loss: 0.931414 
Epoch (244), Batch(100/107), loss: 1.053577, imid loss: 0.125166, cmid loss: 0.928411 
Train 244, loss: 1.053332
Start validation
Val 244, loss: 8.160926
Linear Accuracy (val): 0.6145833333333334
Start training epoch: (245/300)
Epoch (245), Batch(0/107), loss: 1.082912, imid loss: 0.118839, cmid loss: 0.964073 
Epoch (245), Batch(20/107), loss: 1.033260, imid loss: 0.124426, cmid loss: 0.908834 
Epoch (245), Batch(40/107), loss: 1.063988, imid loss: 0.128624, cmid loss: 0.935363 
Epoch (245), Batch(60/107), loss: 1.055950, imid loss: 0.128330, cmid loss: 0.927620 
Epoch (245), Batch(80/107), loss: 1.055746, imid loss: 0.127073, cmid loss: 0.928673 
Epoch (245), Batch(100/107), loss: 1.061950, imid loss: 0.126154, cmid loss: 0.935797 
Train 245, loss: 1.059123
Start validation
Val 245, loss: 3.552496
Linear Accuracy (val): 0.6041666666666666
Start training epoch: (246/300)
Epoch (246), Batch(0/107), loss: 1.102135, imid loss: 0.129082, cmid loss: 0.973053 
Epoch (246), Batch(20/107), loss: 1.039075, imid loss: 0.120738, cmid loss: 0.918336 
Epoch (246), Batch(40/107), loss: 1.053740, imid loss: 0.123983, cmid loss: 0.929757 
Epoch (246), Batch(60/107), loss: 1.064093, imid loss: 0.127077, cmid loss: 0.937016 
Epoch (246), Batch(80/107), loss: 1.054234, imid loss: 0.125973, cmid loss: 0.928262 
Epoch (246), Batch(100/107), loss: 1.056888, imid loss: 0.126533, cmid loss: 0.930356 
Train 246, loss: 1.059021
Start validation
Val 246, loss: 8.580349
Linear Accuracy (val): 0.6015625
Start training epoch: (247/300)
Epoch (247), Batch(0/107), loss: 1.072392, imid loss: 0.099252, cmid loss: 0.973140 
Epoch (247), Batch(20/107), loss: 1.049727, imid loss: 0.125609, cmid loss: 0.924117 
Epoch (247), Batch(40/107), loss: 1.049638, imid loss: 0.126632, cmid loss: 0.923007 
Epoch (247), Batch(60/107), loss: 1.048805, imid loss: 0.126516, cmid loss: 0.922289 
Epoch (247), Batch(80/107), loss: 1.049385, imid loss: 0.126924, cmid loss: 0.922461 
Epoch (247), Batch(100/107), loss: 1.045946, imid loss: 0.125647, cmid loss: 0.920299 
Train 247, loss: 1.048718
Start validation
Val 247, loss: 1.559899
Linear Accuracy (val): 0.6189236111111112
Start training epoch: (248/300)
Epoch (248), Batch(0/107), loss: 0.948489, imid loss: 0.125688, cmid loss: 0.822801 
Epoch (248), Batch(20/107), loss: 1.015072, imid loss: 0.125618, cmid loss: 0.889454 
Epoch (248), Batch(40/107), loss: 1.022201, imid loss: 0.122780, cmid loss: 0.899421 
Epoch (248), Batch(60/107), loss: 1.026131, imid loss: 0.123583, cmid loss: 0.902548 
Epoch (248), Batch(80/107), loss: 1.031709, imid loss: 0.123651, cmid loss: 0.908059 
Epoch (248), Batch(100/107), loss: 1.035241, imid loss: 0.123433, cmid loss: 0.911808 
Train 248, loss: 1.038685
Start validation
Val 248, loss: 8.111262
Linear Accuracy (val): 0.6163194444444444
Start training epoch: (249/300)
Epoch (249), Batch(0/107), loss: 0.876036, imid loss: 0.127110, cmid loss: 0.748926 
Epoch (249), Batch(20/107), loss: 1.053952, imid loss: 0.132324, cmid loss: 0.921628 
Epoch (249), Batch(40/107), loss: 1.040067, imid loss: 0.126375, cmid loss: 0.913692 
Epoch (249), Batch(60/107), loss: 1.052167, imid loss: 0.126088, cmid loss: 0.926079 
Epoch (249), Batch(80/107), loss: 1.054608, imid loss: 0.125875, cmid loss: 0.928733 
Epoch (249), Batch(100/107), loss: 1.052989, imid loss: 0.124108, cmid loss: 0.928881 
Train 249, loss: 1.053423
Start validation
Val 249, loss: 11.079108
Linear Accuracy (val): 0.5920138888888888
Start training epoch: (250/300)
Epoch (250), Batch(0/107), loss: 0.886439, imid loss: 0.109563, cmid loss: 0.776876 
Epoch (250), Batch(20/107), loss: 1.035237, imid loss: 0.115144, cmid loss: 0.920092 
Epoch (250), Batch(40/107), loss: 1.041687, imid loss: 0.120688, cmid loss: 0.920999 
Epoch (250), Batch(60/107), loss: 1.033366, imid loss: 0.121749, cmid loss: 0.911617 
Epoch (250), Batch(80/107), loss: 1.038338, imid loss: 0.121806, cmid loss: 0.916532 
Epoch (250), Batch(100/107), loss: 1.039789, imid loss: 0.122728, cmid loss: 0.917060 
Train 250, loss: 1.039856
Start validation
Val 250, loss: 5.904039
Linear Accuracy (val): 0.6267361111111112
==> Saving...
Start training epoch: (251/300)
Epoch (251), Batch(0/107), loss: 1.120573, imid loss: 0.137561, cmid loss: 0.983012 
Epoch (251), Batch(20/107), loss: 1.078697, imid loss: 0.130404, cmid loss: 0.948293 
Epoch (251), Batch(40/107), loss: 1.038605, imid loss: 0.125280, cmid loss: 0.913325 
Epoch (251), Batch(60/107), loss: 1.034213, imid loss: 0.125671, cmid loss: 0.908542 
Epoch (251), Batch(80/107), loss: 1.029170, imid loss: 0.123579, cmid loss: 0.905591 
Epoch (251), Batch(100/107), loss: 1.040038, imid loss: 0.124018, cmid loss: 0.916020 
Train 251, loss: 1.041416
Start validation
Val 251, loss: 10.020626
Linear Accuracy (val): 0.609375
Start training epoch: (252/300)
Epoch (252), Batch(0/107), loss: 0.934754, imid loss: 0.128288, cmid loss: 0.806467 
Epoch (252), Batch(20/107), loss: 1.035059, imid loss: 0.124318, cmid loss: 0.910742 
Epoch (252), Batch(40/107), loss: 1.033036, imid loss: 0.121300, cmid loss: 0.911736 
Epoch (252), Batch(60/107), loss: 1.034683, imid loss: 0.122892, cmid loss: 0.911791 
Epoch (252), Batch(80/107), loss: 1.040718, imid loss: 0.121483, cmid loss: 0.919235 
Epoch (252), Batch(100/107), loss: 1.053862, imid loss: 0.122747, cmid loss: 0.931115 
Train 252, loss: 1.054768
Start validation
Val 252, loss: 8.713513
Linear Accuracy (val): 0.6119791666666666
Start training epoch: (253/300)
Epoch (253), Batch(0/107), loss: 1.127947, imid loss: 0.117910, cmid loss: 1.010037 
Epoch (253), Batch(20/107), loss: 1.049582, imid loss: 0.123753, cmid loss: 0.925829 
Epoch (253), Batch(40/107), loss: 1.039788, imid loss: 0.126601, cmid loss: 0.913187 
Epoch (253), Batch(60/107), loss: 1.037861, imid loss: 0.124718, cmid loss: 0.913143 
Epoch (253), Batch(80/107), loss: 1.040684, imid loss: 0.124235, cmid loss: 0.916449 
Epoch (253), Batch(100/107), loss: 1.043677, imid loss: 0.125159, cmid loss: 0.918518 
Train 253, loss: 1.045676
Start validation
Val 253, loss: 11.183085
Linear Accuracy (val): 0.6015625
Start training epoch: (254/300)
Epoch (254), Batch(0/107), loss: 1.051899, imid loss: 0.142756, cmid loss: 0.909143 
Epoch (254), Batch(20/107), loss: 1.042247, imid loss: 0.127956, cmid loss: 0.914291 
Epoch (254), Batch(40/107), loss: 1.041790, imid loss: 0.126064, cmid loss: 0.915726 
Epoch (254), Batch(60/107), loss: 1.039320, imid loss: 0.124396, cmid loss: 0.914924 
Epoch (254), Batch(80/107), loss: 1.040434, imid loss: 0.124583, cmid loss: 0.915852 
Epoch (254), Batch(100/107), loss: 1.043615, imid loss: 0.123802, cmid loss: 0.919813 
Train 254, loss: 1.041259
Start validation
Val 254, loss: 8.165416
Linear Accuracy (val): 0.6111111111111112
Start training epoch: (255/300)
Epoch (255), Batch(0/107), loss: 1.042013, imid loss: 0.123829, cmid loss: 0.918184 
Epoch (255), Batch(20/107), loss: 1.008520, imid loss: 0.116884, cmid loss: 0.891636 
Epoch (255), Batch(40/107), loss: 1.031338, imid loss: 0.120476, cmid loss: 0.910861 
Epoch (255), Batch(60/107), loss: 1.031136, imid loss: 0.119399, cmid loss: 0.911737 
Epoch (255), Batch(80/107), loss: 1.032663, imid loss: 0.119357, cmid loss: 0.913306 
Epoch (255), Batch(100/107), loss: 1.033725, imid loss: 0.120732, cmid loss: 0.912993 
Train 255, loss: 1.034670
Start validation
Val 255, loss: 7.540384
Linear Accuracy (val): 0.6163194444444444
Start training epoch: (256/300)
Epoch (256), Batch(0/107), loss: 1.136918, imid loss: 0.108893, cmid loss: 1.028025 
Epoch (256), Batch(20/107), loss: 1.083057, imid loss: 0.125065, cmid loss: 0.957992 
Epoch (256), Batch(40/107), loss: 1.069422, imid loss: 0.127188, cmid loss: 0.942233 
Epoch (256), Batch(60/107), loss: 1.061355, imid loss: 0.127382, cmid loss: 0.933973 
Epoch (256), Batch(80/107), loss: 1.054044, imid loss: 0.126180, cmid loss: 0.927864 
Epoch (256), Batch(100/107), loss: 1.054643, imid loss: 0.124043, cmid loss: 0.930600 
Train 256, loss: 1.051283
Start validation
Val 256, loss: 11.383693
Linear Accuracy (val): 0.6128472222222222
Start training epoch: (257/300)
Epoch (257), Batch(0/107), loss: 1.071675, imid loss: 0.093164, cmid loss: 0.978511 
Epoch (257), Batch(20/107), loss: 1.049712, imid loss: 0.120083, cmid loss: 0.929629 
Epoch (257), Batch(40/107), loss: 1.044426, imid loss: 0.121400, cmid loss: 0.923026 
Epoch (257), Batch(60/107), loss: 1.036043, imid loss: 0.119999, cmid loss: 0.916044 
Epoch (257), Batch(80/107), loss: 1.043143, imid loss: 0.121758, cmid loss: 0.921385 
Epoch (257), Batch(100/107), loss: 1.040203, imid loss: 0.121887, cmid loss: 0.918316 
Train 257, loss: 1.044311
Start validation
Val 257, loss: 8.757061
Linear Accuracy (val): 0.6102430555555556
Start training epoch: (258/300)
Epoch (258), Batch(0/107), loss: 1.004478, imid loss: 0.107231, cmid loss: 0.897247 
Epoch (258), Batch(20/107), loss: 1.030526, imid loss: 0.122706, cmid loss: 0.907820 
Epoch (258), Batch(40/107), loss: 1.016145, imid loss: 0.121767, cmid loss: 0.894378 
Epoch (258), Batch(60/107), loss: 1.028344, imid loss: 0.124072, cmid loss: 0.904273 
Epoch (258), Batch(80/107), loss: 1.020439, imid loss: 0.121604, cmid loss: 0.898835 
Epoch (258), Batch(100/107), loss: 1.030057, imid loss: 0.121283, cmid loss: 0.908774 
Train 258, loss: 1.032026
Start validation
Val 258, loss: 7.618499
Linear Accuracy (val): 0.609375
Start training epoch: (259/300)
Epoch (259), Batch(0/107), loss: 1.006547, imid loss: 0.132830, cmid loss: 0.873717 
Epoch (259), Batch(20/107), loss: 1.029138, imid loss: 0.119975, cmid loss: 0.909163 
Epoch (259), Batch(40/107), loss: 1.053357, imid loss: 0.127828, cmid loss: 0.925530 
Epoch (259), Batch(60/107), loss: 1.045831, imid loss: 0.124556, cmid loss: 0.921275 
Epoch (259), Batch(80/107), loss: 1.051553, imid loss: 0.124964, cmid loss: 0.926589 
Epoch (259), Batch(100/107), loss: 1.051604, imid loss: 0.124808, cmid loss: 0.926796 
Train 259, loss: 1.049339
Start validation
Val 259, loss: 8.764192
Linear Accuracy (val): 0.6067708333333334
Start training epoch: (260/300)
Epoch (260), Batch(0/107), loss: 1.030892, imid loss: 0.101882, cmid loss: 0.929010 
Epoch (260), Batch(20/107), loss: 1.026692, imid loss: 0.120091, cmid loss: 0.906601 
Epoch (260), Batch(40/107), loss: 1.030886, imid loss: 0.123744, cmid loss: 0.907142 
Epoch (260), Batch(60/107), loss: 1.027021, imid loss: 0.122834, cmid loss: 0.904187 
Epoch (260), Batch(80/107), loss: 1.025472, imid loss: 0.122256, cmid loss: 0.903216 
Epoch (260), Batch(100/107), loss: 1.020979, imid loss: 0.122897, cmid loss: 0.898082 
Train 260, loss: 1.017398
Start validation
Val 260, loss: 8.284600
Linear Accuracy (val): 0.6111111111111112
==> Saving...
Start training epoch: (261/300)
Epoch (261), Batch(0/107), loss: 1.032819, imid loss: 0.137741, cmid loss: 0.895078 
Epoch (261), Batch(20/107), loss: 1.039919, imid loss: 0.122984, cmid loss: 0.916935 
Epoch (261), Batch(40/107), loss: 1.040077, imid loss: 0.122649, cmid loss: 0.917428 
Epoch (261), Batch(60/107), loss: 1.032205, imid loss: 0.119110, cmid loss: 0.913096 
Epoch (261), Batch(80/107), loss: 1.039910, imid loss: 0.119681, cmid loss: 0.920229 
Epoch (261), Batch(100/107), loss: 1.045175, imid loss: 0.120838, cmid loss: 0.924337 
Train 261, loss: 1.043712
Start validation
Val 261, loss: 8.676273
Linear Accuracy (val): 0.5989583333333334
Start training epoch: (262/300)
Epoch (262), Batch(0/107), loss: 1.148763, imid loss: 0.123315, cmid loss: 1.025448 
Epoch (262), Batch(20/107), loss: 1.043137, imid loss: 0.124792, cmid loss: 0.918345 
Epoch (262), Batch(40/107), loss: 1.035657, imid loss: 0.125395, cmid loss: 0.910263 
Epoch (262), Batch(60/107), loss: 1.038750, imid loss: 0.124410, cmid loss: 0.914339 
Epoch (262), Batch(80/107), loss: 1.039998, imid loss: 0.124576, cmid loss: 0.915422 
Epoch (262), Batch(100/107), loss: 1.039677, imid loss: 0.124503, cmid loss: 0.915174 
Train 262, loss: 1.040368
Start validation
Val 262, loss: 9.312591
Linear Accuracy (val): 0.6041666666666666
Start training epoch: (263/300)
Epoch (263), Batch(0/107), loss: 1.040515, imid loss: 0.088253, cmid loss: 0.952261 
Epoch (263), Batch(20/107), loss: 1.050211, imid loss: 0.118992, cmid loss: 0.931219 
Epoch (263), Batch(40/107), loss: 1.040342, imid loss: 0.119245, cmid loss: 0.921098 
Epoch (263), Batch(60/107), loss: 1.040680, imid loss: 0.120956, cmid loss: 0.919724 
Epoch (263), Batch(80/107), loss: 1.042916, imid loss: 0.122647, cmid loss: 0.920269 
Epoch (263), Batch(100/107), loss: 1.033065, imid loss: 0.121396, cmid loss: 0.911669 
Train 263, loss: 1.034611
Start validation
Val 263, loss: 1.545453
Linear Accuracy (val): 0.6119791666666666
Start training epoch: (264/300)
Epoch (264), Batch(0/107), loss: 1.018586, imid loss: 0.142378, cmid loss: 0.876207 
Epoch (264), Batch(20/107), loss: 1.042537, imid loss: 0.129378, cmid loss: 0.913159 
Epoch (264), Batch(40/107), loss: 1.048336, imid loss: 0.127846, cmid loss: 0.920489 
Epoch (264), Batch(60/107), loss: 1.042776, imid loss: 0.127122, cmid loss: 0.915654 
Epoch (264), Batch(80/107), loss: 1.040551, imid loss: 0.125648, cmid loss: 0.914903 
Epoch (264), Batch(100/107), loss: 1.027367, imid loss: 0.123293, cmid loss: 0.904073 
Train 264, loss: 1.029260
Start validation
Val 264, loss: 9.414013
Linear Accuracy (val): 0.6067708333333334
Start training epoch: (265/300)
Epoch (265), Batch(0/107), loss: 1.212866, imid loss: 0.136594, cmid loss: 1.076272 
Epoch (265), Batch(20/107), loss: 1.041043, imid loss: 0.119406, cmid loss: 0.921637 
Epoch (265), Batch(40/107), loss: 1.028064, imid loss: 0.122672, cmid loss: 0.905392 
Epoch (265), Batch(60/107), loss: 1.026924, imid loss: 0.123772, cmid loss: 0.903151 
Epoch (265), Batch(80/107), loss: 1.038305, imid loss: 0.123702, cmid loss: 0.914603 
Epoch (265), Batch(100/107), loss: 1.038228, imid loss: 0.123603, cmid loss: 0.914625 
Train 265, loss: 1.038688
Start validation
Val 265, loss: 8.198669
Linear Accuracy (val): 0.6015625
Start training epoch: (266/300)
Epoch (266), Batch(0/107), loss: 0.991191, imid loss: 0.101754, cmid loss: 0.889437 
Epoch (266), Batch(20/107), loss: 1.003664, imid loss: 0.116647, cmid loss: 0.887016 
Epoch (266), Batch(40/107), loss: 1.012195, imid loss: 0.119814, cmid loss: 0.892381 
Epoch (266), Batch(60/107), loss: 1.027103, imid loss: 0.123495, cmid loss: 0.903608 
Epoch (266), Batch(80/107), loss: 1.035934, imid loss: 0.121782, cmid loss: 0.914152 
Epoch (266), Batch(100/107), loss: 1.024947, imid loss: 0.122833, cmid loss: 0.902114 
Train 266, loss: 1.026924
Start validation
Val 266, loss: 1.491198
Linear Accuracy (val): 0.6189236111111112
Start training epoch: (267/300)
Epoch (267), Batch(0/107), loss: 0.982795, imid loss: 0.110334, cmid loss: 0.872461 
Epoch (267), Batch(20/107), loss: 1.053870, imid loss: 0.124606, cmid loss: 0.929264 
Epoch (267), Batch(40/107), loss: 1.064253, imid loss: 0.126110, cmid loss: 0.938143 
Epoch (267), Batch(60/107), loss: 1.055527, imid loss: 0.126027, cmid loss: 0.929500 
Epoch (267), Batch(80/107), loss: 1.056679, imid loss: 0.125778, cmid loss: 0.930901 
Epoch (267), Batch(100/107), loss: 1.051854, imid loss: 0.124960, cmid loss: 0.926894 
Train 267, loss: 1.054154
Start validation
Val 267, loss: 1.512673
Linear Accuracy (val): 0.609375
Start training epoch: (268/300)
Epoch (268), Batch(0/107), loss: 0.915218, imid loss: 0.117962, cmid loss: 0.797255 
Epoch (268), Batch(20/107), loss: 1.015317, imid loss: 0.120042, cmid loss: 0.895275 
Epoch (268), Batch(40/107), loss: 1.036371, imid loss: 0.122637, cmid loss: 0.913734 
Epoch (268), Batch(60/107), loss: 1.032670, imid loss: 0.122103, cmid loss: 0.910567 
Epoch (268), Batch(80/107), loss: 1.035951, imid loss: 0.120958, cmid loss: 0.914994 
Epoch (268), Batch(100/107), loss: 1.031086, imid loss: 0.122236, cmid loss: 0.908850 
Train 268, loss: 1.024403
Start validation
Val 268, loss: 1.757571
Linear Accuracy (val): 0.6085069444444444
Start training epoch: (269/300)
Epoch (269), Batch(0/107), loss: 1.077209, imid loss: 0.126942, cmid loss: 0.950268 
Epoch (269), Batch(20/107), loss: 1.009085, imid loss: 0.121810, cmid loss: 0.887274 
Epoch (269), Batch(40/107), loss: 1.014465, imid loss: 0.122336, cmid loss: 0.892129 
Epoch (269), Batch(60/107), loss: 1.015703, imid loss: 0.122961, cmid loss: 0.892741 
Epoch (269), Batch(80/107), loss: 1.022879, imid loss: 0.122671, cmid loss: 0.900208 
Epoch (269), Batch(100/107), loss: 1.019710, imid loss: 0.120996, cmid loss: 0.898714 
Train 269, loss: 1.021479
Start validation
Val 269, loss: 8.663869
Linear Accuracy (val): 0.6015625
Start training epoch: (270/300)
Epoch (270), Batch(0/107), loss: 0.959011, imid loss: 0.095043, cmid loss: 0.863969 
Epoch (270), Batch(20/107), loss: 1.051123, imid loss: 0.120883, cmid loss: 0.930240 
Epoch (270), Batch(40/107), loss: 1.039449, imid loss: 0.121371, cmid loss: 0.918078 
Epoch (270), Batch(60/107), loss: 1.032230, imid loss: 0.119922, cmid loss: 0.912308 
Epoch (270), Batch(80/107), loss: 1.042398, imid loss: 0.120892, cmid loss: 0.921506 
Epoch (270), Batch(100/107), loss: 1.038891, imid loss: 0.121256, cmid loss: 0.917635 
Train 270, loss: 1.037409
Start validation
Val 270, loss: 8.804103
Linear Accuracy (val): 0.6128472222222222
==> Saving...
Start training epoch: (271/300)
Epoch (271), Batch(0/107), loss: 1.032529, imid loss: 0.140531, cmid loss: 0.891998 
Epoch (271), Batch(20/107), loss: 1.023877, imid loss: 0.121640, cmid loss: 0.902238 
Epoch (271), Batch(40/107), loss: 1.028407, imid loss: 0.124149, cmid loss: 0.904258 
Epoch (271), Batch(60/107), loss: 1.025665, imid loss: 0.125105, cmid loss: 0.900560 
Epoch (271), Batch(80/107), loss: 1.017290, imid loss: 0.122077, cmid loss: 0.895213 
Epoch (271), Batch(100/107), loss: 1.022266, imid loss: 0.121046, cmid loss: 0.901220 
Train 271, loss: 1.025402
Start validation
Val 271, loss: 10.298158
Linear Accuracy (val): 0.6050347222222222
Start training epoch: (272/300)
Epoch (272), Batch(0/107), loss: 1.020868, imid loss: 0.093515, cmid loss: 0.927352 
Epoch (272), Batch(20/107), loss: 1.018980, imid loss: 0.120539, cmid loss: 0.898441 
Epoch (272), Batch(40/107), loss: 1.019130, imid loss: 0.121946, cmid loss: 0.897184 
Epoch (272), Batch(60/107), loss: 1.015066, imid loss: 0.122380, cmid loss: 0.892686 
Epoch (272), Batch(80/107), loss: 1.014987, imid loss: 0.121095, cmid loss: 0.893892 
Epoch (272), Batch(100/107), loss: 1.007906, imid loss: 0.120529, cmid loss: 0.887377 
Train 272, loss: 1.005891
Start validation
Val 272, loss: 10.646358
Linear Accuracy (val): 0.6050347222222222
Start training epoch: (273/300)
Epoch (273), Batch(0/107), loss: 1.126178, imid loss: 0.111860, cmid loss: 1.014317 
Epoch (273), Batch(20/107), loss: 1.058512, imid loss: 0.124829, cmid loss: 0.933683 
Epoch (273), Batch(40/107), loss: 1.046646, imid loss: 0.126944, cmid loss: 0.919702 
Epoch (273), Batch(60/107), loss: 1.041921, imid loss: 0.126430, cmid loss: 0.915491 
Epoch (273), Batch(80/107), loss: 1.043333, imid loss: 0.126468, cmid loss: 0.916864 
Epoch (273), Batch(100/107), loss: 1.040245, imid loss: 0.124842, cmid loss: 0.915403 
Train 273, loss: 1.038367
Start validation
Val 273, loss: 1.612610
Linear Accuracy (val): 0.6137152777777778
Start training epoch: (274/300)
Epoch (274), Batch(0/107), loss: 0.913599, imid loss: 0.103436, cmid loss: 0.810163 
Epoch (274), Batch(20/107), loss: 1.029451, imid loss: 0.119676, cmid loss: 0.909775 
Epoch (274), Batch(40/107), loss: 1.015913, imid loss: 0.120401, cmid loss: 0.895512 
Epoch (274), Batch(60/107), loss: 1.025085, imid loss: 0.122907, cmid loss: 0.902178 
Epoch (274), Batch(80/107), loss: 1.033676, imid loss: 0.125129, cmid loss: 0.908547 
Epoch (274), Batch(100/107), loss: 1.035853, imid loss: 0.124884, cmid loss: 0.910969 
Train 274, loss: 1.034355
Start validation
Val 274, loss: 1.560535
Linear Accuracy (val): 0.6137152777777778
Start training epoch: (275/300)
Epoch (275), Batch(0/107), loss: 0.996716, imid loss: 0.107728, cmid loss: 0.888988 
Epoch (275), Batch(20/107), loss: 1.025487, imid loss: 0.125848, cmid loss: 0.899639 
Epoch (275), Batch(40/107), loss: 1.039795, imid loss: 0.125594, cmid loss: 0.914201 
Epoch (275), Batch(60/107), loss: 1.027827, imid loss: 0.121051, cmid loss: 0.906776 
Epoch (275), Batch(80/107), loss: 1.029040, imid loss: 0.121042, cmid loss: 0.907998 
Epoch (275), Batch(100/107), loss: 1.024866, imid loss: 0.120346, cmid loss: 0.904520 
Train 275, loss: 1.026968
Start validation
Val 275, loss: 1.520082
Linear Accuracy (val): 0.6154513888888888
Start training epoch: (276/300)
Epoch (276), Batch(0/107), loss: 0.834402, imid loss: 0.101432, cmid loss: 0.732969 
Epoch (276), Batch(20/107), loss: 1.016947, imid loss: 0.124146, cmid loss: 0.892801 
Epoch (276), Batch(40/107), loss: 1.009822, imid loss: 0.121897, cmid loss: 0.887925 
Epoch (276), Batch(60/107), loss: 1.001365, imid loss: 0.120792, cmid loss: 0.880573 
Epoch (276), Batch(80/107), loss: 1.003305, imid loss: 0.120926, cmid loss: 0.882379 
Epoch (276), Batch(100/107), loss: 1.013414, imid loss: 0.121421, cmid loss: 0.891993 
Train 276, loss: 1.012551
Start validation
Val 276, loss: 8.303585
Linear Accuracy (val): 0.6145833333333334
Start training epoch: (277/300)
Epoch (277), Batch(0/107), loss: 0.935093, imid loss: 0.122489, cmid loss: 0.812604 
Epoch (277), Batch(20/107), loss: 1.042247, imid loss: 0.125546, cmid loss: 0.916701 
Epoch (277), Batch(40/107), loss: 1.029431, imid loss: 0.123818, cmid loss: 0.905613 
Epoch (277), Batch(60/107), loss: 1.025580, imid loss: 0.122130, cmid loss: 0.903450 
Epoch (277), Batch(80/107), loss: 1.021306, imid loss: 0.121117, cmid loss: 0.900189 
Epoch (277), Batch(100/107), loss: 1.018291, imid loss: 0.119875, cmid loss: 0.898416 
Train 277, loss: 1.023351
Start validation
Val 277, loss: 8.634897
Linear Accuracy (val): 0.6154513888888888
Start training epoch: (278/300)
Epoch (278), Batch(0/107), loss: 1.212000, imid loss: 0.109629, cmid loss: 1.102370 
Epoch (278), Batch(20/107), loss: 1.017259, imid loss: 0.117942, cmid loss: 0.899317 
Epoch (278), Batch(40/107), loss: 1.035039, imid loss: 0.117616, cmid loss: 0.917422 
Epoch (278), Batch(60/107), loss: 1.033014, imid loss: 0.118988, cmid loss: 0.914026 
Epoch (278), Batch(80/107), loss: 1.030395, imid loss: 0.120168, cmid loss: 0.910227 
Epoch (278), Batch(100/107), loss: 1.030891, imid loss: 0.120771, cmid loss: 0.910120 
Train 278, loss: 1.031973
Start validation
Val 278, loss: 1.464372
Linear Accuracy (val): 0.6171875
Start training epoch: (279/300)
Epoch (279), Batch(0/107), loss: 0.959316, imid loss: 0.085518, cmid loss: 0.873798 
Epoch (279), Batch(20/107), loss: 1.014037, imid loss: 0.114707, cmid loss: 0.899330 
Epoch (279), Batch(40/107), loss: 1.021434, imid loss: 0.120412, cmid loss: 0.901023 
Epoch (279), Batch(60/107), loss: 1.026277, imid loss: 0.121205, cmid loss: 0.905071 
Epoch (279), Batch(80/107), loss: 1.019428, imid loss: 0.120835, cmid loss: 0.898593 
Epoch (279), Batch(100/107), loss: 1.023686, imid loss: 0.120347, cmid loss: 0.903339 
Train 279, loss: 1.023496
Start validation
Val 279, loss: 8.482818
Linear Accuracy (val): 0.6206597222222222
Start training epoch: (280/300)
Epoch (280), Batch(0/107), loss: 1.176157, imid loss: 0.153272, cmid loss: 1.022885 
Epoch (280), Batch(20/107), loss: 1.010224, imid loss: 0.121745, cmid loss: 0.888479 
Epoch (280), Batch(40/107), loss: 1.025887, imid loss: 0.120373, cmid loss: 0.905514 
Epoch (280), Batch(60/107), loss: 1.028815, imid loss: 0.121506, cmid loss: 0.907309 
Epoch (280), Batch(80/107), loss: 1.030862, imid loss: 0.122928, cmid loss: 0.907934 
Epoch (280), Batch(100/107), loss: 1.028487, imid loss: 0.121424, cmid loss: 0.907063 
Train 280, loss: 1.024036
Start validation
Val 280, loss: 7.499826
Linear Accuracy (val): 0.6163194444444444
==> Saving...
Start training epoch: (281/300)
Epoch (281), Batch(0/107), loss: 0.975207, imid loss: 0.118147, cmid loss: 0.857059 
Epoch (281), Batch(20/107), loss: 1.022436, imid loss: 0.121585, cmid loss: 0.900852 
Epoch (281), Batch(40/107), loss: 1.008995, imid loss: 0.118501, cmid loss: 0.890494 
Epoch (281), Batch(60/107), loss: 1.018472, imid loss: 0.120395, cmid loss: 0.898076 
Epoch (281), Batch(80/107), loss: 1.035441, imid loss: 0.123378, cmid loss: 0.912064 
Epoch (281), Batch(100/107), loss: 1.031259, imid loss: 0.121920, cmid loss: 0.909339 
Train 281, loss: 1.027265
Start validation
Val 281, loss: 2.333116
Linear Accuracy (val): 0.6137152777777778
Start training epoch: (282/300)
Epoch (282), Batch(0/107), loss: 1.028384, imid loss: 0.096802, cmid loss: 0.931582 
Epoch (282), Batch(20/107), loss: 1.012301, imid loss: 0.112841, cmid loss: 0.899460 
Epoch (282), Batch(40/107), loss: 1.033527, imid loss: 0.119880, cmid loss: 0.913648 
Epoch (282), Batch(60/107), loss: 1.042253, imid loss: 0.121943, cmid loss: 0.920310 
Epoch (282), Batch(80/107), loss: 1.030517, imid loss: 0.122242, cmid loss: 0.908274 
Epoch (282), Batch(100/107), loss: 1.031404, imid loss: 0.123236, cmid loss: 0.908168 
Train 282, loss: 1.031370
Start validation
Val 282, loss: 1.465536
Linear Accuracy (val): 0.6085069444444444
Start training epoch: (283/300)
Epoch (283), Batch(0/107), loss: 1.080379, imid loss: 0.120943, cmid loss: 0.959435 
Epoch (283), Batch(20/107), loss: 1.002600, imid loss: 0.116145, cmid loss: 0.886455 
Epoch (283), Batch(40/107), loss: 1.016233, imid loss: 0.119617, cmid loss: 0.896616 
Epoch (283), Batch(60/107), loss: 1.010986, imid loss: 0.119693, cmid loss: 0.891293 
Epoch (283), Batch(80/107), loss: 1.015858, imid loss: 0.120779, cmid loss: 0.895079 
Epoch (283), Batch(100/107), loss: 1.021627, imid loss: 0.122574, cmid loss: 0.899053 
Train 283, loss: 1.024363
Start validation
Val 283, loss: 1.547124
Linear Accuracy (val): 0.6189236111111112
Start training epoch: (284/300)
Epoch (284), Batch(0/107), loss: 1.066269, imid loss: 0.159673, cmid loss: 0.906595 
Epoch (284), Batch(20/107), loss: 1.004931, imid loss: 0.119095, cmid loss: 0.885835 
Epoch (284), Batch(40/107), loss: 1.012960, imid loss: 0.122470, cmid loss: 0.890490 
Epoch (284), Batch(60/107), loss: 1.014840, imid loss: 0.123072, cmid loss: 0.891768 
Epoch (284), Batch(80/107), loss: 1.022595, imid loss: 0.122617, cmid loss: 0.899978 
Epoch (284), Batch(100/107), loss: 1.012346, imid loss: 0.122392, cmid loss: 0.889954 
Train 284, loss: 1.012014
Start validation
Val 284, loss: 1.522881
Linear Accuracy (val): 0.625
Start training epoch: (285/300)
Epoch (285), Batch(0/107), loss: 1.027672, imid loss: 0.121090, cmid loss: 0.906582 
Epoch (285), Batch(20/107), loss: 1.001691, imid loss: 0.120454, cmid loss: 0.881237 
Epoch (285), Batch(40/107), loss: 1.009911, imid loss: 0.122314, cmid loss: 0.887597 
Epoch (285), Batch(60/107), loss: 1.011835, imid loss: 0.121173, cmid loss: 0.890662 
Epoch (285), Batch(80/107), loss: 1.012255, imid loss: 0.121752, cmid loss: 0.890502 
Epoch (285), Batch(100/107), loss: 1.012549, imid loss: 0.121026, cmid loss: 0.891523 
Train 285, loss: 1.007663
Start validation
Val 285, loss: 1.521428
Linear Accuracy (val): 0.6059027777777778
Start training epoch: (286/300)
Epoch (286), Batch(0/107), loss: 0.896759, imid loss: 0.111836, cmid loss: 0.784923 
Epoch (286), Batch(20/107), loss: 1.014859, imid loss: 0.122752, cmid loss: 0.892107 
Epoch (286), Batch(40/107), loss: 1.039698, imid loss: 0.122234, cmid loss: 0.917464 
Epoch (286), Batch(60/107), loss: 1.032919, imid loss: 0.122143, cmid loss: 0.910775 
Epoch (286), Batch(80/107), loss: 1.028408, imid loss: 0.121771, cmid loss: 0.906637 
Epoch (286), Batch(100/107), loss: 1.034396, imid loss: 0.123054, cmid loss: 0.911342 
Train 286, loss: 1.032657
Start validation
Val 286, loss: 1.520039
Linear Accuracy (val): 0.6119791666666666
Start training epoch: (287/300)
Epoch (287), Batch(0/107), loss: 0.940095, imid loss: 0.133716, cmid loss: 0.806379 
Epoch (287), Batch(20/107), loss: 1.013648, imid loss: 0.127178, cmid loss: 0.886470 
Epoch (287), Batch(40/107), loss: 1.010985, imid loss: 0.121702, cmid loss: 0.889283 
Epoch (287), Batch(60/107), loss: 1.008327, imid loss: 0.121597, cmid loss: 0.886730 
Epoch (287), Batch(80/107), loss: 1.008024, imid loss: 0.121138, cmid loss: 0.886886 
Epoch (287), Batch(100/107), loss: 1.009177, imid loss: 0.120737, cmid loss: 0.888439 
Train 287, loss: 1.012317
Start validation
Val 287, loss: 1.524004
Linear Accuracy (val): 0.6206597222222222
Start training epoch: (288/300)
Epoch (288), Batch(0/107), loss: 0.962853, imid loss: 0.110449, cmid loss: 0.852403 
Epoch (288), Batch(20/107), loss: 1.007688, imid loss: 0.122897, cmid loss: 0.884790 
Epoch (288), Batch(40/107), loss: 1.029160, imid loss: 0.124338, cmid loss: 0.904822 
Epoch (288), Batch(60/107), loss: 1.031694, imid loss: 0.123634, cmid loss: 0.908060 
Epoch (288), Batch(80/107), loss: 1.033237, imid loss: 0.124565, cmid loss: 0.908672 
Epoch (288), Batch(100/107), loss: 1.030470, imid loss: 0.122878, cmid loss: 0.907592 
Train 288, loss: 1.032041
Start validation
Val 288, loss: 6.827700
Linear Accuracy (val): 0.6059027777777778
Start training epoch: (289/300)
Epoch (289), Batch(0/107), loss: 1.068609, imid loss: 0.133480, cmid loss: 0.935129 
Epoch (289), Batch(20/107), loss: 1.024281, imid loss: 0.125313, cmid loss: 0.898969 
Epoch (289), Batch(40/107), loss: 1.023261, imid loss: 0.125470, cmid loss: 0.897790 
Epoch (289), Batch(60/107), loss: 1.019651, imid loss: 0.124683, cmid loss: 0.894968 
Epoch (289), Batch(80/107), loss: 1.012205, imid loss: 0.123112, cmid loss: 0.889093 
Epoch (289), Batch(100/107), loss: 1.007118, imid loss: 0.122068, cmid loss: 0.885050 
Train 289, loss: 1.007841
Start validation
Val 289, loss: 5.772917
Linear Accuracy (val): 0.6180555555555556
Start training epoch: (290/300)
Epoch (290), Batch(0/107), loss: 0.921944, imid loss: 0.134717, cmid loss: 0.787227 
Epoch (290), Batch(20/107), loss: 1.035793, imid loss: 0.119393, cmid loss: 0.916401 
Epoch (290), Batch(40/107), loss: 1.023792, imid loss: 0.121728, cmid loss: 0.902064 
Epoch (290), Batch(60/107), loss: 1.024647, imid loss: 0.121799, cmid loss: 0.902848 
Epoch (290), Batch(80/107), loss: 1.023916, imid loss: 0.122006, cmid loss: 0.901911 
Epoch (290), Batch(100/107), loss: 1.026384, imid loss: 0.121934, cmid loss: 0.904451 
Train 290, loss: 1.026320
Start validation
Val 290, loss: 1.558422
Linear Accuracy (val): 0.6171875
==> Saving...
Start training epoch: (291/300)
Epoch (291), Batch(0/107), loss: 1.037779, imid loss: 0.103463, cmid loss: 0.934315 
Epoch (291), Batch(20/107), loss: 1.026503, imid loss: 0.118994, cmid loss: 0.907509 
Epoch (291), Batch(40/107), loss: 1.022741, imid loss: 0.119816, cmid loss: 0.902925 
Epoch (291), Batch(60/107), loss: 1.003835, imid loss: 0.120921, cmid loss: 0.882914 
Epoch (291), Batch(80/107), loss: 1.009501, imid loss: 0.119724, cmid loss: 0.889777 
Epoch (291), Batch(100/107), loss: 1.016401, imid loss: 0.120896, cmid loss: 0.895505 
Train 291, loss: 1.020685
Start validation
Val 291, loss: 1.508303
Linear Accuracy (val): 0.6128472222222222
Start training epoch: (292/300)
Epoch (292), Batch(0/107), loss: 1.272656, imid loss: 0.177160, cmid loss: 1.095495 
Epoch (292), Batch(20/107), loss: 1.028368, imid loss: 0.119240, cmid loss: 0.909128 
Epoch (292), Batch(40/107), loss: 1.031714, imid loss: 0.121806, cmid loss: 0.909908 
Epoch (292), Batch(60/107), loss: 1.029048, imid loss: 0.123153, cmid loss: 0.905894 
Epoch (292), Batch(80/107), loss: 1.022317, imid loss: 0.123200, cmid loss: 0.899117 
Epoch (292), Batch(100/107), loss: 1.024937, imid loss: 0.122724, cmid loss: 0.902213 
Train 292, loss: 1.022018
Start validation
Val 292, loss: 1.522263
Linear Accuracy (val): 0.6171875
Start training epoch: (293/300)
Epoch (293), Batch(0/107), loss: 1.021345, imid loss: 0.118997, cmid loss: 0.902348 
Epoch (293), Batch(20/107), loss: 1.020021, imid loss: 0.124566, cmid loss: 0.895455 
Epoch (293), Batch(40/107), loss: 1.024064, imid loss: 0.126365, cmid loss: 0.897699 
Epoch (293), Batch(60/107), loss: 1.037811, imid loss: 0.126557, cmid loss: 0.911254 
Epoch (293), Batch(80/107), loss: 1.038203, imid loss: 0.126799, cmid loss: 0.911404 
Epoch (293), Batch(100/107), loss: 1.031088, imid loss: 0.124821, cmid loss: 0.906267 
Train 293, loss: 1.034733
Start validation
Val 293, loss: 1.513762
Linear Accuracy (val): 0.6215277777777778
Start training epoch: (294/300)
Epoch (294), Batch(0/107), loss: 1.042500, imid loss: 0.139222, cmid loss: 0.903279 
Epoch (294), Batch(20/107), loss: 1.038281, imid loss: 0.121725, cmid loss: 0.916557 
Epoch (294), Batch(40/107), loss: 1.040376, imid loss: 0.123135, cmid loss: 0.917241 
Epoch (294), Batch(60/107), loss: 1.032962, imid loss: 0.123088, cmid loss: 0.909874 
Epoch (294), Batch(80/107), loss: 1.024189, imid loss: 0.124257, cmid loss: 0.899932 
Epoch (294), Batch(100/107), loss: 1.018764, imid loss: 0.123052, cmid loss: 0.895712 
Train 294, loss: 1.019455
Start validation
Val 294, loss: 1.558205
Linear Accuracy (val): 0.6032986111111112
Start training epoch: (295/300)
Epoch (295), Batch(0/107), loss: 1.023862, imid loss: 0.090835, cmid loss: 0.933028 
Epoch (295), Batch(20/107), loss: 0.990465, imid loss: 0.119647, cmid loss: 0.870818 
Epoch (295), Batch(40/107), loss: 1.007916, imid loss: 0.118180, cmid loss: 0.889736 
Epoch (295), Batch(60/107), loss: 1.029776, imid loss: 0.122640, cmid loss: 0.907137 
Epoch (295), Batch(80/107), loss: 1.031943, imid loss: 0.122107, cmid loss: 0.909836 
Epoch (295), Batch(100/107), loss: 1.032791, imid loss: 0.122706, cmid loss: 0.910084 
Train 295, loss: 1.036298
Start validation
Val 295, loss: 6.991628
Linear Accuracy (val): 0.6171875
Start training epoch: (296/300)
Epoch (296), Batch(0/107), loss: 0.948812, imid loss: 0.108887, cmid loss: 0.839924 
Epoch (296), Batch(20/107), loss: 0.981765, imid loss: 0.115491, cmid loss: 0.866275 
Epoch (296), Batch(40/107), loss: 0.993685, imid loss: 0.119602, cmid loss: 0.874083 
Epoch (296), Batch(60/107), loss: 0.999144, imid loss: 0.120692, cmid loss: 0.878452 
Epoch (296), Batch(80/107), loss: 1.013472, imid loss: 0.122397, cmid loss: 0.891075 
Epoch (296), Batch(100/107), loss: 1.017515, imid loss: 0.121902, cmid loss: 0.895614 
Train 296, loss: 1.017526
Start validation
Val 296, loss: 1.489178
Linear Accuracy (val): 0.6145833333333334
Start training epoch: (297/300)
Epoch (297), Batch(0/107), loss: 1.114779, imid loss: 0.137153, cmid loss: 0.977626 
Epoch (297), Batch(20/107), loss: 1.030783, imid loss: 0.124038, cmid loss: 0.906745 
Epoch (297), Batch(40/107), loss: 1.026172, imid loss: 0.122193, cmid loss: 0.903979 
Epoch (297), Batch(60/107), loss: 1.024829, imid loss: 0.124266, cmid loss: 0.900563 
Epoch (297), Batch(80/107), loss: 1.028066, imid loss: 0.123104, cmid loss: 0.904962 
Epoch (297), Batch(100/107), loss: 1.027230, imid loss: 0.121855, cmid loss: 0.905374 
Train 297, loss: 1.028553
Start validation
Val 297, loss: 1.467030
Linear Accuracy (val): 0.6154513888888888
Start training epoch: (298/300)
Epoch (298), Batch(0/107), loss: 1.014966, imid loss: 0.099962, cmid loss: 0.915004 
Epoch (298), Batch(20/107), loss: 1.010375, imid loss: 0.122234, cmid loss: 0.888141 
Epoch (298), Batch(40/107), loss: 1.020179, imid loss: 0.126851, cmid loss: 0.893328 
Epoch (298), Batch(60/107), loss: 1.016038, imid loss: 0.127218, cmid loss: 0.888820 
Epoch (298), Batch(80/107), loss: 1.013342, imid loss: 0.124911, cmid loss: 0.888431 
Epoch (298), Batch(100/107), loss: 1.022450, imid loss: 0.125263, cmid loss: 0.897187 
Train 298, loss: 1.019435
Start validation
Val 298, loss: 1.512963
Linear Accuracy (val): 0.6171875
Start training epoch: (299/300)
Epoch (299), Batch(0/107), loss: 1.058043, imid loss: 0.120640, cmid loss: 0.937403 
Epoch (299), Batch(20/107), loss: 1.016101, imid loss: 0.115055, cmid loss: 0.901045 
Epoch (299), Batch(40/107), loss: 1.020126, imid loss: 0.118479, cmid loss: 0.901647 
Epoch (299), Batch(60/107), loss: 1.028107, imid loss: 0.122673, cmid loss: 0.905434 
Epoch (299), Batch(80/107), loss: 1.022116, imid loss: 0.122880, cmid loss: 0.899236 
Epoch (299), Batch(100/107), loss: 1.022271, imid loss: 0.123153, cmid loss: 0.899118 
Train 299, loss: 1.022377
Start validation
Val 299, loss: 1.469863
Linear Accuracy (val): 0.6067708333333334
==> Saving Last Model...
